{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf \n",
    "import matplotlib.gridspec as gridspec\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data[\"Class\"].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Column for non-fraud transaction\n",
    "data.loc[data.Class == 0, 'normal'] = 1\n",
    "data.loc[data.Class == 1, 'normal'] = 0\n",
    "\n",
    "# Rename the Class to fraud\n",
    "\n",
    "data = data.rename(columns ={'Class' : 'fraud'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 33)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = data.drop(['Time', 'Amount'], axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284315, 31)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud = data[data.fraud == 1]\n",
    "normal = data[data.normal ==1]\n",
    "\n",
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>fraud</th>\n",
       "      <th>normal</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.350151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.254117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.081839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.313249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.514355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V22       V23  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ...  0.277838 -0.110474   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.771679  0.909412   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ...  0.005274 -0.190321   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ...  0.798278 -0.137458   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.111864  1.014480   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.924384  0.012463   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.578229 -0.037501   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.800049 -0.163298   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.643078  0.376777   \n",
       "\n",
       "             V24       V25       V26       V27       V28  fraud  normal  \\\n",
       "0       0.066928  0.128539 -0.189115  0.133558 -0.021053      0     1.0   \n",
       "1      -0.339846  0.167170  0.125895 -0.008983  0.014724      0     1.0   \n",
       "2      -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0     1.0   \n",
       "3      -1.175575  0.647376 -0.221929  0.062723  0.061458      0     1.0   \n",
       "4       0.141267 -0.206010  0.502292  0.219422  0.215153      0     1.0   \n",
       "...          ...       ...       ...       ...       ...    ...     ...   \n",
       "284802 -0.509348  1.436807  0.250034  0.943651  0.823731      0     1.0   \n",
       "284803 -1.016226 -0.606624 -0.395255  0.068472 -0.053527      0     1.0   \n",
       "284804  0.640134  0.265745 -0.087371  0.004455 -0.026561      0     1.0   \n",
       "284805  0.123205 -0.569159  0.546668  0.108821  0.104533      0     1.0   \n",
       "284806  0.008797 -0.473649 -0.818267 -0.002415  0.013649      0     1.0   \n",
       "\n",
       "        normAmount  \n",
       "0         0.244964  \n",
       "1        -0.342475  \n",
       "2         1.160686  \n",
       "3         0.140534  \n",
       "4        -0.073403  \n",
       "...            ...  \n",
       "284802   -0.350151  \n",
       "284803   -0.254117  \n",
       "284804   -0.081839  \n",
       "284805   -0.313249  \n",
       "284806    0.514355  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "normal =resample(normal, replace=False, #sample without replacement\n",
    "                         n_samples =492, # to match with minority class\n",
    "                         random_state =123 #reproducible results\n",
    "                )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X_train to 80% of fraduelent transactions\n",
    "X_train = fraud.sample(frac =0.8)\n",
    "count_frauds =len(X_train)\n",
    "# Add 80% of normal tansactions to X_train\n",
    "X_train = pd.concat([X_train, normal.sample(frac=0.8)], axis =0)\n",
    "# X_test now contains all the transactions not in X_train\n",
    "X_test = data.loc[~data.index.isin(X_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               V1         V2         V3        V4         V5        V6  \\\n",
      "228284   1.986505  -1.176584   0.017761 -0.474229  -1.400026  0.059587   \n",
      "158464   2.089127   0.032539  -2.521136 -0.127376   1.210427 -0.652897   \n",
      "90856    1.239842   0.672866  -0.235624  1.311518   0.032509 -1.196771   \n",
      "220725  -1.169203   1.863414  -2.515135  5.463681  -0.297971  1.364918   \n",
      "192687   1.522080  -0.519429  -2.581685  0.774741   0.206722 -1.431020   \n",
      "...           ...        ...        ...       ...        ...       ...   \n",
      "144104  -3.365265   2.928541  -5.660999  3.891160  -1.840375 -1.800887   \n",
      "253865  -3.617076   3.796598  -3.606746 -0.579314  -1.548979 -1.289197   \n",
      "14170  -15.903635  10.393917 -19.133602  6.185969 -12.538021 -4.027030   \n",
      "64329   -9.848776   7.365546 -12.898538  4.273323  -7.611991 -3.427045   \n",
      "74472    0.022843   0.893441   0.169920  1.356702   0.297970 -0.852668   \n",
      "\n",
      "               V7         V8        V9       V10  ...       V22       V23  \\\n",
      "228284  -1.337491   0.145433  0.036932  0.934946  ... -0.235923  0.308660   \n",
      "158464   0.693046  -0.509084  1.248334 -0.214919  ...  0.262651 -0.262682   \n",
      "90856    0.300944  -0.247690 -0.090192 -0.567431  ... -0.073937 -0.119856   \n",
      "220725   0.759219  -0.118861 -2.293921 -0.423784  ... -0.708692  0.471309   \n",
      "192687   0.757011  -0.444418  0.997921 -1.429490  ... -0.211678 -0.247452   \n",
      "...           ...        ...       ...       ...  ...       ...       ...   \n",
      "144104  -5.558679   2.402322 -2.848923 -5.995676  ... -0.102501 -0.606283   \n",
      "253865  -1.547312   2.921392 -0.129447 -0.565810  ... -1.032368  0.489060   \n",
      "14170  -13.897827  10.662252 -2.844954 -9.668789  ... -1.280137 -0.601295   \n",
      "64329   -8.350808   6.863604 -2.387567 -6.065782  ... -0.874467 -0.192639   \n",
      "74472    0.790223  -0.146458 -0.399306  0.474942  ...  0.698858  0.225386   \n",
      "\n",
      "             V24       V25       V26       V27       V28  fraud  normal  \\\n",
      "228284 -0.340420 -0.700575  0.482619  0.004501 -0.038478      0     1.0   \n",
      "158464 -1.372573  0.564234  0.260092 -0.125162 -0.099259      0     1.0   \n",
      "90856   0.278510  0.693283 -0.327776  0.032268  0.051380      0     1.0   \n",
      "220725 -0.078616 -0.544655  0.014777 -0.240930 -0.781055      1     0.0   \n",
      "192687 -0.279472  0.239646 -0.508398 -0.015551  0.041881      1     0.0   \n",
      "...          ...       ...       ...       ...       ...    ...     ...   \n",
      "144104 -0.743165  0.096319 -0.135060  1.238695  0.099824      1     0.0   \n",
      "253865  0.542615  0.059931  0.154243 -0.015678 -0.003966      0     1.0   \n",
      "14170   0.040404  0.995502 -0.273743  1.688136  0.527831      1     0.0   \n",
      "64329  -0.035426  0.538665 -0.263934  1.134095  0.225973      1     0.0   \n",
      "74472   0.395738 -0.833052 -0.348332  0.280648  0.178685      0     1.0   \n",
      "\n",
      "        normAmount  \n",
      "228284   -0.153925  \n",
      "158464   -0.131456  \n",
      "90856    -0.349231  \n",
      "220725    0.944509  \n",
      "192687    0.750922  \n",
      "...            ...  \n",
      "144104   -0.349231  \n",
      "253865   -0.313289  \n",
      "14170     0.046539  \n",
      "64329     0.046539  \n",
      "74472    -0.260954  \n",
      "\n",
      "[788 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# shuffle the dataframe so that training can be done in a random fashion\n",
    "X_train = shuffle(X_train)\n",
    "X_test = shuffle(X_test)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding our target features to y_train and y_test\n",
    "y_train = X_train.fraud\n",
    "y_train = pd.concat([y_train, X_train.normal], axis =1)\n",
    "\n",
    "y_test = X_test.fraud\n",
    "y_test = pd.concat([y_test, X_test.normal], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping target features from X_train & X_test\n",
    "X_train = X_train.drop(['fraud', 'normal'], axis =1)\n",
    "X_test = X_test.drop(['fraud', 'normal'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(788, 29)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarve\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\sarve\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\sarve\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n",
      "C:\\Users\\sarve\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# getting required i/p & o/p matrices\n",
    "x_input_train = X_train.as_matrix()\n",
    "y_input_train = y_train.as_matrix()\n",
    "\n",
    "x_input_test = X_test.as_matrix()\n",
    "y_input_test = y_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(788, 29)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284019, 29)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(788, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284019, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18569533817705186 0.18569533817705186 0.31622776601683794 0.31622776601683794\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Defining model hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size =100\n",
    "\n",
    "#placeholders\n",
    "X =tf.placeholder(tf.float32,[None,29], name= 'X_placeholder')\n",
    "Y =tf.placeholder(tf.float32,[None,2], name= 'Y_placeholder')\n",
    "\n",
    "num_classes = 2 \n",
    "feature_num = 29\n",
    "#hidden laye sizes\n",
    "hidden1_unit = 29\n",
    "hidden2_unit = 10\n",
    "hidden3_unit = 10\n",
    "hidden4_unit = 10\n",
    "st1=1.0/math.sqrt(float(feature_num))\n",
    "st2=1.0/math.sqrt(float(hidden1_unit))\n",
    "st3=1.0/math.sqrt(float(hidden2_unit))\n",
    "st4=1.0/math.sqrt(float(hidden4_unit))\n",
    "print(st1, st2, st3, st4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-46-869e22c2aa25>:8: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-46-869e22c2aa25>:29: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "# Model layers\n",
    "weights1= tf.Variable(tf.truncated_normal([29, hidden1_unit], stddev=st1), name = 'weights')\n",
    "biases = tf.Variable(tf.zeros(hidden1_unit), name='biases')\n",
    "hidden1 = tf.nn.sigmoid(tf.matmul((X),weights1)*biases)\n",
    "hidden1 = tf.nn.dropout(hidden1, 0.5)\n",
    "\n",
    "weights2= tf.Variable(tf.truncated_normal([hidden1_unit, hidden2_unit], stddev=st2), name = 'weights')\n",
    "biases = tf.Variable(tf.zeros(hidden2_unit), name='biases')\n",
    "hidden2 = tf.nn.sigmoid(tf.matmul((hidden1),(weights2))*biases)\n",
    "hidden2 = tf.nn.dropout(hidden2, 0.5)\n",
    "\n",
    "weights3= tf.Variable(tf.truncated_normal([hidden2_unit, hidden3_unit], stddev=st3), name = 'weights')\n",
    "biases3 = tf.Variable(tf.zeros(hidden3_unit), name='biases')\n",
    "hidden3 = tf.nn.sigmoid(tf.matmul((hidden2),(weights3))*biases3)\n",
    "hidden3 = tf.nn.dropout(hidden3, 0.5)\n",
    "\n",
    "#Linear\n",
    "\n",
    "weights4= tf.Variable(tf.truncated_normal([hidden3_unit, num_classes], stddev=st4), name = 'weights')\n",
    "biases4 = tf.Variable(tf.zeros(num_classes), name='biases')\n",
    "logits = tf.nn.softmax(tf.matmul((hidden3), weights4) +biases4)\n",
    "\n",
    "loss =tf.cast((tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits =logits, labels=Y)) +\n",
    "                                                                      0.01*tf.nn.l2_loss(weights1)+\n",
    "                                                                      0.01*tf.nn.l2_loss(biases)+\n",
    "                                                                      0.01*tf.nn.l2_loss(weights4)+\n",
    "                                                                      0.01*tf.nn.l2_loss(biases4)), tf.float32)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#train_predictions = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def next_batch(num, data, labels):\n",
    "    # return a total no of 'num' random samples with labels\n",
    "    idx = np.arange(0, len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx =idx[:num]\n",
    "    data_shuffle =[data[ i] for i in idx]\n",
    "    labels_shuffle =[labels[ i] for i in idx]\n",
    "    \n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "step: 0\n",
      "model training accuracy:\n",
      "0.53\n",
      "model test accuracy:\n",
      "0.6104275\n",
      "step: 1\n",
      "model training accuracy:\n",
      "0.53\n",
      "model test accuracy:\n",
      "0.6104275\n",
      "step: 2\n",
      "model training accuracy:\n",
      "0.53\n",
      "model test accuracy:\n",
      "0.6104275\n",
      "step: 3\n",
      "model training accuracy:\n",
      "0.53\n",
      "model test accuracy:\n",
      "0.6104275\n",
      "step: 4\n",
      "model training accuracy:\n",
      "0.53\n",
      "model test accuracy:\n",
      "0.6104275\n",
      "step: 5\n",
      "model training accuracy:\n",
      "0.56\n",
      "model test accuracy:\n",
      "0.5682718\n",
      "step: 6\n",
      "model training accuracy:\n",
      "0.56\n",
      "model test accuracy:\n",
      "0.5682718\n",
      "step: 7\n",
      "model training accuracy:\n",
      "0.56\n",
      "model test accuracy:\n",
      "0.5682718\n",
      "step: 8\n",
      "model training accuracy:\n",
      "0.56\n",
      "model test accuracy:\n",
      "0.5682718\n",
      "step: 9\n",
      "model training accuracy:\n",
      "0.56\n",
      "model test accuracy:\n",
      "0.5682718\n",
      "step: 10\n",
      "model training accuracy:\n",
      "0.52\n",
      "model test accuracy:\n",
      "0.5043219\n",
      "step: 11\n",
      "model training accuracy:\n",
      "0.52\n",
      "model test accuracy:\n",
      "0.5043219\n",
      "step: 12\n",
      "model training accuracy:\n",
      "0.52\n",
      "model test accuracy:\n",
      "0.5043219\n",
      "step: 13\n",
      "model training accuracy:\n",
      "0.52\n",
      "model test accuracy:\n",
      "0.5043219\n",
      "step: 14\n",
      "model training accuracy:\n",
      "0.52\n",
      "model test accuracy:\n",
      "0.5043219\n",
      "step: 15\n",
      "model training accuracy:\n",
      "0.52\n",
      "model test accuracy:\n",
      "0.45026213\n",
      "step: 16\n",
      "model training accuracy:\n",
      "0.52\n",
      "model test accuracy:\n",
      "0.45026213\n",
      "step: 17\n",
      "model training accuracy:\n",
      "0.52\n",
      "model test accuracy:\n",
      "0.45026213\n",
      "step: 18\n",
      "model training accuracy:\n",
      "0.52\n",
      "model test accuracy:\n",
      "0.45026213\n",
      "step: 19\n",
      "model training accuracy:\n",
      "0.52\n",
      "model test accuracy:\n",
      "0.45026213\n",
      "step: 20\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.4276756\n",
      "step: 21\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.4276756\n",
      "step: 22\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.4276756\n",
      "step: 23\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.4276756\n",
      "step: 24\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.4276756\n",
      "step: 25\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.43610463\n",
      "step: 26\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.43610463\n",
      "step: 27\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.43610463\n",
      "step: 28\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.43610463\n",
      "step: 29\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.43610463\n",
      "step: 30\n",
      "model training accuracy:\n",
      "0.53\n",
      "model test accuracy:\n",
      "0.45430058\n",
      "step: 31\n",
      "model training accuracy:\n",
      "0.53\n",
      "model test accuracy:\n",
      "0.45430058\n",
      "step: 32\n",
      "model training accuracy:\n",
      "0.53\n",
      "model test accuracy:\n",
      "0.45430058\n",
      "step: 33\n",
      "model training accuracy:\n",
      "0.53\n",
      "model test accuracy:\n",
      "0.45430058\n",
      "step: 34\n",
      "model training accuracy:\n",
      "0.53\n",
      "model test accuracy:\n",
      "0.45430058\n",
      "step: 35\n",
      "model training accuracy:\n",
      "0.46\n",
      "model test accuracy:\n",
      "0.45830736\n",
      "step: 36\n",
      "model training accuracy:\n",
      "0.46\n",
      "model test accuracy:\n",
      "0.45830736\n",
      "step: 37\n",
      "model training accuracy:\n",
      "0.46\n",
      "model test accuracy:\n",
      "0.45830736\n",
      "step: 38\n",
      "model training accuracy:\n",
      "0.46\n",
      "model test accuracy:\n",
      "0.45830736\n",
      "step: 39\n",
      "model training accuracy:\n",
      "0.46\n",
      "model test accuracy:\n",
      "0.45830736\n",
      "step: 40\n",
      "model training accuracy:\n",
      "0.45\n",
      "model test accuracy:\n",
      "0.47588015\n",
      "step: 41\n",
      "model training accuracy:\n",
      "0.45\n",
      "model test accuracy:\n",
      "0.47588015\n",
      "step: 42\n",
      "model training accuracy:\n",
      "0.45\n",
      "model test accuracy:\n",
      "0.47588015\n",
      "step: 43\n",
      "model training accuracy:\n",
      "0.45\n",
      "model test accuracy:\n",
      "0.47588015\n",
      "step: 44\n",
      "model training accuracy:\n",
      "0.45\n",
      "model test accuracy:\n",
      "0.47588015\n",
      "step: 45\n",
      "model training accuracy:\n",
      "0.48\n",
      "model test accuracy:\n",
      "0.44608635\n",
      "step: 46\n",
      "model training accuracy:\n",
      "0.48\n",
      "model test accuracy:\n",
      "0.44608635\n",
      "step: 47\n",
      "model training accuracy:\n",
      "0.48\n",
      "model test accuracy:\n",
      "0.44608635\n",
      "step: 48\n",
      "model training accuracy:\n",
      "0.48\n",
      "model test accuracy:\n",
      "0.44608635\n",
      "step: 49\n",
      "model training accuracy:\n",
      "0.48\n",
      "model test accuracy:\n",
      "0.44608635\n",
      "step: 50\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.48316133\n",
      "step: 51\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.48316133\n",
      "step: 52\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.48316133\n",
      "step: 53\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.48316133\n",
      "step: 54\n",
      "model training accuracy:\n",
      "0.49\n",
      "model test accuracy:\n",
      "0.48316133\n",
      "step: 55\n",
      "model training accuracy:\n",
      "0.51\n",
      "model test accuracy:\n",
      "0.47460204\n",
      "step: 56\n",
      "model training accuracy:\n",
      "0.51\n",
      "model test accuracy:\n",
      "0.47460204\n",
      "step: 57\n",
      "model training accuracy:\n",
      "0.51\n",
      "model test accuracy:\n",
      "0.47460204\n",
      "step: 58\n",
      "model training accuracy:\n",
      "0.51\n",
      "model test accuracy:\n",
      "0.47460204\n",
      "step: 59\n",
      "model training accuracy:\n",
      "0.51\n",
      "model test accuracy:\n",
      "0.47460204\n",
      "step: 60\n",
      "model training accuracy:\n",
      "0.4\n",
      "model test accuracy:\n",
      "0.45724407\n",
      "step: 61\n",
      "model training accuracy:\n",
      "0.4\n",
      "model test accuracy:\n",
      "0.45724407\n",
      "step: 62\n",
      "model training accuracy:\n",
      "0.4\n",
      "model test accuracy:\n",
      "0.45724407\n",
      "step: 63\n",
      "model training accuracy:\n",
      "0.4\n",
      "model test accuracy:\n",
      "0.45724407\n",
      "step: 64\n",
      "model training accuracy:\n",
      "0.4\n",
      "model test accuracy:\n",
      "0.45724407\n",
      "step: 65\n",
      "model training accuracy:\n",
      "0.56\n",
      "model test accuracy:\n",
      "0.44176975\n",
      "step: 66\n",
      "model training accuracy:\n",
      "0.56\n",
      "model test accuracy:\n",
      "0.44176975\n",
      "step: 67\n",
      "model training accuracy:\n",
      "0.56\n",
      "model test accuracy:\n",
      "0.44176975\n",
      "step: 68\n",
      "model training accuracy:\n",
      "0.56\n",
      "model test accuracy:\n",
      "0.44176975\n",
      "step: 69\n",
      "model training accuracy:\n",
      "0.56\n",
      "model test accuracy:\n",
      "0.44176975\n",
      "step: 70\n",
      "model training accuracy:\n",
      "0.47\n",
      "model test accuracy:\n",
      "0.43364352\n",
      "step: 71\n",
      "model training accuracy:\n",
      "0.47\n",
      "model test accuracy:\n",
      "0.43364352\n",
      "step: 72\n",
      "model training accuracy:\n",
      "0.47\n",
      "model test accuracy:\n",
      "0.43364352\n",
      "step: 73\n",
      "model training accuracy:\n",
      "0.47\n",
      "model test accuracy:\n",
      "0.43364352\n",
      "step: 74\n",
      "model training accuracy:\n",
      "0.47\n",
      "model test accuracy:\n",
      "0.43364352\n",
      "step: 75\n",
      "model training accuracy:\n",
      "0.47\n",
      "model test accuracy:\n",
      "0.4812671\n",
      "step: 76\n",
      "model training accuracy:\n",
      "0.47\n",
      "model test accuracy:\n",
      "0.4812671\n",
      "step: 77\n",
      "model training accuracy:\n",
      "0.47\n",
      "model test accuracy:\n",
      "0.4812671\n",
      "step: 78\n",
      "model training accuracy:\n",
      "0.47\n",
      "model test accuracy:\n",
      "0.4812671\n",
      "step: 79\n",
      "model training accuracy:\n",
      "0.47\n",
      "model test accuracy:\n",
      "0.4812671\n",
      "step: 80\n",
      "model training accuracy:\n",
      "0.54\n",
      "model test accuracy:\n",
      "0.4805594\n",
      "step: 81\n",
      "model training accuracy:\n",
      "0.54\n",
      "model test accuracy:\n",
      "0.4805594\n",
      "step: 82\n",
      "model training accuracy:\n",
      "0.54\n",
      "model test accuracy:\n",
      "0.4805594\n",
      "step: 83\n",
      "model training accuracy:\n",
      "0.54\n",
      "model test accuracy:\n",
      "0.4805594\n",
      "step: 84\n",
      "model training accuracy:\n",
      "0.54\n",
      "model test accuracy:\n",
      "0.4805594\n",
      "step: 85\n",
      "model training accuracy:\n",
      "0.54\n",
      "model test accuracy:\n",
      "0.5142719\n",
      "step: 86\n",
      "model training accuracy:\n",
      "0.54\n",
      "model test accuracy:\n",
      "0.5142719\n",
      "step: 87\n",
      "model training accuracy:\n",
      "0.54\n",
      "model test accuracy:\n",
      "0.5142719\n",
      "step: 88\n",
      "model training accuracy:\n",
      "0.54\n",
      "model test accuracy:\n",
      "0.5142719\n",
      "step: 89\n",
      "model training accuracy:\n",
      "0.54\n",
      "model test accuracy:\n",
      "0.5142719\n",
      "step: 90\n",
      "model training accuracy:\n",
      "0.42\n",
      "model test accuracy:\n",
      "0.5287604\n",
      "step: 91\n",
      "model training accuracy:\n",
      "0.42\n",
      "model test accuracy:\n",
      "0.5287604\n",
      "step: 92\n",
      "model training accuracy:\n",
      "0.42\n",
      "model test accuracy:\n",
      "0.5287604\n",
      "step: 93\n",
      "model training accuracy:\n",
      "0.42\n",
      "model test accuracy:\n",
      "0.5287604\n",
      "step: 94\n",
      "model training accuracy:\n",
      "0.42\n",
      "model test accuracy:\n",
      "0.5287604\n",
      "step: 95\n",
      "model training accuracy:\n",
      "0.48\n",
      "model test accuracy:\n",
      "0.4340484\n",
      "step: 96\n",
      "model training accuracy:\n",
      "0.48\n",
      "model test accuracy:\n",
      "0.4340484\n",
      "step: 97\n",
      "model training accuracy:\n",
      "0.48\n",
      "model test accuracy:\n",
      "0.4340484\n",
      "step: 98\n",
      "model training accuracy:\n",
      "0.48\n",
      "model test accuracy:\n",
      "0.4340484\n",
      "step: 99\n",
      "model training accuracy:\n",
      "0.48\n",
      "model test accuracy:\n",
      "0.4340484\n",
      "step: 100\n",
      "model training accuracy:\n",
      "0.57\n",
      "model test accuracy:\n",
      "0.21248579\n",
      "step: 101\n",
      "model training accuracy:\n",
      "0.57\n",
      "model test accuracy:\n",
      "0.21248579\n",
      "step: 102\n",
      "model training accuracy:\n",
      "0.57\n",
      "model test accuracy:\n",
      "0.21248579\n",
      "step: 103\n",
      "model training accuracy:\n",
      "0.57\n",
      "model test accuracy:\n",
      "0.21248579\n",
      "step: 104\n",
      "model training accuracy:\n",
      "0.57\n",
      "model test accuracy:\n",
      "0.21248579\n",
      "step: 105\n",
      "model training accuracy:\n",
      "0.8113000133633613\n",
      "model test accuracy:\n",
      "0.9019845005099487\n",
      "step: 106\n",
      "model training accuracy:\n",
      "0.8113000133633613\n",
      "model test accuracy:\n",
      "0.9019845005099487\n",
      "step: 107\n",
      "model training accuracy:\n",
      "0.8113000133633613\n",
      "model test accuracy:\n",
      "0.9019845005099487\n",
      "step: 108\n",
      "model training accuracy:\n",
      "0.8113000133633613\n",
      "model test accuracy:\n",
      "0.9019845005099487\n",
      "step: 109\n",
      "model training accuracy:\n",
      "0.8113000133633613\n",
      "model test accuracy:\n",
      "0.9019845005099487\n",
      "step: 110\n",
      "model training accuracy:\n",
      "0.8283999970555306\n",
      "model test accuracy:\n",
      "0.9032297577666608\n",
      "step: 111\n",
      "model training accuracy:\n",
      "0.8283999970555306\n",
      "model test accuracy:\n",
      "0.9032297577666608\n",
      "step: 112\n",
      "model training accuracy:\n",
      "0.8283999970555306\n",
      "model test accuracy:\n",
      "0.9032297577666608\n",
      "step: 113\n",
      "model training accuracy:\n",
      "0.8283999970555306\n",
      "model test accuracy:\n",
      "0.9032297577666608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 114\n",
      "model training accuracy:\n",
      "0.8283999970555306\n",
      "model test accuracy:\n",
      "0.9032297577666608\n",
      "step: 115\n",
      "model training accuracy:\n",
      "0.9462000036239623\n",
      "model test accuracy:\n",
      "0.9029433907712807\n",
      "step: 116\n",
      "model training accuracy:\n",
      "0.9462000036239623\n",
      "model test accuracy:\n",
      "0.9029433907712807\n",
      "step: 117\n",
      "model training accuracy:\n",
      "0.9462000036239623\n",
      "model test accuracy:\n",
      "0.9029433907712807\n",
      "step: 118\n",
      "model training accuracy:\n",
      "0.9462000036239623\n",
      "model test accuracy:\n",
      "0.9029433907712807\n",
      "step: 119\n",
      "model training accuracy:\n",
      "0.9462000036239623\n",
      "model test accuracy:\n",
      "0.9029433907712807\n",
      "step: 120\n",
      "model training accuracy:\n",
      "0.7885000067949295\n",
      "model test accuracy:\n",
      "0.9027684129060775\n",
      "step: 121\n",
      "model training accuracy:\n",
      "0.7885000067949295\n",
      "model test accuracy:\n",
      "0.9027684129060775\n",
      "step: 122\n",
      "model training accuracy:\n",
      "0.7885000067949295\n",
      "model test accuracy:\n",
      "0.9027684129060775\n",
      "step: 123\n",
      "model training accuracy:\n",
      "0.7885000067949295\n",
      "model test accuracy:\n",
      "0.9027684129060775\n",
      "step: 124\n",
      "model training accuracy:\n",
      "0.7885000067949295\n",
      "model test accuracy:\n",
      "0.9027684129060775\n",
      "step: 125\n",
      "model training accuracy:\n",
      "0.9101000040769577\n",
      "model test accuracy:\n",
      "0.9085158575288467\n",
      "step: 126\n",
      "model training accuracy:\n",
      "0.9101000040769577\n",
      "model test accuracy:\n",
      "0.9085158575288467\n",
      "step: 127\n",
      "model training accuracy:\n",
      "0.9101000040769577\n",
      "model test accuracy:\n",
      "0.9085158575288467\n",
      "step: 128\n",
      "model training accuracy:\n",
      "0.9101000040769577\n",
      "model test accuracy:\n",
      "0.9085158575288467\n",
      "step: 129\n",
      "model training accuracy:\n",
      "0.9101000040769577\n",
      "model test accuracy:\n",
      "0.9085158575288467\n",
      "step: 130\n",
      "model training accuracy:\n",
      "0.9272000443935394\n",
      "model test accuracy:\n",
      "0.9015856939321418\n",
      "step: 131\n",
      "model training accuracy:\n",
      "0.9272000443935394\n",
      "model test accuracy:\n",
      "0.9015856939321418\n",
      "step: 132\n",
      "model training accuracy:\n",
      "0.9272000443935394\n",
      "model test accuracy:\n",
      "0.9015856939321418\n",
      "step: 133\n",
      "model training accuracy:\n",
      "0.9272000443935394\n",
      "model test accuracy:\n",
      "0.9015856939321418\n",
      "step: 134\n",
      "model training accuracy:\n",
      "0.9272000443935394\n",
      "model test accuracy:\n",
      "0.9015856939321418\n",
      "step: 135\n",
      "model training accuracy:\n",
      "0.7942000126838684\n",
      "model test accuracy:\n",
      "0.9058189155058706\n",
      "step: 136\n",
      "model training accuracy:\n",
      "0.7942000126838684\n",
      "model test accuracy:\n",
      "0.9058189155058706\n",
      "step: 137\n",
      "model training accuracy:\n",
      "0.7942000126838684\n",
      "model test accuracy:\n",
      "0.9058189155058706\n",
      "step: 138\n",
      "model training accuracy:\n",
      "0.7942000126838684\n",
      "model test accuracy:\n",
      "0.9058189155058706\n",
      "step: 139\n",
      "model training accuracy:\n",
      "0.7942000126838684\n",
      "model test accuracy:\n",
      "0.9058189155058706\n",
      "step: 140\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.8985141779014213\n",
      "step: 141\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.8985141779014213\n",
      "step: 142\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.8985141779014213\n",
      "step: 143\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.8985141779014213\n",
      "step: 144\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.8985141779014213\n",
      "step: 145\n",
      "model training accuracy:\n",
      "0.895633960845106\n",
      "model test accuracy:\n",
      "0.9057711348102515\n",
      "step: 146\n",
      "model training accuracy:\n",
      "0.895633960845106\n",
      "model test accuracy:\n",
      "0.9057711348102515\n",
      "step: 147\n",
      "model training accuracy:\n",
      "0.895633960845106\n",
      "model test accuracy:\n",
      "0.9057711348102515\n",
      "step: 148\n",
      "model training accuracy:\n",
      "0.895633960845106\n",
      "model test accuracy:\n",
      "0.9057711348102515\n",
      "step: 149\n",
      "model training accuracy:\n",
      "0.895633960845106\n",
      "model test accuracy:\n",
      "0.9057711348102515\n",
      "step: 150\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9100512878239064\n",
      "step: 151\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9100512878239064\n",
      "step: 152\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9100512878239064\n",
      "step: 153\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9100512878239064\n",
      "step: 154\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9100512878239064\n",
      "step: 155\n",
      "model training accuracy:\n",
      "0.8796999934315681\n",
      "model test accuracy:\n",
      "0.907529084875527\n",
      "step: 156\n",
      "model training accuracy:\n",
      "0.8796999934315681\n",
      "model test accuracy:\n",
      "0.907529084875527\n",
      "step: 157\n",
      "model training accuracy:\n",
      "0.8796999934315681\n",
      "model test accuracy:\n",
      "0.907529084875527\n",
      "step: 158\n",
      "model training accuracy:\n",
      "0.8796999934315681\n",
      "model test accuracy:\n",
      "0.907529084875527\n",
      "step: 159\n",
      "model training accuracy:\n",
      "0.8796999934315681\n",
      "model test accuracy:\n",
      "0.907529084875527\n",
      "step: 160\n",
      "model training accuracy:\n",
      "0.8435999825596809\n",
      "model test accuracy:\n",
      "0.9059361474171894\n",
      "step: 161\n",
      "model training accuracy:\n",
      "0.8435999825596809\n",
      "model test accuracy:\n",
      "0.9059361474171894\n",
      "step: 162\n",
      "model training accuracy:\n",
      "0.8435999825596809\n",
      "model test accuracy:\n",
      "0.9059361474171894\n",
      "step: 163\n",
      "model training accuracy:\n",
      "0.8435999825596809\n",
      "model test accuracy:\n",
      "0.9059361474171894\n",
      "step: 164\n",
      "model training accuracy:\n",
      "0.8435999825596809\n",
      "model test accuracy:\n",
      "0.9059361474171894\n",
      "step: 165\n",
      "model training accuracy:\n",
      "0.8113000133633613\n",
      "model test accuracy:\n",
      "0.9050208469119407\n",
      "step: 166\n",
      "model training accuracy:\n",
      "0.8113000133633613\n",
      "model test accuracy:\n",
      "0.9050208469119407\n",
      "step: 167\n",
      "model training accuracy:\n",
      "0.8113000133633613\n",
      "model test accuracy:\n",
      "0.9050208469119407\n",
      "step: 168\n",
      "model training accuracy:\n",
      "0.8113000133633613\n",
      "model test accuracy:\n",
      "0.9050208469119407\n",
      "step: 169\n",
      "model training accuracy:\n",
      "0.8113000133633613\n",
      "model test accuracy:\n",
      "0.9050208469119407\n",
      "step: 170\n",
      "model training accuracy:\n",
      "0.8834999841451645\n",
      "model test accuracy:\n",
      "0.9067306147321644\n",
      "step: 171\n",
      "model training accuracy:\n",
      "0.8834999841451645\n",
      "model test accuracy:\n",
      "0.9067306147321644\n",
      "step: 172\n",
      "model training accuracy:\n",
      "0.8834999841451645\n",
      "model test accuracy:\n",
      "0.9067306147321644\n",
      "step: 173\n",
      "model training accuracy:\n",
      "0.8834999841451645\n",
      "model test accuracy:\n",
      "0.9067306147321644\n",
      "step: 174\n",
      "model training accuracy:\n",
      "0.8834999841451645\n",
      "model test accuracy:\n",
      "0.9067306147321644\n",
      "step: 175\n",
      "model training accuracy:\n",
      "0.8758999800682068\n",
      "model test accuracy:\n",
      "0.9045485355998643\n",
      "step: 176\n",
      "model training accuracy:\n",
      "0.8758999800682068\n",
      "model test accuracy:\n",
      "0.9045485355998643\n",
      "step: 177\n",
      "model training accuracy:\n",
      "0.8758999800682068\n",
      "model test accuracy:\n",
      "0.9045485355998643\n",
      "step: 178\n",
      "model training accuracy:\n",
      "0.8758999800682068\n",
      "model test accuracy:\n",
      "0.9045485355998643\n",
      "step: 179\n",
      "model training accuracy:\n",
      "0.8758999800682068\n",
      "model test accuracy:\n",
      "0.9045485355998643\n",
      "step: 180\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9076620149597628\n",
      "step: 181\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9076620149597628\n",
      "step: 182\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9076620149597628\n",
      "step: 183\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9076620149597628\n",
      "step: 184\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9076620149597628\n",
      "step: 185\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9084842566874244\n",
      "step: 186\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9084842566874244\n",
      "step: 187\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9084842566874244\n",
      "step: 188\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9084842566874244\n",
      "step: 189\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9084842566874244\n",
      "step: 190\n",
      "model training accuracy:\n",
      "0.9689999932050704\n",
      "model test accuracy:\n",
      "0.9062758320552885\n",
      "step: 191\n",
      "model training accuracy:\n",
      "0.9689999932050704\n",
      "model test accuracy:\n",
      "0.9062758320552885\n",
      "step: 192\n",
      "model training accuracy:\n",
      "0.9689999932050704\n",
      "model test accuracy:\n",
      "0.9062758320552885\n",
      "step: 193\n",
      "model training accuracy:\n",
      "0.9689999932050704\n",
      "model test accuracy:\n",
      "0.9062758320552885\n",
      "step: 194\n",
      "model training accuracy:\n",
      "0.9689999932050704\n",
      "model test accuracy:\n",
      "0.9062758320552885\n",
      "step: 195\n",
      "model training accuracy:\n",
      "0.7467000183463097\n",
      "model test accuracy:\n",
      "0.9062488219110209\n",
      "step: 196\n",
      "model training accuracy:\n",
      "0.7467000183463097\n",
      "model test accuracy:\n",
      "0.9062488219110209\n",
      "step: 197\n",
      "model training accuracy:\n",
      "0.7467000183463097\n",
      "model test accuracy:\n",
      "0.9062488219110209\n",
      "step: 198\n",
      "model training accuracy:\n",
      "0.7467000183463097\n",
      "model test accuracy:\n",
      "0.9062488219110209\n",
      "step: 199\n",
      "model training accuracy:\n",
      "0.7467000183463097\n",
      "model test accuracy:\n",
      "0.9062488219110209\n",
      "step: 200\n",
      "model training accuracy:\n",
      "0.8872999918460847\n",
      "model test accuracy:\n",
      "0.9029117573494033\n",
      "step: 201\n",
      "model training accuracy:\n",
      "0.8872999918460847\n",
      "model test accuracy:\n",
      "0.9029117573494033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 202\n",
      "model training accuracy:\n",
      "0.8872999918460847\n",
      "model test accuracy:\n",
      "0.9029117573494033\n",
      "step: 203\n",
      "model training accuracy:\n",
      "0.8872999918460847\n",
      "model test accuracy:\n",
      "0.9029117573494033\n",
      "step: 204\n",
      "model training accuracy:\n",
      "0.8872999918460847\n",
      "model test accuracy:\n",
      "0.9029117573494033\n",
      "step: 205\n",
      "model training accuracy:\n",
      "0.9272000443935394\n",
      "model test accuracy:\n",
      "0.9033442866724385\n",
      "step: 206\n",
      "model training accuracy:\n",
      "0.9272000443935394\n",
      "model test accuracy:\n",
      "0.9033442866724385\n",
      "step: 207\n",
      "model training accuracy:\n",
      "0.9272000443935394\n",
      "model test accuracy:\n",
      "0.9033442866724385\n",
      "step: 208\n",
      "model training accuracy:\n",
      "0.9272000443935394\n",
      "model test accuracy:\n",
      "0.9033442866724385\n",
      "step: 209\n",
      "model training accuracy:\n",
      "0.9272000443935394\n",
      "model test accuracy:\n",
      "0.9033442866724385\n",
      "step: 210\n",
      "model training accuracy:\n",
      "0.9119999909400939\n",
      "model test accuracy:\n",
      "0.9009820582761088\n",
      "step: 211\n",
      "model training accuracy:\n",
      "0.9119999909400939\n",
      "model test accuracy:\n",
      "0.9009820582761088\n",
      "step: 212\n",
      "model training accuracy:\n",
      "0.9119999909400939\n",
      "model test accuracy:\n",
      "0.9009820582761088\n",
      "step: 213\n",
      "model training accuracy:\n",
      "0.9119999909400939\n",
      "model test accuracy:\n",
      "0.9009820582761088\n",
      "step: 214\n",
      "model training accuracy:\n",
      "0.9119999909400939\n",
      "model test accuracy:\n",
      "0.9009820582761088\n",
      "step: 215\n",
      "model training accuracy:\n",
      "0.9081999945640564\n",
      "model test accuracy:\n",
      "0.9112393155644477\n",
      "step: 216\n",
      "model training accuracy:\n",
      "0.9081999945640564\n",
      "model test accuracy:\n",
      "0.9112393155644477\n",
      "step: 217\n",
      "model training accuracy:\n",
      "0.9081999945640564\n",
      "model test accuracy:\n",
      "0.9112393155644477\n",
      "step: 218\n",
      "model training accuracy:\n",
      "0.9081999945640564\n",
      "model test accuracy:\n",
      "0.9112393155644477\n",
      "step: 219\n",
      "model training accuracy:\n",
      "0.9081999945640564\n",
      "model test accuracy:\n",
      "0.9112393155644477\n",
      "step: 220\n",
      "model training accuracy:\n",
      "0.8454999920725823\n",
      "model test accuracy:\n",
      "0.9019580340464408\n",
      "step: 221\n",
      "model training accuracy:\n",
      "0.8454999920725823\n",
      "model test accuracy:\n",
      "0.9019580340464408\n",
      "step: 222\n",
      "model training accuracy:\n",
      "0.8454999920725823\n",
      "model test accuracy:\n",
      "0.9019580340464408\n",
      "step: 223\n",
      "model training accuracy:\n",
      "0.8454999920725823\n",
      "model test accuracy:\n",
      "0.9019580340464408\n",
      "step: 224\n",
      "model training accuracy:\n",
      "0.8454999920725823\n",
      "model test accuracy:\n",
      "0.9019580340464408\n",
      "step: 225\n",
      "model training accuracy:\n",
      "0.8075\n",
      "model test accuracy:\n",
      "0.9092853923597753\n",
      "step: 226\n",
      "model training accuracy:\n",
      "0.8075\n",
      "model test accuracy:\n",
      "0.9092853923597753\n",
      "step: 227\n",
      "model training accuracy:\n",
      "0.8075\n",
      "model test accuracy:\n",
      "0.9092853923597753\n",
      "step: 228\n",
      "model training accuracy:\n",
      "0.8075\n",
      "model test accuracy:\n",
      "0.9092853923597753\n",
      "step: 229\n",
      "model training accuracy:\n",
      "0.8075\n",
      "model test accuracy:\n",
      "0.9092853923597753\n",
      "step: 230\n",
      "model training accuracy:\n",
      "0.8150999927520751\n",
      "model test accuracy:\n",
      "0.9103120725222473\n",
      "step: 231\n",
      "model training accuracy:\n",
      "0.8150999927520751\n",
      "model test accuracy:\n",
      "0.9103120725222473\n",
      "step: 232\n",
      "model training accuracy:\n",
      "0.8150999927520751\n",
      "model test accuracy:\n",
      "0.9103120725222473\n",
      "step: 233\n",
      "model training accuracy:\n",
      "0.8150999927520751\n",
      "model test accuracy:\n",
      "0.9103120725222473\n",
      "step: 234\n",
      "model training accuracy:\n",
      "0.8150999927520751\n",
      "model test accuracy:\n",
      "0.9103120725222473\n",
      "step: 235\n",
      "model training accuracy:\n",
      "0.8720999836921691\n",
      "model test accuracy:\n",
      "0.9015638311774142\n",
      "step: 236\n",
      "model training accuracy:\n",
      "0.8720999836921691\n",
      "model test accuracy:\n",
      "0.9015638311774142\n",
      "step: 237\n",
      "model training accuracy:\n",
      "0.8720999836921691\n",
      "model test accuracy:\n",
      "0.9015638311774142\n",
      "step: 238\n",
      "model training accuracy:\n",
      "0.8720999836921691\n",
      "model test accuracy:\n",
      "0.9015638311774142\n",
      "step: 239\n",
      "model training accuracy:\n",
      "0.8720999836921691\n",
      "model test accuracy:\n",
      "0.9015638311774142\n",
      "step: 240\n",
      "model training accuracy:\n",
      "0.7865999802947043\n",
      "model test accuracy:\n",
      "0.902045524394837\n",
      "step: 241\n",
      "model training accuracy:\n",
      "0.7865999802947043\n",
      "model test accuracy:\n",
      "0.902045524394837\n",
      "step: 242\n",
      "model training accuracy:\n",
      "0.7865999802947043\n",
      "model test accuracy:\n",
      "0.902045524394837\n",
      "step: 243\n",
      "model training accuracy:\n",
      "0.7865999802947043\n",
      "model test accuracy:\n",
      "0.902045524394837\n",
      "step: 244\n",
      "model training accuracy:\n",
      "0.7865999802947043\n",
      "model test accuracy:\n",
      "0.902045524394837\n",
      "step: 245\n",
      "model training accuracy:\n",
      "0.9975000226497649\n",
      "model test accuracy:\n",
      "0.9076850318236472\n",
      "step: 246\n",
      "model training accuracy:\n",
      "0.9975000226497649\n",
      "model test accuracy:\n",
      "0.9076850318236472\n",
      "step: 247\n",
      "model training accuracy:\n",
      "0.9975000226497649\n",
      "model test accuracy:\n",
      "0.9076850318236472\n",
      "step: 248\n",
      "model training accuracy:\n",
      "0.9975000226497649\n",
      "model test accuracy:\n",
      "0.9076850318236472\n",
      "step: 249\n",
      "model training accuracy:\n",
      "0.9975000226497649\n",
      "model test accuracy:\n",
      "0.9076850318236472\n",
      "step: 250\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9051568656065946\n",
      "step: 251\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9051568656065946\n",
      "step: 252\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9051568656065946\n",
      "step: 253\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9051568656065946\n",
      "step: 254\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9051568656065946\n",
      "step: 255\n",
      "model training accuracy:\n",
      "0.826499981880188\n",
      "model test accuracy:\n",
      "0.9099665489041514\n",
      "step: 256\n",
      "model training accuracy:\n",
      "0.826499981880188\n",
      "model test accuracy:\n",
      "0.9099665489041514\n",
      "step: 257\n",
      "model training accuracy:\n",
      "0.826499981880188\n",
      "model test accuracy:\n",
      "0.9099665489041514\n",
      "step: 258\n",
      "model training accuracy:\n",
      "0.826499981880188\n",
      "model test accuracy:\n",
      "0.9099665489041514\n",
      "step: 259\n",
      "model training accuracy:\n",
      "0.826499981880188\n",
      "model test accuracy:\n",
      "0.9099665489041514\n",
      "step: 260\n",
      "model training accuracy:\n",
      "0.8132000058889388\n",
      "model test accuracy:\n",
      "0.9056307237146206\n",
      "step: 261\n",
      "model training accuracy:\n",
      "0.8132000058889388\n",
      "model test accuracy:\n",
      "0.9056307237146206\n",
      "step: 262\n",
      "model training accuracy:\n",
      "0.8132000058889388\n",
      "model test accuracy:\n",
      "0.9056307237146206\n",
      "step: 263\n",
      "model training accuracy:\n",
      "0.8132000058889388\n",
      "model test accuracy:\n",
      "0.9056307237146206\n",
      "step: 264\n",
      "model training accuracy:\n",
      "0.8132000058889388\n",
      "model test accuracy:\n",
      "0.9056307237146206\n",
      "step: 265\n",
      "model training accuracy:\n",
      "0.8625999927520751\n",
      "model test accuracy:\n",
      "0.9030744475869442\n",
      "step: 266\n",
      "model training accuracy:\n",
      "0.8625999927520751\n",
      "model test accuracy:\n",
      "0.9030744475869442\n",
      "step: 267\n",
      "model training accuracy:\n",
      "0.8625999927520751\n",
      "model test accuracy:\n",
      "0.9030744475869442\n",
      "step: 268\n",
      "model training accuracy:\n",
      "0.8625999927520751\n",
      "model test accuracy:\n",
      "0.9030744475869442\n",
      "step: 269\n",
      "model training accuracy:\n",
      "0.8625999927520751\n",
      "model test accuracy:\n",
      "0.9030744475869442\n",
      "step: 270\n",
      "model training accuracy:\n",
      "0.8930725293186909\n",
      "model test accuracy:\n",
      "0.9077647308205864\n",
      "step: 271\n",
      "model training accuracy:\n",
      "0.8930725293186909\n",
      "model test accuracy:\n",
      "0.9077647308205864\n",
      "step: 272\n",
      "model training accuracy:\n",
      "0.8930725293186909\n",
      "model test accuracy:\n",
      "0.9077647308205864\n",
      "step: 273\n",
      "model training accuracy:\n",
      "0.8930725293186909\n",
      "model test accuracy:\n",
      "0.9077647308205864\n",
      "step: 274\n",
      "model training accuracy:\n",
      "0.8930725293186909\n",
      "model test accuracy:\n",
      "0.9077647308205864\n",
      "step: 275\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.907479100010647\n",
      "step: 276\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.907479100010647\n",
      "step: 277\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.907479100010647\n",
      "step: 278\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.907479100010647\n",
      "step: 279\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.907479100010647\n",
      "step: 280\n",
      "model training accuracy:\n",
      "0.8872999918460845\n",
      "model test accuracy:\n",
      "0.9072935106336725\n",
      "step: 281\n",
      "model training accuracy:\n",
      "0.8872999918460845\n",
      "model test accuracy:\n",
      "0.9072935106336725\n",
      "step: 282\n",
      "model training accuracy:\n",
      "0.8872999918460845\n",
      "model test accuracy:\n",
      "0.9072935106336725\n",
      "step: 283\n",
      "model training accuracy:\n",
      "0.8872999918460845\n",
      "model test accuracy:\n",
      "0.9072935106336725\n",
      "step: 284\n",
      "model training accuracy:\n",
      "0.8872999918460845\n",
      "model test accuracy:\n",
      "0.9072935106336725\n",
      "step: 285\n",
      "model training accuracy:\n",
      "0.8872999805212021\n",
      "model test accuracy:\n",
      "0.9033971137385711\n",
      "step: 286\n",
      "model training accuracy:\n",
      "0.8872999805212021\n",
      "model test accuracy:\n",
      "0.9033971137385711\n",
      "step: 287\n",
      "model training accuracy:\n",
      "0.8872999805212021\n",
      "model test accuracy:\n",
      "0.9033971137385711\n",
      "step: 288\n",
      "model training accuracy:\n",
      "0.8872999805212021\n",
      "model test accuracy:\n",
      "0.9033971137385711\n",
      "step: 289\n",
      "model training accuracy:\n",
      "0.8872999805212021\n",
      "model test accuracy:\n",
      "0.9033971137385711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 290\n",
      "model training accuracy:\n",
      "0.8944626146728448\n",
      "model test accuracy:\n",
      "0.90081591402895\n",
      "step: 291\n",
      "model training accuracy:\n",
      "0.8944626146728448\n",
      "model test accuracy:\n",
      "0.90081591402895\n",
      "step: 292\n",
      "model training accuracy:\n",
      "0.8944626146728448\n",
      "model test accuracy:\n",
      "0.90081591402895\n",
      "step: 293\n",
      "model training accuracy:\n",
      "0.8944626146728448\n",
      "model test accuracy:\n",
      "0.90081591402895\n",
      "step: 294\n",
      "model training accuracy:\n",
      "0.8944626146728448\n",
      "model test accuracy:\n",
      "0.90081591402895\n",
      "step: 295\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.8995233466839544\n",
      "step: 296\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.8995233466839544\n",
      "step: 297\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.8995233466839544\n",
      "step: 298\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.8995233466839544\n",
      "step: 299\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.8995233466839544\n",
      "step: 300\n",
      "model training accuracy:\n",
      "0.8132000115513802\n",
      "model test accuracy:\n",
      "0.907257418380919\n",
      "step: 301\n",
      "model training accuracy:\n",
      "0.8132000115513802\n",
      "model test accuracy:\n",
      "0.907257418380919\n",
      "step: 302\n",
      "model training accuracy:\n",
      "0.8132000115513802\n",
      "model test accuracy:\n",
      "0.907257418380919\n",
      "step: 303\n",
      "model training accuracy:\n",
      "0.8132000115513802\n",
      "model test accuracy:\n",
      "0.907257418380919\n",
      "step: 304\n",
      "model training accuracy:\n",
      "0.8132000115513802\n",
      "model test accuracy:\n",
      "0.907257418380919\n",
      "step: 305\n",
      "model training accuracy:\n",
      "0.925299989581108\n",
      "model test accuracy:\n",
      "0.9088983795581762\n",
      "step: 306\n",
      "model training accuracy:\n",
      "0.925299989581108\n",
      "model test accuracy:\n",
      "0.9088983795581762\n",
      "step: 307\n",
      "model training accuracy:\n",
      "0.925299989581108\n",
      "model test accuracy:\n",
      "0.9088983795581762\n",
      "step: 308\n",
      "model training accuracy:\n",
      "0.925299989581108\n",
      "model test accuracy:\n",
      "0.9088983795581762\n",
      "step: 309\n",
      "model training accuracy:\n",
      "0.925299989581108\n",
      "model test accuracy:\n",
      "0.9088983795581762\n",
      "step: 310\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9031805818814481\n",
      "step: 311\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9031805818814481\n",
      "step: 312\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9031805818814481\n",
      "step: 313\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9031805818814481\n",
      "step: 314\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9031805818814481\n",
      "step: 315\n",
      "model training accuracy:\n",
      "0.7638000133633613\n",
      "model test accuracy:\n",
      "0.9101955633196731\n",
      "step: 316\n",
      "model training accuracy:\n",
      "0.7638000133633613\n",
      "model test accuracy:\n",
      "0.9101955633196731\n",
      "step: 317\n",
      "model training accuracy:\n",
      "0.7638000133633613\n",
      "model test accuracy:\n",
      "0.9101955633196731\n",
      "step: 318\n",
      "model training accuracy:\n",
      "0.7638000133633613\n",
      "model test accuracy:\n",
      "0.9101955633196731\n",
      "step: 319\n",
      "model training accuracy:\n",
      "0.7638000133633613\n",
      "model test accuracy:\n",
      "0.9101955633196731\n",
      "step: 320\n",
      "model training accuracy:\n",
      "0.8663999891281128\n",
      "model test accuracy:\n",
      "0.9038071530828061\n",
      "step: 321\n",
      "model training accuracy:\n",
      "0.8663999891281128\n",
      "model test accuracy:\n",
      "0.9038071530828061\n",
      "step: 322\n",
      "model training accuracy:\n",
      "0.8663999891281128\n",
      "model test accuracy:\n",
      "0.9038071530828061\n",
      "step: 323\n",
      "model training accuracy:\n",
      "0.8663999891281128\n",
      "model test accuracy:\n",
      "0.9038071530828061\n",
      "step: 324\n",
      "model training accuracy:\n",
      "0.8663999891281128\n",
      "model test accuracy:\n",
      "0.9038071530828061\n",
      "step: 325\n",
      "model training accuracy:\n",
      "0.8379000163078308\n",
      "model test accuracy:\n",
      "0.9034147000380146\n",
      "step: 326\n",
      "model training accuracy:\n",
      "0.8379000163078308\n",
      "model test accuracy:\n",
      "0.9034147000380146\n",
      "step: 327\n",
      "model training accuracy:\n",
      "0.8379000163078308\n",
      "model test accuracy:\n",
      "0.9034147000380146\n",
      "step: 328\n",
      "model training accuracy:\n",
      "0.8379000163078308\n",
      "model test accuracy:\n",
      "0.9034147000380146\n",
      "step: 329\n",
      "model training accuracy:\n",
      "0.8379000163078308\n",
      "model test accuracy:\n",
      "0.9034147000380146\n",
      "step: 330\n",
      "model training accuracy:\n",
      "0.8956228562894544\n",
      "model test accuracy:\n",
      "0.9098031061283149\n",
      "step: 331\n",
      "model training accuracy:\n",
      "0.8956228562894544\n",
      "model test accuracy:\n",
      "0.9098031061283149\n",
      "step: 332\n",
      "model training accuracy:\n",
      "0.8956228562894544\n",
      "model test accuracy:\n",
      "0.9098031061283149\n",
      "step: 333\n",
      "model training accuracy:\n",
      "0.8956228562894544\n",
      "model test accuracy:\n",
      "0.9098031061283149\n",
      "step: 334\n",
      "model training accuracy:\n",
      "0.8956228562894544\n",
      "model test accuracy:\n",
      "0.9098031061283149\n",
      "step: 335\n",
      "model training accuracy:\n",
      "0.9043999868631363\n",
      "model test accuracy:\n",
      "0.9035354445082884\n",
      "step: 336\n",
      "model training accuracy:\n",
      "0.9043999868631363\n",
      "model test accuracy:\n",
      "0.9035354445082884\n",
      "step: 337\n",
      "model training accuracy:\n",
      "0.9043999868631363\n",
      "model test accuracy:\n",
      "0.9035354445082884\n",
      "step: 338\n",
      "model training accuracy:\n",
      "0.9043999868631363\n",
      "model test accuracy:\n",
      "0.9035354445082884\n",
      "step: 339\n",
      "model training accuracy:\n",
      "0.9043999868631363\n",
      "model test accuracy:\n",
      "0.9035354445082884\n",
      "step: 340\n",
      "model training accuracy:\n",
      "0.898700014948845\n",
      "model test accuracy:\n",
      "0.9079649212296336\n",
      "step: 341\n",
      "model training accuracy:\n",
      "0.898700014948845\n",
      "model test accuracy:\n",
      "0.9079649212296336\n",
      "step: 342\n",
      "model training accuracy:\n",
      "0.898700014948845\n",
      "model test accuracy:\n",
      "0.9079649212296336\n",
      "step: 343\n",
      "model training accuracy:\n",
      "0.898700014948845\n",
      "model test accuracy:\n",
      "0.9079649212296336\n",
      "step: 344\n",
      "model training accuracy:\n",
      "0.898700014948845\n",
      "model test accuracy:\n",
      "0.9079649212296336\n",
      "step: 345\n",
      "model training accuracy:\n",
      "0.8936330544183582\n",
      "model test accuracy:\n",
      "0.9115317341981118\n",
      "step: 346\n",
      "model training accuracy:\n",
      "0.8936330544183582\n",
      "model test accuracy:\n",
      "0.9115317341981118\n",
      "step: 347\n",
      "model training accuracy:\n",
      "0.8936330544183582\n",
      "model test accuracy:\n",
      "0.9115317341981118\n",
      "step: 348\n",
      "model training accuracy:\n",
      "0.8936330544183582\n",
      "model test accuracy:\n",
      "0.9115317341981118\n",
      "step: 349\n",
      "model training accuracy:\n",
      "0.8936330544183582\n",
      "model test accuracy:\n",
      "0.9115317341981118\n",
      "step: 350\n",
      "model training accuracy:\n",
      "0.7789999875426292\n",
      "model test accuracy:\n",
      "0.9075697939723998\n",
      "step: 351\n",
      "model training accuracy:\n",
      "0.7789999875426292\n",
      "model test accuracy:\n",
      "0.9075697939723998\n",
      "step: 352\n",
      "model training accuracy:\n",
      "0.7789999875426292\n",
      "model test accuracy:\n",
      "0.9075697939723998\n",
      "step: 353\n",
      "model training accuracy:\n",
      "0.7789999875426292\n",
      "model test accuracy:\n",
      "0.9075697939723998\n",
      "step: 354\n",
      "model training accuracy:\n",
      "0.7789999875426292\n",
      "model test accuracy:\n",
      "0.9075697939723998\n",
      "step: 355\n",
      "model training accuracy:\n",
      "0.895741208405148\n",
      "model test accuracy:\n",
      "0.9010140307245621\n",
      "step: 356\n",
      "model training accuracy:\n",
      "0.895741208405148\n",
      "model test accuracy:\n",
      "0.9010140307245621\n",
      "step: 357\n",
      "model training accuracy:\n",
      "0.895741208405148\n",
      "model test accuracy:\n",
      "0.9010140307245621\n",
      "step: 358\n",
      "model training accuracy:\n",
      "0.895741208405148\n",
      "model test accuracy:\n",
      "0.9010140307245621\n",
      "step: 359\n",
      "model training accuracy:\n",
      "0.895741208405148\n",
      "model test accuracy:\n",
      "0.9010140307245621\n",
      "step: 360\n",
      "model training accuracy:\n",
      "0.8834999728202819\n",
      "model test accuracy:\n",
      "0.9065103818291058\n",
      "step: 361\n",
      "model training accuracy:\n",
      "0.8834999728202819\n",
      "model test accuracy:\n",
      "0.9065103818291058\n",
      "step: 362\n",
      "model training accuracy:\n",
      "0.8834999728202819\n",
      "model test accuracy:\n",
      "0.9065103818291058\n",
      "step: 363\n",
      "model training accuracy:\n",
      "0.8834999728202819\n",
      "model test accuracy:\n",
      "0.9065103818291058\n",
      "step: 364\n",
      "model training accuracy:\n",
      "0.8834999728202819\n",
      "model test accuracy:\n",
      "0.9065103818291058\n",
      "step: 365\n",
      "model training accuracy:\n",
      "0.9366999673843384\n",
      "model test accuracy:\n",
      "0.9046185797908093\n",
      "step: 366\n",
      "model training accuracy:\n",
      "0.9366999673843384\n",
      "model test accuracy:\n",
      "0.9046185797908093\n",
      "step: 367\n",
      "model training accuracy:\n",
      "0.9366999673843384\n",
      "model test accuracy:\n",
      "0.9046185797908093\n",
      "step: 368\n",
      "model training accuracy:\n",
      "0.9366999673843384\n",
      "model test accuracy:\n",
      "0.9046185797908093\n",
      "step: 369\n",
      "model training accuracy:\n",
      "0.9366999673843384\n",
      "model test accuracy:\n",
      "0.9046185797908093\n",
      "step: 370\n",
      "model training accuracy:\n",
      "0.8873000258207321\n",
      "model test accuracy:\n",
      "0.9045342603116554\n",
      "step: 371\n",
      "model training accuracy:\n",
      "0.8873000258207321\n",
      "model test accuracy:\n",
      "0.9045342603116554\n",
      "step: 372\n",
      "model training accuracy:\n",
      "0.8873000258207321\n",
      "model test accuracy:\n",
      "0.9045342603116554\n",
      "step: 373\n",
      "model training accuracy:\n",
      "0.8873000258207321\n",
      "model test accuracy:\n",
      "0.9045342603116554\n",
      "step: 374\n",
      "model training accuracy:\n",
      "0.8873000258207321\n",
      "model test accuracy:\n",
      "0.9045342603116554\n",
      "step: 375\n",
      "model training accuracy:\n",
      "0.889200024008751\n",
      "model test accuracy:\n",
      "0.9057294899347579\n",
      "step: 376\n",
      "model training accuracy:\n",
      "0.889200024008751\n",
      "model test accuracy:\n",
      "0.9057294899347579\n",
      "step: 377\n",
      "model training accuracy:\n",
      "0.889200024008751\n",
      "model test accuracy:\n",
      "0.9057294899347579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 378\n",
      "model training accuracy:\n",
      "0.889200024008751\n",
      "model test accuracy:\n",
      "0.9057294899347579\n",
      "step: 379\n",
      "model training accuracy:\n",
      "0.889200024008751\n",
      "model test accuracy:\n",
      "0.9057294899347579\n",
      "step: 380\n",
      "model training accuracy:\n",
      "0.8550000169873236\n",
      "model test accuracy:\n",
      "0.9106703669081683\n",
      "step: 381\n",
      "model training accuracy:\n",
      "0.8550000169873236\n",
      "model test accuracy:\n",
      "0.9106703669081683\n",
      "step: 382\n",
      "model training accuracy:\n",
      "0.8550000169873236\n",
      "model test accuracy:\n",
      "0.9106703669081683\n",
      "step: 383\n",
      "model training accuracy:\n",
      "0.8550000169873236\n",
      "model test accuracy:\n",
      "0.9106703669081683\n",
      "step: 384\n",
      "model training accuracy:\n",
      "0.8550000169873236\n",
      "model test accuracy:\n",
      "0.9106703669081683\n",
      "step: 385\n",
      "model training accuracy:\n",
      "0.8283999800682067\n",
      "model test accuracy:\n",
      "0.9053964712159411\n",
      "step: 386\n",
      "model training accuracy:\n",
      "0.8283999800682067\n",
      "model test accuracy:\n",
      "0.9053964712159411\n",
      "step: 387\n",
      "model training accuracy:\n",
      "0.8283999800682067\n",
      "model test accuracy:\n",
      "0.9053964712159411\n",
      "step: 388\n",
      "model training accuracy:\n",
      "0.8283999800682067\n",
      "model test accuracy:\n",
      "0.9053964712159411\n",
      "step: 389\n",
      "model training accuracy:\n",
      "0.8283999800682067\n",
      "model test accuracy:\n",
      "0.9053964712159411\n",
      "step: 390\n",
      "model training accuracy:\n",
      "0.8341000086069107\n",
      "model test accuracy:\n",
      "0.9002704868888498\n",
      "step: 391\n",
      "model training accuracy:\n",
      "0.8341000086069107\n",
      "model test accuracy:\n",
      "0.9002704868888498\n",
      "step: 392\n",
      "model training accuracy:\n",
      "0.8341000086069107\n",
      "model test accuracy:\n",
      "0.9002704868888498\n",
      "step: 393\n",
      "model training accuracy:\n",
      "0.8341000086069107\n",
      "model test accuracy:\n",
      "0.9002704868888498\n",
      "step: 394\n",
      "model training accuracy:\n",
      "0.8341000086069107\n",
      "model test accuracy:\n",
      "0.9002704868888498\n",
      "step: 395\n",
      "model training accuracy:\n",
      "0.9614000117778778\n",
      "model test accuracy:\n",
      "0.8995405860723337\n",
      "step: 396\n",
      "model training accuracy:\n",
      "0.9614000117778778\n",
      "model test accuracy:\n",
      "0.8995405860723337\n",
      "step: 397\n",
      "model training accuracy:\n",
      "0.9614000117778778\n",
      "model test accuracy:\n",
      "0.8995405860723337\n",
      "step: 398\n",
      "model training accuracy:\n",
      "0.9614000117778778\n",
      "model test accuracy:\n",
      "0.8995405860723337\n",
      "step: 399\n",
      "model training accuracy:\n",
      "0.9614000117778778\n",
      "model test accuracy:\n",
      "0.8995405860723337\n",
      "step: 400\n",
      "model training accuracy:\n",
      "0.855\n",
      "model test accuracy:\n",
      "0.9052979150920045\n",
      "step: 401\n",
      "model training accuracy:\n",
      "0.855\n",
      "model test accuracy:\n",
      "0.9052979150920045\n",
      "step: 402\n",
      "model training accuracy:\n",
      "0.855\n",
      "model test accuracy:\n",
      "0.9052979150920045\n",
      "step: 403\n",
      "model training accuracy:\n",
      "0.855\n",
      "model test accuracy:\n",
      "0.9052979150920045\n",
      "step: 404\n",
      "model training accuracy:\n",
      "0.855\n",
      "model test accuracy:\n",
      "0.9052979150920045\n",
      "step: 405\n",
      "model training accuracy:\n",
      "0.7847000104188919\n",
      "model test accuracy:\n",
      "0.9041296898016334\n",
      "step: 406\n",
      "model training accuracy:\n",
      "0.7847000104188919\n",
      "model test accuracy:\n",
      "0.9041296898016334\n",
      "step: 407\n",
      "model training accuracy:\n",
      "0.7847000104188919\n",
      "model test accuracy:\n",
      "0.9041296898016334\n",
      "step: 408\n",
      "model training accuracy:\n",
      "0.7847000104188919\n",
      "model test accuracy:\n",
      "0.9041296898016334\n",
      "step: 409\n",
      "model training accuracy:\n",
      "0.7847000104188919\n",
      "model test accuracy:\n",
      "0.9041296898016334\n",
      "step: 410\n",
      "model training accuracy:\n",
      "0.9271999764442443\n",
      "model test accuracy:\n",
      "0.9061078253848305\n",
      "step: 411\n",
      "model training accuracy:\n",
      "0.9271999764442443\n",
      "model test accuracy:\n",
      "0.9061078253848305\n",
      "step: 412\n",
      "model training accuracy:\n",
      "0.9271999764442443\n",
      "model test accuracy:\n",
      "0.9061078253848305\n",
      "step: 413\n",
      "model training accuracy:\n",
      "0.9271999764442443\n",
      "model test accuracy:\n",
      "0.9061078253848305\n",
      "step: 414\n",
      "model training accuracy:\n",
      "0.9271999764442443\n",
      "model test accuracy:\n",
      "0.9061078253848305\n",
      "step: 415\n",
      "model training accuracy:\n",
      "0.7998999959230423\n",
      "model test accuracy:\n",
      "0.900225077765717\n",
      "step: 416\n",
      "model training accuracy:\n",
      "0.7998999959230423\n",
      "model test accuracy:\n",
      "0.900225077765717\n",
      "step: 417\n",
      "model training accuracy:\n",
      "0.7998999959230423\n",
      "model test accuracy:\n",
      "0.900225077765717\n",
      "step: 418\n",
      "model training accuracy:\n",
      "0.7998999959230423\n",
      "model test accuracy:\n",
      "0.900225077765717\n",
      "step: 419\n",
      "model training accuracy:\n",
      "0.7998999959230423\n",
      "model test accuracy:\n",
      "0.900225077765717\n",
      "step: 420\n",
      "model training accuracy:\n",
      "0.9214999932050705\n",
      "model test accuracy:\n",
      "0.9055975275727208\n",
      "step: 421\n",
      "model training accuracy:\n",
      "0.9214999932050705\n",
      "model test accuracy:\n",
      "0.9055975275727208\n",
      "step: 422\n",
      "model training accuracy:\n",
      "0.9214999932050705\n",
      "model test accuracy:\n",
      "0.9055975275727208\n",
      "step: 423\n",
      "model training accuracy:\n",
      "0.9214999932050705\n",
      "model test accuracy:\n",
      "0.9055975275727208\n",
      "step: 424\n",
      "model training accuracy:\n",
      "0.9214999932050705\n",
      "model test accuracy:\n",
      "0.9055975275727208\n",
      "step: 425\n",
      "model training accuracy:\n",
      "0.8607000058889389\n",
      "model test accuracy:\n",
      "0.8996746795953284\n",
      "step: 426\n",
      "model training accuracy:\n",
      "0.8607000058889389\n",
      "model test accuracy:\n",
      "0.8996746795953284\n",
      "step: 427\n",
      "model training accuracy:\n",
      "0.8607000058889389\n",
      "model test accuracy:\n",
      "0.8996746795953284\n",
      "step: 428\n",
      "model training accuracy:\n",
      "0.8607000058889389\n",
      "model test accuracy:\n",
      "0.8996746795953284\n",
      "step: 429\n",
      "model training accuracy:\n",
      "0.8607000058889389\n",
      "model test accuracy:\n",
      "0.8996746795953284\n",
      "step: 430\n",
      "model training accuracy:\n",
      "0.7638000133633613\n",
      "model test accuracy:\n",
      "0.9048090665363858\n",
      "step: 431\n",
      "model training accuracy:\n",
      "0.7638000133633613\n",
      "model test accuracy:\n",
      "0.9048090665363858\n",
      "step: 432\n",
      "model training accuracy:\n",
      "0.7638000133633613\n",
      "model test accuracy:\n",
      "0.9048090665363858\n",
      "step: 433\n",
      "model training accuracy:\n",
      "0.7638000133633613\n",
      "model test accuracy:\n",
      "0.9048090665363858\n",
      "step: 434\n",
      "model training accuracy:\n",
      "0.7638000133633613\n",
      "model test accuracy:\n",
      "0.9048090665363858\n",
      "step: 435\n",
      "model training accuracy:\n",
      "0.8037000149488449\n",
      "model test accuracy:\n",
      "0.9060925377667257\n",
      "step: 436\n",
      "model training accuracy:\n",
      "0.8037000149488449\n",
      "model test accuracy:\n",
      "0.9060925377667257\n",
      "step: 437\n",
      "model training accuracy:\n",
      "0.8037000149488449\n",
      "model test accuracy:\n",
      "0.9060925377667257\n",
      "step: 438\n",
      "model training accuracy:\n",
      "0.8037000149488449\n",
      "model test accuracy:\n",
      "0.9060925377667257\n",
      "step: 439\n",
      "model training accuracy:\n",
      "0.8037000149488449\n",
      "model test accuracy:\n",
      "0.9060925377667257\n",
      "step: 440\n",
      "model training accuracy:\n",
      "0.9442999941110611\n",
      "model test accuracy:\n",
      "0.9098767837494768\n",
      "step: 441\n",
      "model training accuracy:\n",
      "0.9442999941110611\n",
      "model test accuracy:\n",
      "0.9098767837494768\n",
      "step: 442\n",
      "model training accuracy:\n",
      "0.9442999941110611\n",
      "model test accuracy:\n",
      "0.9098767837494768\n",
      "step: 443\n",
      "model training accuracy:\n",
      "0.9442999941110611\n",
      "model test accuracy:\n",
      "0.9098767837494768\n",
      "step: 444\n",
      "model training accuracy:\n",
      "0.9442999941110611\n",
      "model test accuracy:\n",
      "0.9098767837494768\n",
      "step: 445\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9013242131572224\n",
      "step: 446\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9013242131572224\n",
      "step: 447\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9013242131572224\n",
      "step: 448\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9013242131572224\n",
      "step: 449\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9013242131572224\n",
      "step: 450\n",
      "model training accuracy:\n",
      "0.9005999678373336\n",
      "model test accuracy:\n",
      "0.9039567771310528\n",
      "step: 451\n",
      "model training accuracy:\n",
      "0.9005999678373336\n",
      "model test accuracy:\n",
      "0.9039567771310528\n",
      "step: 452\n",
      "model training accuracy:\n",
      "0.9005999678373336\n",
      "model test accuracy:\n",
      "0.9039567771310528\n",
      "step: 453\n",
      "model training accuracy:\n",
      "0.9005999678373336\n",
      "model test accuracy:\n",
      "0.9039567771310528\n",
      "step: 454\n",
      "model training accuracy:\n",
      "0.9005999678373336\n",
      "model test accuracy:\n",
      "0.9039567771310528\n",
      "step: 455\n",
      "model training accuracy:\n",
      "0.8037000206112862\n",
      "model test accuracy:\n",
      "0.9048786133231046\n",
      "step: 456\n",
      "model training accuracy:\n",
      "0.8037000206112862\n",
      "model test accuracy:\n",
      "0.9048786133231046\n",
      "step: 457\n",
      "model training accuracy:\n",
      "0.8037000206112862\n",
      "model test accuracy:\n",
      "0.9048786133231046\n",
      "step: 458\n",
      "model training accuracy:\n",
      "0.8037000206112862\n",
      "model test accuracy:\n",
      "0.9048786133231046\n",
      "step: 459\n",
      "model training accuracy:\n",
      "0.8037000206112862\n",
      "model test accuracy:\n",
      "0.9048786133231046\n",
      "step: 460\n",
      "model training accuracy:\n",
      "0.8949110455315511\n",
      "model test accuracy:\n",
      "0.9104744256748513\n",
      "step: 461\n",
      "model training accuracy:\n",
      "0.8949110455315511\n",
      "model test accuracy:\n",
      "0.9104744256748513\n",
      "step: 462\n",
      "model training accuracy:\n",
      "0.8949110455315511\n",
      "model test accuracy:\n",
      "0.9104744256748513\n",
      "step: 463\n",
      "model training accuracy:\n",
      "0.8949110455315511\n",
      "model test accuracy:\n",
      "0.9104744256748513\n",
      "step: 464\n",
      "model training accuracy:\n",
      "0.8949110455315511\n",
      "model test accuracy:\n",
      "0.9104744256748513\n",
      "step: 465\n",
      "model training accuracy:\n",
      "0.8093999981880188\n",
      "model test accuracy:\n",
      "0.9003943506245133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 466\n",
      "model training accuracy:\n",
      "0.8093999981880188\n",
      "model test accuracy:\n",
      "0.9003943506245133\n",
      "step: 467\n",
      "model training accuracy:\n",
      "0.8093999981880188\n",
      "model test accuracy:\n",
      "0.9003943506245133\n",
      "step: 468\n",
      "model training accuracy:\n",
      "0.8093999981880188\n",
      "model test accuracy:\n",
      "0.9003943506245133\n",
      "step: 469\n",
      "model training accuracy:\n",
      "0.8093999981880188\n",
      "model test accuracy:\n",
      "0.9003943506245133\n",
      "step: 470\n",
      "model training accuracy:\n",
      "0.8587999907135964\n",
      "model test accuracy:\n",
      "0.9026654091487489\n",
      "step: 471\n",
      "model training accuracy:\n",
      "0.8587999907135964\n",
      "model test accuracy:\n",
      "0.9026654091487489\n",
      "step: 472\n",
      "model training accuracy:\n",
      "0.8587999907135964\n",
      "model test accuracy:\n",
      "0.9026654091487489\n",
      "step: 473\n",
      "model training accuracy:\n",
      "0.8587999907135964\n",
      "model test accuracy:\n",
      "0.9026654091487489\n",
      "step: 474\n",
      "model training accuracy:\n",
      "0.8587999907135964\n",
      "model test accuracy:\n",
      "0.9026654091487489\n",
      "step: 475\n",
      "model training accuracy:\n",
      "0.870200042128563\n",
      "model test accuracy:\n",
      "0.9081771258612711\n",
      "step: 476\n",
      "model training accuracy:\n",
      "0.870200042128563\n",
      "model test accuracy:\n",
      "0.9081771258612711\n",
      "step: 477\n",
      "model training accuracy:\n",
      "0.870200042128563\n",
      "model test accuracy:\n",
      "0.9081771258612711\n",
      "step: 478\n",
      "model training accuracy:\n",
      "0.870200042128563\n",
      "model test accuracy:\n",
      "0.9081771258612711\n",
      "step: 479\n",
      "model training accuracy:\n",
      "0.870200042128563\n",
      "model test accuracy:\n",
      "0.9081771258612711\n",
      "step: 480\n",
      "model training accuracy:\n",
      "0.8454999977350234\n",
      "model test accuracy:\n",
      "0.901989957125189\n",
      "step: 481\n",
      "model training accuracy:\n",
      "0.8454999977350234\n",
      "model test accuracy:\n",
      "0.901989957125189\n",
      "step: 482\n",
      "model training accuracy:\n",
      "0.8454999977350234\n",
      "model test accuracy:\n",
      "0.901989957125189\n",
      "step: 483\n",
      "model training accuracy:\n",
      "0.8454999977350234\n",
      "model test accuracy:\n",
      "0.901989957125189\n",
      "step: 484\n",
      "model training accuracy:\n",
      "0.8454999977350234\n",
      "model test accuracy:\n",
      "0.901989957125189\n",
      "step: 485\n",
      "model training accuracy:\n",
      "0.7675999984145164\n",
      "model test accuracy:\n",
      "0.9072041489376169\n",
      "step: 486\n",
      "model training accuracy:\n",
      "0.7675999984145164\n",
      "model test accuracy:\n",
      "0.9072041489376169\n",
      "step: 487\n",
      "model training accuracy:\n",
      "0.7675999984145164\n",
      "model test accuracy:\n",
      "0.9072041489376169\n",
      "step: 488\n",
      "model training accuracy:\n",
      "0.7675999984145164\n",
      "model test accuracy:\n",
      "0.9072041489376169\n",
      "step: 489\n",
      "model training accuracy:\n",
      "0.7675999984145164\n",
      "model test accuracy:\n",
      "0.9072041489376169\n",
      "step: 490\n",
      "model training accuracy:\n",
      "0.7713999891281127\n",
      "model test accuracy:\n",
      "0.9026941437756218\n",
      "step: 491\n",
      "model training accuracy:\n",
      "0.7713999891281127\n",
      "model test accuracy:\n",
      "0.9026941437756218\n",
      "step: 492\n",
      "model training accuracy:\n",
      "0.7713999891281127\n",
      "model test accuracy:\n",
      "0.9026941437756218\n",
      "step: 493\n",
      "model training accuracy:\n",
      "0.7713999891281127\n",
      "model test accuracy:\n",
      "0.9026941437756218\n",
      "step: 494\n",
      "model training accuracy:\n",
      "0.7713999891281127\n",
      "model test accuracy:\n",
      "0.9026941437756218\n",
      "step: 495\n",
      "model training accuracy:\n",
      "0.8037000206112862\n",
      "model test accuracy:\n",
      "0.9111656889314231\n",
      "step: 496\n",
      "model training accuracy:\n",
      "0.8037000206112862\n",
      "model test accuracy:\n",
      "0.9111656889314231\n",
      "step: 497\n",
      "model training accuracy:\n",
      "0.8037000206112862\n",
      "model test accuracy:\n",
      "0.9111656889314231\n",
      "step: 498\n",
      "model training accuracy:\n",
      "0.8037000206112862\n",
      "model test accuracy:\n",
      "0.9111656889314231\n",
      "step: 499\n",
      "model training accuracy:\n",
      "0.8037000206112862\n",
      "model test accuracy:\n",
      "0.9111656889314231\n",
      "step: 500\n",
      "model training accuracy:\n",
      "0.9082000285387039\n",
      "model test accuracy:\n",
      "0.9102219218730004\n",
      "step: 501\n",
      "model training accuracy:\n",
      "0.9082000285387039\n",
      "model test accuracy:\n",
      "0.9102219218730004\n",
      "step: 502\n",
      "model training accuracy:\n",
      "0.9082000285387039\n",
      "model test accuracy:\n",
      "0.9102219218730004\n",
      "step: 503\n",
      "model training accuracy:\n",
      "0.9082000285387039\n",
      "model test accuracy:\n",
      "0.9102219218730004\n",
      "step: 504\n",
      "model training accuracy:\n",
      "0.9082000285387039\n",
      "model test accuracy:\n",
      "0.9102219218730004\n",
      "step: 505\n",
      "model training accuracy:\n",
      "0.845500031709671\n",
      "model test accuracy:\n",
      "0.9112397907449623\n",
      "step: 506\n",
      "model training accuracy:\n",
      "0.845500031709671\n",
      "model test accuracy:\n",
      "0.9112397907449623\n",
      "step: 507\n",
      "model training accuracy:\n",
      "0.845500031709671\n",
      "model test accuracy:\n",
      "0.9112397907449623\n",
      "step: 508\n",
      "model training accuracy:\n",
      "0.845500031709671\n",
      "model test accuracy:\n",
      "0.9112397907449623\n",
      "step: 509\n",
      "model training accuracy:\n",
      "0.845500031709671\n",
      "model test accuracy:\n",
      "0.9112397907449623\n",
      "step: 510\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9041487061226772\n",
      "step: 511\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9041487061226772\n",
      "step: 512\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9041487061226772\n",
      "step: 513\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9041487061226772\n",
      "step: 514\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9041487061226772\n",
      "step: 515\n",
      "model training accuracy:\n",
      "0.9804000049829482\n",
      "model test accuracy:\n",
      "0.9058193490291575\n",
      "step: 516\n",
      "model training accuracy:\n",
      "0.9804000049829482\n",
      "model test accuracy:\n",
      "0.9058193490291575\n",
      "step: 517\n",
      "model training accuracy:\n",
      "0.9804000049829482\n",
      "model test accuracy:\n",
      "0.9058193490291575\n",
      "step: 518\n",
      "model training accuracy:\n",
      "0.9804000049829482\n",
      "model test accuracy:\n",
      "0.9058193490291575\n",
      "step: 519\n",
      "model training accuracy:\n",
      "0.9804000049829482\n",
      "model test accuracy:\n",
      "0.9058193490291575\n",
      "step: 520\n",
      "model training accuracy:\n",
      "0.7257999929785728\n",
      "model test accuracy:\n",
      "0.906262750933601\n",
      "step: 521\n",
      "model training accuracy:\n",
      "0.7257999929785728\n",
      "model test accuracy:\n",
      "0.906262750933601\n",
      "step: 522\n",
      "model training accuracy:\n",
      "0.7257999929785728\n",
      "model test accuracy:\n",
      "0.906262750933601\n",
      "step: 523\n",
      "model training accuracy:\n",
      "0.7257999929785728\n",
      "model test accuracy:\n",
      "0.906262750933601\n",
      "step: 524\n",
      "model training accuracy:\n",
      "0.7257999929785728\n",
      "model test accuracy:\n",
      "0.906262750933601\n",
      "step: 525\n",
      "model training accuracy:\n",
      "0.9006000018119812\n",
      "model test accuracy:\n",
      "0.9068586877397302\n",
      "step: 526\n",
      "model training accuracy:\n",
      "0.9006000018119812\n",
      "model test accuracy:\n",
      "0.9068586877397302\n",
      "step: 527\n",
      "model training accuracy:\n",
      "0.9006000018119812\n",
      "model test accuracy:\n",
      "0.9068586877397302\n",
      "step: 528\n",
      "model training accuracy:\n",
      "0.9006000018119812\n",
      "model test accuracy:\n",
      "0.9068586877397302\n",
      "step: 529\n",
      "model training accuracy:\n",
      "0.9006000018119812\n",
      "model test accuracy:\n",
      "0.9068586877397302\n",
      "step: 530\n",
      "model training accuracy:\n",
      "0.7942000296711922\n",
      "model test accuracy:\n",
      "0.9092838403772223\n",
      "step: 531\n",
      "model training accuracy:\n",
      "0.7942000296711922\n",
      "model test accuracy:\n",
      "0.9092838403772223\n",
      "step: 532\n",
      "model training accuracy:\n",
      "0.7942000296711922\n",
      "model test accuracy:\n",
      "0.9092838403772223\n",
      "step: 533\n",
      "model training accuracy:\n",
      "0.7942000296711922\n",
      "model test accuracy:\n",
      "0.9092838403772223\n",
      "step: 534\n",
      "model training accuracy:\n",
      "0.7942000296711922\n",
      "model test accuracy:\n",
      "0.9092838403772223\n",
      "step: 535\n",
      "model training accuracy:\n",
      "0.9082000285387039\n",
      "model test accuracy:\n",
      "0.9000937353906044\n",
      "step: 536\n",
      "model training accuracy:\n",
      "0.9082000285387039\n",
      "model test accuracy:\n",
      "0.9000937353906044\n",
      "step: 537\n",
      "model training accuracy:\n",
      "0.9082000285387039\n",
      "model test accuracy:\n",
      "0.9000937353906044\n",
      "step: 538\n",
      "model training accuracy:\n",
      "0.9082000285387039\n",
      "model test accuracy:\n",
      "0.9000937353906044\n",
      "step: 539\n",
      "model training accuracy:\n",
      "0.9082000285387039\n",
      "model test accuracy:\n",
      "0.9000937353906044\n",
      "step: 540\n",
      "model training accuracy:\n",
      "0.8492999997735023\n",
      "model test accuracy:\n",
      "0.9083617411255784\n",
      "step: 541\n",
      "model training accuracy:\n",
      "0.8492999997735023\n",
      "model test accuracy:\n",
      "0.9083617411255784\n",
      "step: 542\n",
      "model training accuracy:\n",
      "0.8492999997735023\n",
      "model test accuracy:\n",
      "0.9083617411255784\n",
      "step: 543\n",
      "model training accuracy:\n",
      "0.8492999997735023\n",
      "model test accuracy:\n",
      "0.9083617411255784\n",
      "step: 544\n",
      "model training accuracy:\n",
      "0.8492999997735023\n",
      "model test accuracy:\n",
      "0.9083617411255784\n",
      "step: 545\n",
      "model training accuracy:\n",
      "0.8055999904870986\n",
      "model test accuracy:\n",
      "0.9027207657773934\n",
      "step: 546\n",
      "model training accuracy:\n",
      "0.8055999904870986\n",
      "model test accuracy:\n",
      "0.9027207657773934\n",
      "step: 547\n",
      "model training accuracy:\n",
      "0.8055999904870986\n",
      "model test accuracy:\n",
      "0.9027207657773934\n",
      "step: 548\n",
      "model training accuracy:\n",
      "0.8055999904870986\n",
      "model test accuracy:\n",
      "0.9027207657773934\n",
      "step: 549\n",
      "model training accuracy:\n",
      "0.8055999904870986\n",
      "model test accuracy:\n",
      "0.9027207657773934\n",
      "step: 550\n",
      "model training accuracy:\n",
      "0.8132000058889388\n",
      "model test accuracy:\n",
      "0.9087227703669281\n",
      "step: 551\n",
      "model training accuracy:\n",
      "0.8132000058889388\n",
      "model test accuracy:\n",
      "0.9087227703669281\n",
      "step: 552\n",
      "model training accuracy:\n",
      "0.8132000058889388\n",
      "model test accuracy:\n",
      "0.9087227703669281\n",
      "step: 553\n",
      "model training accuracy:\n",
      "0.8132000058889388\n",
      "model test accuracy:\n",
      "0.9087227703669281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 554\n",
      "model training accuracy:\n",
      "0.8132000058889388\n",
      "model test accuracy:\n",
      "0.9087227703669281\n",
      "step: 555\n",
      "model training accuracy:\n",
      "0.8911000108718872\n",
      "model test accuracy:\n",
      "0.9083428457597932\n",
      "step: 556\n",
      "model training accuracy:\n",
      "0.8911000108718872\n",
      "model test accuracy:\n",
      "0.9083428457597932\n",
      "step: 557\n",
      "model training accuracy:\n",
      "0.8911000108718872\n",
      "model test accuracy:\n",
      "0.9083428457597932\n",
      "step: 558\n",
      "model training accuracy:\n",
      "0.8911000108718872\n",
      "model test accuracy:\n",
      "0.9083428457597932\n",
      "step: 559\n",
      "model training accuracy:\n",
      "0.8911000108718872\n",
      "model test accuracy:\n",
      "0.9083428457597932\n",
      "step: 560\n",
      "model training accuracy:\n",
      "0.8037000036239624\n",
      "model test accuracy:\n",
      "0.9055254799229995\n",
      "step: 561\n",
      "model training accuracy:\n",
      "0.8037000036239624\n",
      "model test accuracy:\n",
      "0.9055254799229995\n",
      "step: 562\n",
      "model training accuracy:\n",
      "0.8037000036239624\n",
      "model test accuracy:\n",
      "0.9055254799229995\n",
      "step: 563\n",
      "model training accuracy:\n",
      "0.8037000036239624\n",
      "model test accuracy:\n",
      "0.9055254799229995\n",
      "step: 564\n",
      "model training accuracy:\n",
      "0.8037000036239624\n",
      "model test accuracy:\n",
      "0.9055254799229995\n",
      "step: 565\n",
      "model training accuracy:\n",
      "0.7714000061154365\n",
      "model test accuracy:\n",
      "0.9093349520822723\n",
      "step: 566\n",
      "model training accuracy:\n",
      "0.7714000061154365\n",
      "model test accuracy:\n",
      "0.9093349520822723\n",
      "step: 567\n",
      "model training accuracy:\n",
      "0.7714000061154365\n",
      "model test accuracy:\n",
      "0.9093349520822723\n",
      "step: 568\n",
      "model training accuracy:\n",
      "0.7714000061154365\n",
      "model test accuracy:\n",
      "0.9093349520822723\n",
      "step: 569\n",
      "model training accuracy:\n",
      "0.7714000061154365\n",
      "model test accuracy:\n",
      "0.9093349520822723\n",
      "step: 570\n",
      "model training accuracy:\n",
      "0.8720999950170516\n",
      "model test accuracy:\n",
      "0.9111298861278996\n",
      "step: 571\n",
      "model training accuracy:\n",
      "0.8720999950170516\n",
      "model test accuracy:\n",
      "0.9111298861278996\n",
      "step: 572\n",
      "model training accuracy:\n",
      "0.8720999950170516\n",
      "model test accuracy:\n",
      "0.9111298861278996\n",
      "step: 573\n",
      "model training accuracy:\n",
      "0.8720999950170516\n",
      "model test accuracy:\n",
      "0.9111298861278996\n",
      "step: 574\n",
      "model training accuracy:\n",
      "0.8720999950170516\n",
      "model test accuracy:\n",
      "0.9111298861278996\n",
      "step: 575\n",
      "model training accuracy:\n",
      "0.7999000072479248\n",
      "model test accuracy:\n",
      "0.903382132180424\n",
      "step: 576\n",
      "model training accuracy:\n",
      "0.7999000072479248\n",
      "model test accuracy:\n",
      "0.903382132180424\n",
      "step: 577\n",
      "model training accuracy:\n",
      "0.7999000072479248\n",
      "model test accuracy:\n",
      "0.903382132180424\n",
      "step: 578\n",
      "model training accuracy:\n",
      "0.7999000072479248\n",
      "model test accuracy:\n",
      "0.903382132180424\n",
      "step: 579\n",
      "model training accuracy:\n",
      "0.7999000072479248\n",
      "model test accuracy:\n",
      "0.903382132180424\n",
      "step: 580\n",
      "model training accuracy:\n",
      "0.835999972820282\n",
      "model test accuracy:\n",
      "0.9074789404809349\n",
      "step: 581\n",
      "model training accuracy:\n",
      "0.835999972820282\n",
      "model test accuracy:\n",
      "0.9074789404809349\n",
      "step: 582\n",
      "model training accuracy:\n",
      "0.835999972820282\n",
      "model test accuracy:\n",
      "0.9074789404809349\n",
      "step: 583\n",
      "model training accuracy:\n",
      "0.835999972820282\n",
      "model test accuracy:\n",
      "0.9074789404809349\n",
      "step: 584\n",
      "model training accuracy:\n",
      "0.835999972820282\n",
      "model test accuracy:\n",
      "0.9074789404809349\n",
      "step: 585\n",
      "model training accuracy:\n",
      "0.9708999687433242\n",
      "model test accuracy:\n",
      "0.909086369958137\n",
      "step: 586\n",
      "model training accuracy:\n",
      "0.9708999687433242\n",
      "model test accuracy:\n",
      "0.909086369958137\n",
      "step: 587\n",
      "model training accuracy:\n",
      "0.9708999687433242\n",
      "model test accuracy:\n",
      "0.909086369958137\n",
      "step: 588\n",
      "model training accuracy:\n",
      "0.9708999687433242\n",
      "model test accuracy:\n",
      "0.909086369958137\n",
      "step: 589\n",
      "model training accuracy:\n",
      "0.9708999687433242\n",
      "model test accuracy:\n",
      "0.909086369958137\n",
      "step: 590\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9062899058157086\n",
      "step: 591\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9062899058157086\n",
      "step: 592\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9062899058157086\n",
      "step: 593\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9062899058157086\n",
      "step: 594\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9062899058157086\n",
      "step: 595\n",
      "model training accuracy:\n",
      "0.8683000099658966\n",
      "model test accuracy:\n",
      "0.9070066060346054\n",
      "step: 596\n",
      "model training accuracy:\n",
      "0.8683000099658966\n",
      "model test accuracy:\n",
      "0.9070066060346054\n",
      "step: 597\n",
      "model training accuracy:\n",
      "0.8683000099658966\n",
      "model test accuracy:\n",
      "0.9070066060346054\n",
      "step: 598\n",
      "model training accuracy:\n",
      "0.8683000099658966\n",
      "model test accuracy:\n",
      "0.9070066060346054\n",
      "step: 599\n",
      "model training accuracy:\n",
      "0.8683000099658966\n",
      "model test accuracy:\n",
      "0.9070066060346054\n",
      "step: 600\n",
      "model training accuracy:\n",
      "0.7922999691963196\n",
      "model test accuracy:\n",
      "0.9068604870449797\n",
      "step: 601\n",
      "model training accuracy:\n",
      "0.7922999691963196\n",
      "model test accuracy:\n",
      "0.9068604870449797\n",
      "step: 602\n",
      "model training accuracy:\n",
      "0.7922999691963196\n",
      "model test accuracy:\n",
      "0.9068604870449797\n",
      "step: 603\n",
      "model training accuracy:\n",
      "0.7922999691963196\n",
      "model test accuracy:\n",
      "0.9068604870449797\n",
      "step: 604\n",
      "model training accuracy:\n",
      "0.7922999691963196\n",
      "model test accuracy:\n",
      "0.9068604870449797\n",
      "step: 605\n",
      "model training accuracy:\n",
      "0.773300021290779\n",
      "model test accuracy:\n",
      "0.9040921734253021\n",
      "step: 606\n",
      "model training accuracy:\n",
      "0.773300021290779\n",
      "model test accuracy:\n",
      "0.9040921734253021\n",
      "step: 607\n",
      "model training accuracy:\n",
      "0.773300021290779\n",
      "model test accuracy:\n",
      "0.9040921734253021\n",
      "step: 608\n",
      "model training accuracy:\n",
      "0.773300021290779\n",
      "model test accuracy:\n",
      "0.9040921734253021\n",
      "step: 609\n",
      "model training accuracy:\n",
      "0.773300021290779\n",
      "model test accuracy:\n",
      "0.9040921734253021\n",
      "step: 610\n",
      "model training accuracy:\n",
      "0.8417000070214271\n",
      "model test accuracy:\n",
      "0.9000450008595662\n",
      "step: 611\n",
      "model training accuracy:\n",
      "0.8417000070214271\n",
      "model test accuracy:\n",
      "0.9000450008595662\n",
      "step: 612\n",
      "model training accuracy:\n",
      "0.8417000070214271\n",
      "model test accuracy:\n",
      "0.9000450008595662\n",
      "step: 613\n",
      "model training accuracy:\n",
      "0.8417000070214271\n",
      "model test accuracy:\n",
      "0.9000450008595662\n",
      "step: 614\n",
      "model training accuracy:\n",
      "0.8417000070214271\n",
      "model test accuracy:\n",
      "0.9000450008595662\n",
      "step: 615\n",
      "model training accuracy:\n",
      "0.8131999945640564\n",
      "model test accuracy:\n",
      "0.9031313096519467\n",
      "step: 616\n",
      "model training accuracy:\n",
      "0.8131999945640564\n",
      "model test accuracy:\n",
      "0.9031313096519467\n",
      "step: 617\n",
      "model training accuracy:\n",
      "0.8131999945640564\n",
      "model test accuracy:\n",
      "0.9031313096519467\n",
      "step: 618\n",
      "model training accuracy:\n",
      "0.8131999945640564\n",
      "model test accuracy:\n",
      "0.9031313096519467\n",
      "step: 619\n",
      "model training accuracy:\n",
      "0.8131999945640564\n",
      "model test accuracy:\n",
      "0.9031313096519467\n",
      "step: 620\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9007950173711256\n",
      "step: 621\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9007950173711256\n",
      "step: 622\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9007950173711256\n",
      "step: 623\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9007950173711256\n",
      "step: 624\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9007950173711256\n",
      "step: 625\n",
      "model training accuracy:\n",
      "0.8074999886751175\n",
      "model test accuracy:\n",
      "0.9101833125450327\n",
      "step: 626\n",
      "model training accuracy:\n",
      "0.8074999886751175\n",
      "model test accuracy:\n",
      "0.9101833125450327\n",
      "step: 627\n",
      "model training accuracy:\n",
      "0.8074999886751175\n",
      "model test accuracy:\n",
      "0.9101833125450327\n",
      "step: 628\n",
      "model training accuracy:\n",
      "0.8074999886751175\n",
      "model test accuracy:\n",
      "0.9101833125450327\n",
      "step: 629\n",
      "model training accuracy:\n",
      "0.8074999886751175\n",
      "model test accuracy:\n",
      "0.9101833125450327\n",
      "step: 630\n",
      "model training accuracy:\n",
      "0.9253000122308731\n",
      "model test accuracy:\n",
      "0.9018250646380033\n",
      "step: 631\n",
      "model training accuracy:\n",
      "0.9253000122308731\n",
      "model test accuracy:\n",
      "0.9018250646380033\n",
      "step: 632\n",
      "model training accuracy:\n",
      "0.9253000122308731\n",
      "model test accuracy:\n",
      "0.9018250646380033\n",
      "step: 633\n",
      "model training accuracy:\n",
      "0.9253000122308731\n",
      "model test accuracy:\n",
      "0.9018250646380033\n",
      "step: 634\n",
      "model training accuracy:\n",
      "0.9253000122308731\n",
      "model test accuracy:\n",
      "0.9018250646380033\n",
      "step: 635\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9095771950303979\n",
      "step: 636\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9095771950303979\n",
      "step: 637\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9095771950303979\n",
      "step: 638\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9095771950303979\n",
      "step: 639\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9095771950303979\n",
      "step: 640\n",
      "model training accuracy:\n",
      "0.735300012230873\n",
      "model test accuracy:\n",
      "0.9018382722050096\n",
      "step: 641\n",
      "model training accuracy:\n",
      "0.735300012230873\n",
      "model test accuracy:\n",
      "0.9018382722050096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 642\n",
      "model training accuracy:\n",
      "0.735300012230873\n",
      "model test accuracy:\n",
      "0.9018382722050096\n",
      "step: 643\n",
      "model training accuracy:\n",
      "0.735300012230873\n",
      "model test accuracy:\n",
      "0.9018382722050096\n",
      "step: 644\n",
      "model training accuracy:\n",
      "0.735300012230873\n",
      "model test accuracy:\n",
      "0.9018382722050096\n",
      "step: 645\n",
      "model training accuracy:\n",
      "0.8625999927520751\n",
      "model test accuracy:\n",
      "0.9093528452855337\n",
      "step: 646\n",
      "model training accuracy:\n",
      "0.8625999927520751\n",
      "model test accuracy:\n",
      "0.9093528452855337\n",
      "step: 647\n",
      "model training accuracy:\n",
      "0.8625999927520751\n",
      "model test accuracy:\n",
      "0.9093528452855337\n",
      "step: 648\n",
      "model training accuracy:\n",
      "0.8625999927520751\n",
      "model test accuracy:\n",
      "0.9093528452855337\n",
      "step: 649\n",
      "model training accuracy:\n",
      "0.8625999927520751\n",
      "model test accuracy:\n",
      "0.9093528452855337\n",
      "step: 650\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9016315313998131\n",
      "step: 651\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9016315313998131\n",
      "step: 652\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9016315313998131\n",
      "step: 653\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9016315313998131\n",
      "step: 654\n",
      "model training accuracy:\n",
      "0.8530999565124511\n",
      "model test accuracy:\n",
      "0.9016315313998131\n",
      "step: 655\n",
      "model training accuracy:\n",
      "0.9538000190258025\n",
      "model test accuracy:\n",
      "0.9116384011583477\n",
      "step: 656\n",
      "model training accuracy:\n",
      "0.9538000190258025\n",
      "model test accuracy:\n",
      "0.9116384011583477\n",
      "step: 657\n",
      "model training accuracy:\n",
      "0.9538000190258025\n",
      "model test accuracy:\n",
      "0.9116384011583477\n",
      "step: 658\n",
      "model training accuracy:\n",
      "0.9538000190258025\n",
      "model test accuracy:\n",
      "0.9116384011583477\n",
      "step: 659\n",
      "model training accuracy:\n",
      "0.9538000190258025\n",
      "model test accuracy:\n",
      "0.9116384011583477\n",
      "step: 660\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9043142999312569\n",
      "step: 661\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9043142999312569\n",
      "step: 662\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9043142999312569\n",
      "step: 663\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9043142999312569\n",
      "step: 664\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9043142999312569\n",
      "step: 665\n",
      "model training accuracy:\n",
      "0.8322000217437745\n",
      "model test accuracy:\n",
      "0.910183627735966\n",
      "step: 666\n",
      "model training accuracy:\n",
      "0.8322000217437745\n",
      "model test accuracy:\n",
      "0.910183627735966\n",
      "step: 667\n",
      "model training accuracy:\n",
      "0.8322000217437745\n",
      "model test accuracy:\n",
      "0.910183627735966\n",
      "step: 668\n",
      "model training accuracy:\n",
      "0.8322000217437745\n",
      "model test accuracy:\n",
      "0.910183627735966\n",
      "step: 669\n",
      "model training accuracy:\n",
      "0.8322000217437745\n",
      "model test accuracy:\n",
      "0.910183627735966\n",
      "step: 670\n",
      "model training accuracy:\n",
      "0.9215000045299531\n",
      "model test accuracy:\n",
      "0.9049421833770243\n",
      "step: 671\n",
      "model training accuracy:\n",
      "0.9215000045299531\n",
      "model test accuracy:\n",
      "0.9049421833770243\n",
      "step: 672\n",
      "model training accuracy:\n",
      "0.9215000045299531\n",
      "model test accuracy:\n",
      "0.9049421833770243\n",
      "step: 673\n",
      "model training accuracy:\n",
      "0.9215000045299531\n",
      "model test accuracy:\n",
      "0.9049421833770243\n",
      "step: 674\n",
      "model training accuracy:\n",
      "0.9215000045299531\n",
      "model test accuracy:\n",
      "0.9049421833770243\n",
      "step: 675\n",
      "model training accuracy:\n",
      "0.7409999784827233\n",
      "model test accuracy:\n",
      "0.9074169713138482\n",
      "step: 676\n",
      "model training accuracy:\n",
      "0.7409999784827233\n",
      "model test accuracy:\n",
      "0.9074169713138482\n",
      "step: 677\n",
      "model training accuracy:\n",
      "0.7409999784827233\n",
      "model test accuracy:\n",
      "0.9074169713138482\n",
      "step: 678\n",
      "model training accuracy:\n",
      "0.7409999784827233\n",
      "model test accuracy:\n",
      "0.9074169713138482\n",
      "step: 679\n",
      "model training accuracy:\n",
      "0.7409999784827233\n",
      "model test accuracy:\n",
      "0.9074169713138482\n",
      "step: 680\n",
      "model training accuracy:\n",
      "0.8929999750852585\n",
      "model test accuracy:\n",
      "0.9000254751962973\n",
      "step: 681\n",
      "model training accuracy:\n",
      "0.8929999750852585\n",
      "model test accuracy:\n",
      "0.9000254751962973\n",
      "step: 682\n",
      "model training accuracy:\n",
      "0.8929999750852585\n",
      "model test accuracy:\n",
      "0.9000254751962973\n",
      "step: 683\n",
      "model training accuracy:\n",
      "0.8929999750852585\n",
      "model test accuracy:\n",
      "0.9000254751962973\n",
      "step: 684\n",
      "model training accuracy:\n",
      "0.8929999750852585\n",
      "model test accuracy:\n",
      "0.9000254751962973\n",
      "step: 685\n",
      "model training accuracy:\n",
      "0.8075\n",
      "model test accuracy:\n",
      "0.9059545086542261\n",
      "step: 686\n",
      "model training accuracy:\n",
      "0.8075\n",
      "model test accuracy:\n",
      "0.9059545086542261\n",
      "step: 687\n",
      "model training accuracy:\n",
      "0.8075\n",
      "model test accuracy:\n",
      "0.9059545086542261\n",
      "step: 688\n",
      "model training accuracy:\n",
      "0.8075\n",
      "model test accuracy:\n",
      "0.9059545086542261\n",
      "step: 689\n",
      "model training accuracy:\n",
      "0.8075\n",
      "model test accuracy:\n",
      "0.9059545086542261\n",
      "step: 690\n",
      "model training accuracy:\n",
      "0.8112999963760376\n",
      "model test accuracy:\n",
      "0.9009559956628184\n",
      "step: 691\n",
      "model training accuracy:\n",
      "0.8112999963760376\n",
      "model test accuracy:\n",
      "0.9009559956628184\n",
      "step: 692\n",
      "model training accuracy:\n",
      "0.8112999963760376\n",
      "model test accuracy:\n",
      "0.9009559956628184\n",
      "step: 693\n",
      "model training accuracy:\n",
      "0.8112999963760376\n",
      "model test accuracy:\n",
      "0.9009559956628184\n",
      "step: 694\n",
      "model training accuracy:\n",
      "0.8112999963760376\n",
      "model test accuracy:\n",
      "0.9009559956628184\n",
      "step: 695\n",
      "model training accuracy:\n",
      "0.8834999728202819\n",
      "model test accuracy:\n",
      "0.9094904512760185\n",
      "step: 696\n",
      "model training accuracy:\n",
      "0.8834999728202819\n",
      "model test accuracy:\n",
      "0.9094904512760185\n",
      "step: 697\n",
      "model training accuracy:\n",
      "0.8834999728202819\n",
      "model test accuracy:\n",
      "0.9094904512760185\n",
      "step: 698\n",
      "model training accuracy:\n",
      "0.8834999728202819\n",
      "model test accuracy:\n",
      "0.9094904512760185\n",
      "step: 699\n",
      "model training accuracy:\n",
      "0.8834999728202819\n",
      "model test accuracy:\n",
      "0.9094904512760185\n",
      "step: 700\n",
      "model training accuracy:\n",
      "0.8739999988675117\n",
      "model test accuracy:\n",
      "0.9073311837063993\n",
      "step: 701\n",
      "model training accuracy:\n",
      "0.8739999988675117\n",
      "model test accuracy:\n",
      "0.9073311837063993\n",
      "step: 702\n",
      "model training accuracy:\n",
      "0.8739999988675117\n",
      "model test accuracy:\n",
      "0.9073311837063993\n",
      "step: 703\n",
      "model training accuracy:\n",
      "0.8739999988675117\n",
      "model test accuracy:\n",
      "0.9073311837063993\n",
      "step: 704\n",
      "model training accuracy:\n",
      "0.8739999988675117\n",
      "model test accuracy:\n",
      "0.9073311837063993\n",
      "step: 705\n",
      "model training accuracy:\n",
      "0.9519000208377838\n",
      "model test accuracy:\n",
      "0.9049407787805345\n",
      "step: 706\n",
      "model training accuracy:\n",
      "0.9519000208377838\n",
      "model test accuracy:\n",
      "0.9049407787805345\n",
      "step: 707\n",
      "model training accuracy:\n",
      "0.9519000208377838\n",
      "model test accuracy:\n",
      "0.9049407787805345\n",
      "step: 708\n",
      "model training accuracy:\n",
      "0.9519000208377838\n",
      "model test accuracy:\n",
      "0.9049407787805345\n",
      "step: 709\n",
      "model training accuracy:\n",
      "0.9519000208377838\n",
      "model test accuracy:\n",
      "0.9049407787805345\n",
      "step: 710\n",
      "model training accuracy:\n",
      "0.8663999891281128\n",
      "model test accuracy:\n",
      "0.9047399133318799\n",
      "step: 711\n",
      "model training accuracy:\n",
      "0.8663999891281128\n",
      "model test accuracy:\n",
      "0.9047399133318799\n",
      "step: 712\n",
      "model training accuracy:\n",
      "0.8663999891281128\n",
      "model test accuracy:\n",
      "0.9047399133318799\n",
      "step: 713\n",
      "model training accuracy:\n",
      "0.8663999891281128\n",
      "model test accuracy:\n",
      "0.9047399133318799\n",
      "step: 714\n",
      "model training accuracy:\n",
      "0.8663999891281128\n",
      "model test accuracy:\n",
      "0.9047399133318799\n",
      "step: 715\n",
      "model training accuracy:\n",
      "0.8606999945640564\n",
      "model test accuracy:\n",
      "0.9004166158007832\n",
      "step: 716\n",
      "model training accuracy:\n",
      "0.8606999945640564\n",
      "model test accuracy:\n",
      "0.9004166158007832\n",
      "step: 717\n",
      "model training accuracy:\n",
      "0.8606999945640564\n",
      "model test accuracy:\n",
      "0.9004166158007832\n",
      "step: 718\n",
      "model training accuracy:\n",
      "0.8606999945640564\n",
      "model test accuracy:\n",
      "0.9004166158007832\n",
      "step: 719\n",
      "model training accuracy:\n",
      "0.8606999945640564\n",
      "model test accuracy:\n",
      "0.9004166158007832\n",
      "step: 720\n",
      "model training accuracy:\n",
      "0.7998999959230423\n",
      "model test accuracy:\n",
      "0.9029094439160787\n",
      "step: 721\n",
      "model training accuracy:\n",
      "0.7998999959230423\n",
      "model test accuracy:\n",
      "0.9029094439160787\n",
      "step: 722\n",
      "model training accuracy:\n",
      "0.7998999959230423\n",
      "model test accuracy:\n",
      "0.9029094439160787\n",
      "step: 723\n",
      "model training accuracy:\n",
      "0.7998999959230423\n",
      "model test accuracy:\n",
      "0.9029094439160787\n",
      "step: 724\n",
      "model training accuracy:\n",
      "0.7998999959230423\n",
      "model test accuracy:\n",
      "0.9029094439160787\n",
      "step: 725\n",
      "model training accuracy:\n",
      "0.8417000240087509\n",
      "model test accuracy:\n",
      "0.9099815053422926\n",
      "step: 726\n",
      "model training accuracy:\n",
      "0.8417000240087509\n",
      "model test accuracy:\n",
      "0.9099815053422926\n",
      "step: 727\n",
      "model training accuracy:\n",
      "0.8417000240087509\n",
      "model test accuracy:\n",
      "0.9099815053422926\n",
      "step: 728\n",
      "model training accuracy:\n",
      "0.8417000240087509\n",
      "model test accuracy:\n",
      "0.9099815053422926\n",
      "step: 729\n",
      "model training accuracy:\n",
      "0.8417000240087509\n",
      "model test accuracy:\n",
      "0.9099815053422926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 730\n",
      "model training accuracy:\n",
      "0.9385999768972396\n",
      "model test accuracy:\n",
      "0.9012632841245377\n",
      "step: 731\n",
      "model training accuracy:\n",
      "0.9385999768972396\n",
      "model test accuracy:\n",
      "0.9012632841245377\n",
      "step: 732\n",
      "model training accuracy:\n",
      "0.9385999768972396\n",
      "model test accuracy:\n",
      "0.9012632841245377\n",
      "step: 733\n",
      "model training accuracy:\n",
      "0.9385999768972396\n",
      "model test accuracy:\n",
      "0.9012632841245377\n",
      "step: 734\n",
      "model training accuracy:\n",
      "0.9385999768972396\n",
      "model test accuracy:\n",
      "0.9012632841245377\n",
      "step: 735\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9000954453413126\n",
      "step: 736\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9000954453413126\n",
      "step: 737\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9000954453413126\n",
      "step: 738\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9000954453413126\n",
      "step: 739\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9000954453413126\n",
      "step: 740\n",
      "model training accuracy:\n",
      "0.8132000115513802\n",
      "model test accuracy:\n",
      "0.9061477342456522\n",
      "step: 741\n",
      "model training accuracy:\n",
      "0.8132000115513802\n",
      "model test accuracy:\n",
      "0.9061477342456522\n",
      "step: 742\n",
      "model training accuracy:\n",
      "0.8132000115513802\n",
      "model test accuracy:\n",
      "0.9061477342456522\n",
      "step: 743\n",
      "model training accuracy:\n",
      "0.8132000115513802\n",
      "model test accuracy:\n",
      "0.9061477342456522\n",
      "step: 744\n",
      "model training accuracy:\n",
      "0.8132000115513802\n",
      "model test accuracy:\n",
      "0.9061477342456522\n",
      "step: 745\n",
      "model training accuracy:\n",
      "0.8607000058889389\n",
      "model test accuracy:\n",
      "0.9081995091717349\n",
      "step: 746\n",
      "model training accuracy:\n",
      "0.8607000058889389\n",
      "model test accuracy:\n",
      "0.9081995091717349\n",
      "step: 747\n",
      "model training accuracy:\n",
      "0.8607000058889389\n",
      "model test accuracy:\n",
      "0.9081995091717349\n",
      "step: 748\n",
      "model training accuracy:\n",
      "0.8607000058889389\n",
      "model test accuracy:\n",
      "0.9081995091717349\n",
      "step: 749\n",
      "model training accuracy:\n",
      "0.8607000058889389\n",
      "model test accuracy:\n",
      "0.9081995091717349\n",
      "step: 750\n",
      "model training accuracy:\n",
      "0.8910999655723572\n",
      "model test accuracy:\n",
      "0.9093996660385067\n",
      "step: 751\n",
      "model training accuracy:\n",
      "0.8910999655723572\n",
      "model test accuracy:\n",
      "0.9093996660385067\n",
      "step: 752\n",
      "model training accuracy:\n",
      "0.8910999655723572\n",
      "model test accuracy:\n",
      "0.9093996660385067\n",
      "step: 753\n",
      "model training accuracy:\n",
      "0.8910999655723572\n",
      "model test accuracy:\n",
      "0.9093996660385067\n",
      "step: 754\n",
      "model training accuracy:\n",
      "0.8910999655723572\n",
      "model test accuracy:\n",
      "0.9093996660385067\n",
      "step: 755\n",
      "model training accuracy:\n",
      "0.8937807268889135\n",
      "model test accuracy:\n",
      "0.9041188848379557\n",
      "step: 756\n",
      "model training accuracy:\n",
      "0.8937807268889135\n",
      "model test accuracy:\n",
      "0.9041188848379557\n",
      "step: 757\n",
      "model training accuracy:\n",
      "0.8937807268889135\n",
      "model test accuracy:\n",
      "0.9041188848379557\n",
      "step: 758\n",
      "model training accuracy:\n",
      "0.8937807268889135\n",
      "model test accuracy:\n",
      "0.9041188848379557\n",
      "step: 759\n",
      "model training accuracy:\n",
      "0.8937807268889135\n",
      "model test accuracy:\n",
      "0.9041188848379557\n",
      "step: 760\n",
      "model training accuracy:\n",
      "0.8397999975085259\n",
      "model test accuracy:\n",
      "0.9042181609056593\n",
      "step: 761\n",
      "model training accuracy:\n",
      "0.8397999975085259\n",
      "model test accuracy:\n",
      "0.9042181609056593\n",
      "step: 762\n",
      "model training accuracy:\n",
      "0.8397999975085259\n",
      "model test accuracy:\n",
      "0.9042181609056593\n",
      "step: 763\n",
      "model training accuracy:\n",
      "0.8397999975085259\n",
      "model test accuracy:\n",
      "0.9042181609056593\n",
      "step: 764\n",
      "model training accuracy:\n",
      "0.8397999975085259\n",
      "model test accuracy:\n",
      "0.9042181609056593\n",
      "step: 765\n",
      "model training accuracy:\n",
      "0.8720999950170516\n",
      "model test accuracy:\n",
      "0.8999756559860134\n",
      "step: 766\n",
      "model training accuracy:\n",
      "0.8720999950170516\n",
      "model test accuracy:\n",
      "0.8999756559860134\n",
      "step: 767\n",
      "model training accuracy:\n",
      "0.8720999950170516\n",
      "model test accuracy:\n",
      "0.8999756559860134\n",
      "step: 768\n",
      "model training accuracy:\n",
      "0.8720999950170516\n",
      "model test accuracy:\n",
      "0.8999756559860134\n",
      "step: 769\n",
      "model training accuracy:\n",
      "0.8720999950170516\n",
      "model test accuracy:\n",
      "0.8999756559860134\n",
      "step: 770\n",
      "model training accuracy:\n",
      "0.782800012230873\n",
      "model test accuracy:\n",
      "0.9047478184403116\n",
      "step: 771\n",
      "model training accuracy:\n",
      "0.782800012230873\n",
      "model test accuracy:\n",
      "0.9047478184403116\n",
      "step: 772\n",
      "model training accuracy:\n",
      "0.782800012230873\n",
      "model test accuracy:\n",
      "0.9047478184403116\n",
      "step: 773\n",
      "model training accuracy:\n",
      "0.782800012230873\n",
      "model test accuracy:\n",
      "0.9047478184403116\n",
      "step: 774\n",
      "model training accuracy:\n",
      "0.782800012230873\n",
      "model test accuracy:\n",
      "0.9047478184403116\n",
      "step: 775\n",
      "model training accuracy:\n",
      "0.8435999655723571\n",
      "model test accuracy:\n",
      "0.8997309655462885\n",
      "step: 776\n",
      "model training accuracy:\n",
      "0.8435999655723571\n",
      "model test accuracy:\n",
      "0.8997309655462885\n",
      "step: 777\n",
      "model training accuracy:\n",
      "0.8435999655723571\n",
      "model test accuracy:\n",
      "0.8997309655462885\n",
      "step: 778\n",
      "model training accuracy:\n",
      "0.8435999655723571\n",
      "model test accuracy:\n",
      "0.8997309655462885\n",
      "step: 779\n",
      "model training accuracy:\n",
      "0.8435999655723571\n",
      "model test accuracy:\n",
      "0.8997309655462885\n",
      "step: 780\n",
      "model training accuracy:\n",
      "0.9195999950170517\n",
      "model test accuracy:\n",
      "0.9086627744813413\n",
      "step: 781\n",
      "model training accuracy:\n",
      "0.9195999950170517\n",
      "model test accuracy:\n",
      "0.9086627744813413\n",
      "step: 782\n",
      "model training accuracy:\n",
      "0.9195999950170517\n",
      "model test accuracy:\n",
      "0.9086627744813413\n",
      "step: 783\n",
      "model training accuracy:\n",
      "0.9195999950170517\n",
      "model test accuracy:\n",
      "0.9086627744813413\n",
      "step: 784\n",
      "model training accuracy:\n",
      "0.9195999950170517\n",
      "model test accuracy:\n",
      "0.9086627744813413\n",
      "step: 785\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9001189581347252\n",
      "step: 786\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9001189581347252\n",
      "step: 787\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9001189581347252\n",
      "step: 788\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9001189581347252\n",
      "step: 789\n",
      "model training accuracy:\n",
      "0.8815999916195869\n",
      "model test accuracy:\n",
      "0.9001189581347252\n",
      "step: 790\n",
      "model training accuracy:\n",
      "0.8322000160813331\n",
      "model test accuracy:\n",
      "0.9108868393608659\n",
      "step: 791\n",
      "model training accuracy:\n",
      "0.8322000160813331\n",
      "model test accuracy:\n",
      "0.9108868393608659\n",
      "step: 792\n",
      "model training accuracy:\n",
      "0.8322000160813331\n",
      "model test accuracy:\n",
      "0.9108868393608659\n",
      "step: 793\n",
      "model training accuracy:\n",
      "0.8322000160813331\n",
      "model test accuracy:\n",
      "0.9108868393608659\n",
      "step: 794\n",
      "model training accuracy:\n",
      "0.8322000160813331\n",
      "model test accuracy:\n",
      "0.9108868393608659\n",
      "step: 795\n",
      "model training accuracy:\n",
      "0.8378999710083007\n",
      "model test accuracy:\n",
      "0.9003921995739115\n",
      "step: 796\n",
      "model training accuracy:\n",
      "0.8378999710083007\n",
      "model test accuracy:\n",
      "0.9003921995739115\n",
      "step: 797\n",
      "model training accuracy:\n",
      "0.8378999710083007\n",
      "model test accuracy:\n",
      "0.9003921995739115\n",
      "step: 798\n",
      "model training accuracy:\n",
      "0.8378999710083007\n",
      "model test accuracy:\n",
      "0.9003921995739115\n",
      "step: 799\n",
      "model training accuracy:\n",
      "0.8378999710083007\n",
      "model test accuracy:\n",
      "0.9003921995739115\n",
      "step: 800\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9059365142322341\n",
      "step: 801\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9059365142322341\n",
      "step: 802\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9059365142322341\n",
      "step: 803\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9059365142322341\n",
      "step: 804\n",
      "model training accuracy:\n",
      "0.8948999845981597\n",
      "model test accuracy:\n",
      "0.9059365142322341\n",
      "step: 805\n",
      "model training accuracy:\n",
      "0.8246000006794929\n",
      "model test accuracy:\n",
      "0.9066950368830758\n",
      "step: 806\n",
      "model training accuracy:\n",
      "0.8246000006794929\n",
      "model test accuracy:\n",
      "0.9066950368830758\n",
      "step: 807\n",
      "model training accuracy:\n",
      "0.8246000006794929\n",
      "model test accuracy:\n",
      "0.9066950368830758\n",
      "step: 808\n",
      "model training accuracy:\n",
      "0.8246000006794929\n",
      "model test accuracy:\n",
      "0.9066950368830758\n",
      "step: 809\n",
      "model training accuracy:\n",
      "0.8246000006794929\n",
      "model test accuracy:\n",
      "0.9066950368830758\n",
      "step: 810\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.908747003425224\n",
      "step: 811\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.908747003425224\n",
      "step: 812\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.908747003425224\n",
      "step: 813\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.908747003425224\n",
      "step: 814\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.908747003425224\n",
      "step: 815\n",
      "model training accuracy:\n",
      "0.7562000206112862\n",
      "model test accuracy:\n",
      "0.9099454177964061\n",
      "step: 816\n",
      "model training accuracy:\n",
      "0.7562000206112862\n",
      "model test accuracy:\n",
      "0.9099454177964061\n",
      "step: 817\n",
      "model training accuracy:\n",
      "0.7562000206112862\n",
      "model test accuracy:\n",
      "0.9099454177964061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 818\n",
      "model training accuracy:\n",
      "0.7562000206112862\n",
      "model test accuracy:\n",
      "0.9099454177964061\n",
      "step: 819\n",
      "model training accuracy:\n",
      "0.7562000206112862\n",
      "model test accuracy:\n",
      "0.9099454177964061\n",
      "step: 820\n",
      "model training accuracy:\n",
      "0.7599999886751175\n",
      "model test accuracy:\n",
      "0.9111056545961173\n",
      "step: 821\n",
      "model training accuracy:\n",
      "0.7599999886751175\n",
      "model test accuracy:\n",
      "0.9111056545961173\n",
      "step: 822\n",
      "model training accuracy:\n",
      "0.7599999886751175\n",
      "model test accuracy:\n",
      "0.9111056545961173\n",
      "step: 823\n",
      "model training accuracy:\n",
      "0.7599999886751175\n",
      "model test accuracy:\n",
      "0.9111056545961173\n",
      "step: 824\n",
      "model training accuracy:\n",
      "0.7599999886751175\n",
      "model test accuracy:\n",
      "0.9111056545961173\n",
      "step: 825\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9089205489603072\n",
      "step: 826\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9089205489603072\n",
      "step: 827\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9089205489603072\n",
      "step: 828\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9089205489603072\n",
      "step: 829\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9089205489603072\n",
      "step: 830\n",
      "model training accuracy:\n",
      "0.855\n",
      "model test accuracy:\n",
      "0.9032705544210726\n",
      "step: 831\n",
      "model training accuracy:\n",
      "0.855\n",
      "model test accuracy:\n",
      "0.9032705544210726\n",
      "step: 832\n",
      "model training accuracy:\n",
      "0.855\n",
      "model test accuracy:\n",
      "0.9032705544210726\n",
      "step: 833\n",
      "model training accuracy:\n",
      "0.855\n",
      "model test accuracy:\n",
      "0.9032705544210726\n",
      "step: 834\n",
      "model training accuracy:\n",
      "0.855\n",
      "model test accuracy:\n",
      "0.9032705544210726\n",
      "step: 835\n",
      "model training accuracy:\n",
      "0.847399990260601\n",
      "model test accuracy:\n",
      "0.9039024093407182\n",
      "step: 836\n",
      "model training accuracy:\n",
      "0.847399990260601\n",
      "model test accuracy:\n",
      "0.9039024093407182\n",
      "step: 837\n",
      "model training accuracy:\n",
      "0.847399990260601\n",
      "model test accuracy:\n",
      "0.9039024093407182\n",
      "step: 838\n",
      "model training accuracy:\n",
      "0.847399990260601\n",
      "model test accuracy:\n",
      "0.9039024093407182\n",
      "step: 839\n",
      "model training accuracy:\n",
      "0.847399990260601\n",
      "model test accuracy:\n",
      "0.9039024093407182\n",
      "step: 840\n",
      "model training accuracy:\n",
      "0.8322000160813331\n",
      "model test accuracy:\n",
      "0.9065762162400565\n",
      "step: 841\n",
      "model training accuracy:\n",
      "0.8322000160813331\n",
      "model test accuracy:\n",
      "0.9065762162400565\n",
      "step: 842\n",
      "model training accuracy:\n",
      "0.8322000160813331\n",
      "model test accuracy:\n",
      "0.9065762162400565\n",
      "step: 843\n",
      "model training accuracy:\n",
      "0.8322000160813331\n",
      "model test accuracy:\n",
      "0.9065762162400565\n",
      "step: 844\n",
      "model training accuracy:\n",
      "0.8322000160813331\n",
      "model test accuracy:\n",
      "0.9065762162400565\n",
      "step: 845\n",
      "model training accuracy:\n",
      "0.7960999825596808\n",
      "model test accuracy:\n",
      "0.9050392803450054\n",
      "step: 846\n",
      "model training accuracy:\n",
      "0.7960999825596808\n",
      "model test accuracy:\n",
      "0.9050392803450054\n",
      "step: 847\n",
      "model training accuracy:\n",
      "0.7960999825596808\n",
      "model test accuracy:\n",
      "0.9050392803450054\n",
      "step: 848\n",
      "model training accuracy:\n",
      "0.7960999825596808\n",
      "model test accuracy:\n",
      "0.9050392803450054\n",
      "step: 849\n",
      "model training accuracy:\n",
      "0.7960999825596808\n",
      "model test accuracy:\n",
      "0.9050392803450054\n",
      "step: 850\n",
      "model training accuracy:\n",
      "0.773300021290779\n",
      "model test accuracy:\n",
      "0.9080180370989702\n",
      "step: 851\n",
      "model training accuracy:\n",
      "0.773300021290779\n",
      "model test accuracy:\n",
      "0.9080180370989702\n",
      "step: 852\n",
      "model training accuracy:\n",
      "0.773300021290779\n",
      "model test accuracy:\n",
      "0.9080180370989702\n",
      "step: 853\n",
      "model training accuracy:\n",
      "0.773300021290779\n",
      "model test accuracy:\n",
      "0.9080180370989702\n",
      "step: 854\n",
      "model training accuracy:\n",
      "0.773300021290779\n",
      "model test accuracy:\n",
      "0.9080180370989702\n",
      "step: 855\n",
      "model training accuracy:\n",
      "0.845500009059906\n",
      "model test accuracy:\n",
      "0.9028462385027664\n",
      "step: 856\n",
      "model training accuracy:\n",
      "0.845500009059906\n",
      "model test accuracy:\n",
      "0.9028462385027664\n",
      "step: 857\n",
      "model training accuracy:\n",
      "0.845500009059906\n",
      "model test accuracy:\n",
      "0.9028462385027664\n",
      "step: 858\n",
      "model training accuracy:\n",
      "0.845500009059906\n",
      "model test accuracy:\n",
      "0.9028462385027664\n",
      "step: 859\n",
      "model training accuracy:\n",
      "0.845500009059906\n",
      "model test accuracy:\n",
      "0.9028462385027664\n",
      "step: 860\n",
      "model training accuracy:\n",
      "0.7865999916195868\n",
      "model test accuracy:\n",
      "0.901290657754978\n",
      "step: 861\n",
      "model training accuracy:\n",
      "0.7865999916195868\n",
      "model test accuracy:\n",
      "0.901290657754978\n",
      "step: 862\n",
      "model training accuracy:\n",
      "0.7865999916195868\n",
      "model test accuracy:\n",
      "0.901290657754978\n",
      "step: 863\n",
      "model training accuracy:\n",
      "0.7865999916195868\n",
      "model test accuracy:\n",
      "0.901290657754978\n",
      "step: 864\n",
      "model training accuracy:\n",
      "0.7865999916195868\n",
      "model test accuracy:\n",
      "0.901290657754978\n",
      "step: 865\n",
      "model training accuracy:\n",
      "0.9025000113248824\n",
      "model test accuracy:\n",
      "0.9044604255862575\n",
      "step: 866\n",
      "model training accuracy:\n",
      "0.9025000113248824\n",
      "model test accuracy:\n",
      "0.9044604255862575\n",
      "step: 867\n",
      "model training accuracy:\n",
      "0.9025000113248824\n",
      "model test accuracy:\n",
      "0.9044604255862575\n",
      "step: 868\n",
      "model training accuracy:\n",
      "0.9025000113248824\n",
      "model test accuracy:\n",
      "0.9044604255862575\n",
      "step: 869\n",
      "model training accuracy:\n",
      "0.9025000113248824\n",
      "model test accuracy:\n",
      "0.9044604255862575\n",
      "step: 870\n",
      "model training accuracy:\n",
      "0.9100999927520752\n",
      "model test accuracy:\n",
      "0.9105020860351409\n",
      "step: 871\n",
      "model training accuracy:\n",
      "0.9100999927520752\n",
      "model test accuracy:\n",
      "0.9105020860351409\n",
      "step: 872\n",
      "model training accuracy:\n",
      "0.9100999927520752\n",
      "model test accuracy:\n",
      "0.9105020860351409\n",
      "step: 873\n",
      "model training accuracy:\n",
      "0.9100999927520752\n",
      "model test accuracy:\n",
      "0.9105020860351409\n",
      "step: 874\n",
      "model training accuracy:\n",
      "0.9100999927520752\n",
      "model test accuracy:\n",
      "0.9105020860351409\n",
      "step: 875\n",
      "model training accuracy:\n",
      "0.8512000036239624\n",
      "model test accuracy:\n",
      "0.9082361664005574\n",
      "step: 876\n",
      "model training accuracy:\n",
      "0.8512000036239624\n",
      "model test accuracy:\n",
      "0.9082361664005574\n",
      "step: 877\n",
      "model training accuracy:\n",
      "0.8512000036239624\n",
      "model test accuracy:\n",
      "0.9082361664005574\n",
      "step: 878\n",
      "model training accuracy:\n",
      "0.8512000036239624\n",
      "model test accuracy:\n",
      "0.9082361664005574\n",
      "step: 879\n",
      "model training accuracy:\n",
      "0.8512000036239624\n",
      "model test accuracy:\n",
      "0.9082361664005574\n",
      "step: 880\n",
      "model training accuracy:\n",
      "0.7942000296711922\n",
      "model test accuracy:\n",
      "0.9103198788798679\n",
      "step: 881\n",
      "model training accuracy:\n",
      "0.7942000296711922\n",
      "model test accuracy:\n",
      "0.9103198788798679\n",
      "step: 882\n",
      "model training accuracy:\n",
      "0.7942000296711922\n",
      "model test accuracy:\n",
      "0.9103198788798679\n",
      "step: 883\n",
      "model training accuracy:\n",
      "0.7942000296711922\n",
      "model test accuracy:\n",
      "0.9103198788798679\n",
      "step: 884\n",
      "model training accuracy:\n",
      "0.7942000296711922\n",
      "model test accuracy:\n",
      "0.9103198788798679\n",
      "step: 885\n",
      "model training accuracy:\n",
      "0.6555000147223473\n",
      "model test accuracy:\n",
      "0.909115449591691\n",
      "step: 886\n",
      "model training accuracy:\n",
      "0.6555000147223473\n",
      "model test accuracy:\n",
      "0.909115449591691\n",
      "step: 887\n",
      "model training accuracy:\n",
      "0.6555000147223473\n",
      "model test accuracy:\n",
      "0.909115449591691\n",
      "step: 888\n",
      "model training accuracy:\n",
      "0.6555000147223473\n",
      "model test accuracy:\n",
      "0.909115449591691\n",
      "step: 889\n",
      "model training accuracy:\n",
      "0.6555000147223473\n",
      "model test accuracy:\n",
      "0.909115449591691\n",
      "step: 890\n",
      "model training accuracy:\n",
      "0.8227000308036805\n",
      "model test accuracy:\n",
      "0.9052142551611149\n",
      "step: 891\n",
      "model training accuracy:\n",
      "0.8227000308036805\n",
      "model test accuracy:\n",
      "0.9052142551611149\n",
      "step: 892\n",
      "model training accuracy:\n",
      "0.8227000308036805\n",
      "model test accuracy:\n",
      "0.9052142551611149\n",
      "step: 893\n",
      "model training accuracy:\n",
      "0.8227000308036805\n",
      "model test accuracy:\n",
      "0.9052142551611149\n",
      "step: 894\n",
      "model training accuracy:\n",
      "0.8227000308036805\n",
      "model test accuracy:\n",
      "0.9052142551611149\n",
      "step: 895\n",
      "model training accuracy:\n",
      "0.8739999932050705\n",
      "model test accuracy:\n",
      "0.9107916130078533\n",
      "step: 896\n",
      "model training accuracy:\n",
      "0.8739999932050705\n",
      "model test accuracy:\n",
      "0.9107916130078533\n",
      "step: 897\n",
      "model training accuracy:\n",
      "0.8739999932050705\n",
      "model test accuracy:\n",
      "0.9107916130078533\n",
      "step: 898\n",
      "model training accuracy:\n",
      "0.8739999932050705\n",
      "model test accuracy:\n",
      "0.9107916130078533\n",
      "step: 899\n",
      "model training accuracy:\n",
      "0.8739999932050705\n",
      "model test accuracy:\n",
      "0.9107916130078533\n",
      "step: 900\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9040379984065647\n",
      "step: 901\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9040379984065647\n",
      "step: 902\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9040379984065647\n",
      "step: 903\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9040379984065647\n",
      "step: 904\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9040379984065647\n",
      "step: 905\n",
      "model training accuracy:\n",
      "0.816999990940094\n",
      "model test accuracy:\n",
      "0.9112213780820821\n",
      "step: 906\n",
      "model training accuracy:\n",
      "0.816999990940094\n",
      "model test accuracy:\n",
      "0.9112213780820821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 907\n",
      "model training accuracy:\n",
      "0.816999990940094\n",
      "model test accuracy:\n",
      "0.9112213780820821\n",
      "step: 908\n",
      "model training accuracy:\n",
      "0.816999990940094\n",
      "model test accuracy:\n",
      "0.9112213780820821\n",
      "step: 909\n",
      "model training accuracy:\n",
      "0.816999990940094\n",
      "model test accuracy:\n",
      "0.9112213780820821\n",
      "step: 910\n",
      "model training accuracy:\n",
      "0.8987000036239624\n",
      "model test accuracy:\n",
      "0.9086367990425757\n",
      "step: 911\n",
      "model training accuracy:\n",
      "0.8987000036239624\n",
      "model test accuracy:\n",
      "0.9086367990425757\n",
      "step: 912\n",
      "model training accuracy:\n",
      "0.8987000036239624\n",
      "model test accuracy:\n",
      "0.9086367990425757\n",
      "step: 913\n",
      "model training accuracy:\n",
      "0.8987000036239624\n",
      "model test accuracy:\n",
      "0.9086367990425757\n",
      "step: 914\n",
      "model training accuracy:\n",
      "0.8987000036239624\n",
      "model test accuracy:\n",
      "0.9086367990425757\n",
      "step: 915\n",
      "model training accuracy:\n",
      "0.8302999895811082\n",
      "model test accuracy:\n",
      "0.9093439235672945\n",
      "step: 916\n",
      "model training accuracy:\n",
      "0.8302999895811082\n",
      "model test accuracy:\n",
      "0.9093439235672945\n",
      "step: 917\n",
      "model training accuracy:\n",
      "0.8302999895811082\n",
      "model test accuracy:\n",
      "0.9093439235672945\n",
      "step: 918\n",
      "model training accuracy:\n",
      "0.8302999895811082\n",
      "model test accuracy:\n",
      "0.9093439235672945\n",
      "step: 919\n",
      "model training accuracy:\n",
      "0.8302999895811082\n",
      "model test accuracy:\n",
      "0.9093439235672945\n",
      "step: 920\n",
      "model training accuracy:\n",
      "0.8891999843716621\n",
      "model test accuracy:\n",
      "0.9031398106122647\n",
      "step: 921\n",
      "model training accuracy:\n",
      "0.8891999843716621\n",
      "model test accuracy:\n",
      "0.9031398106122647\n",
      "step: 922\n",
      "model training accuracy:\n",
      "0.8891999843716621\n",
      "model test accuracy:\n",
      "0.9031398106122647\n",
      "step: 923\n",
      "model training accuracy:\n",
      "0.8891999843716621\n",
      "model test accuracy:\n",
      "0.9031398106122647\n",
      "step: 924\n",
      "model training accuracy:\n",
      "0.8891999843716621\n",
      "model test accuracy:\n",
      "0.9031398106122647\n",
      "step: 925\n",
      "model training accuracy:\n",
      "0.8094000151753425\n",
      "model test accuracy:\n",
      "0.9021628728312151\n",
      "step: 926\n",
      "model training accuracy:\n",
      "0.8094000151753425\n",
      "model test accuracy:\n",
      "0.9021628728312151\n",
      "step: 927\n",
      "model training accuracy:\n",
      "0.8094000151753425\n",
      "model test accuracy:\n",
      "0.9021628728312151\n",
      "step: 928\n",
      "model training accuracy:\n",
      "0.8094000151753425\n",
      "model test accuracy:\n",
      "0.9021628728312151\n",
      "step: 929\n",
      "model training accuracy:\n",
      "0.8094000151753425\n",
      "model test accuracy:\n",
      "0.9021628728312151\n",
      "step: 930\n",
      "model training accuracy:\n",
      "0.8454999637603761\n",
      "model test accuracy:\n",
      "0.90729039170985\n",
      "step: 931\n",
      "model training accuracy:\n",
      "0.8454999637603761\n",
      "model test accuracy:\n",
      "0.90729039170985\n",
      "step: 932\n",
      "model training accuracy:\n",
      "0.8454999637603761\n",
      "model test accuracy:\n",
      "0.90729039170985\n",
      "step: 933\n",
      "model training accuracy:\n",
      "0.8454999637603761\n",
      "model test accuracy:\n",
      "0.90729039170985\n",
      "step: 934\n",
      "model training accuracy:\n",
      "0.8454999637603761\n",
      "model test accuracy:\n",
      "0.90729039170985\n",
      "step: 935\n",
      "model training accuracy:\n",
      "0.889200024008751\n",
      "model test accuracy:\n",
      "0.9110397829121255\n",
      "step: 936\n",
      "model training accuracy:\n",
      "0.889200024008751\n",
      "model test accuracy:\n",
      "0.9110397829121255\n",
      "step: 937\n",
      "model training accuracy:\n",
      "0.889200024008751\n",
      "model test accuracy:\n",
      "0.9110397829121255\n",
      "step: 938\n",
      "model training accuracy:\n",
      "0.889200024008751\n",
      "model test accuracy:\n",
      "0.9110397829121255\n",
      "step: 939\n",
      "model training accuracy:\n",
      "0.889200024008751\n",
      "model test accuracy:\n",
      "0.9110397829121255\n",
      "step: 940\n",
      "model training accuracy:\n",
      "0.879700033068657\n",
      "model test accuracy:\n",
      "0.9009785433935743\n",
      "step: 941\n",
      "model training accuracy:\n",
      "0.879700033068657\n",
      "model test accuracy:\n",
      "0.9009785433935743\n",
      "step: 942\n",
      "model training accuracy:\n",
      "0.879700033068657\n",
      "model test accuracy:\n",
      "0.9009785433935743\n",
      "step: 943\n",
      "model training accuracy:\n",
      "0.879700033068657\n",
      "model test accuracy:\n",
      "0.9009785433935743\n",
      "step: 944\n",
      "model training accuracy:\n",
      "0.879700033068657\n",
      "model test accuracy:\n",
      "0.9009785433935743\n",
      "step: 945\n",
      "model training accuracy:\n",
      "0.9120000022649765\n",
      "model test accuracy:\n",
      "0.9068702476235808\n",
      "step: 946\n",
      "model training accuracy:\n",
      "0.9120000022649765\n",
      "model test accuracy:\n",
      "0.9068702476235808\n",
      "step: 947\n",
      "model training accuracy:\n",
      "0.9120000022649765\n",
      "model test accuracy:\n",
      "0.9068702476235808\n",
      "step: 948\n",
      "model training accuracy:\n",
      "0.9120000022649765\n",
      "model test accuracy:\n",
      "0.9068702476235808\n",
      "step: 949\n",
      "model training accuracy:\n",
      "0.9120000022649765\n",
      "model test accuracy:\n",
      "0.9068702476235808\n",
      "step: 950\n",
      "model training accuracy:\n",
      "0.8530999904870987\n",
      "model test accuracy:\n",
      "0.9053170383796795\n",
      "step: 951\n",
      "model training accuracy:\n",
      "0.8530999904870987\n",
      "model test accuracy:\n",
      "0.9053170383796795\n",
      "step: 952\n",
      "model training accuracy:\n",
      "0.8530999904870987\n",
      "model test accuracy:\n",
      "0.9053170383796795\n",
      "step: 953\n",
      "model training accuracy:\n",
      "0.8530999904870987\n",
      "model test accuracy:\n",
      "0.9053170383796795\n",
      "step: 954\n",
      "model training accuracy:\n",
      "0.8530999904870987\n",
      "model test accuracy:\n",
      "0.9053170383796795\n",
      "step: 955\n",
      "model training accuracy:\n",
      "0.9405000203847884\n",
      "model test accuracy:\n",
      "0.9116953382102243\n",
      "step: 956\n",
      "model training accuracy:\n",
      "0.9405000203847884\n",
      "model test accuracy:\n",
      "0.9116953382102243\n",
      "step: 957\n",
      "model training accuracy:\n",
      "0.9405000203847884\n",
      "model test accuracy:\n",
      "0.9116953382102243\n",
      "step: 958\n",
      "model training accuracy:\n",
      "0.9405000203847884\n",
      "model test accuracy:\n",
      "0.9116953382102243\n",
      "step: 959\n",
      "model training accuracy:\n",
      "0.9405000203847884\n",
      "model test accuracy:\n",
      "0.9116953382102243\n",
      "step: 960\n",
      "model training accuracy:\n",
      "0.896800016760826\n",
      "model test accuracy:\n",
      "0.9023521038022119\n",
      "step: 961\n",
      "model training accuracy:\n",
      "0.896800016760826\n",
      "model test accuracy:\n",
      "0.9023521038022119\n",
      "step: 962\n",
      "model training accuracy:\n",
      "0.896800016760826\n",
      "model test accuracy:\n",
      "0.9023521038022119\n",
      "step: 963\n",
      "model training accuracy:\n",
      "0.896800016760826\n",
      "model test accuracy:\n",
      "0.9023521038022119\n",
      "step: 964\n",
      "model training accuracy:\n",
      "0.896800016760826\n",
      "model test accuracy:\n",
      "0.9023521038022119\n",
      "step: 965\n",
      "model training accuracy:\n",
      "0.864499990940094\n",
      "model test accuracy:\n",
      "0.9084173815858387\n",
      "step: 966\n",
      "model training accuracy:\n",
      "0.864499990940094\n",
      "model test accuracy:\n",
      "0.9084173815858387\n",
      "step: 967\n",
      "model training accuracy:\n",
      "0.864499990940094\n",
      "model test accuracy:\n",
      "0.9084173815858387\n",
      "step: 968\n",
      "model training accuracy:\n",
      "0.864499990940094\n",
      "model test accuracy:\n",
      "0.9084173815858387\n",
      "step: 969\n",
      "model training accuracy:\n",
      "0.864499990940094\n",
      "model test accuracy:\n",
      "0.9084173815858387\n",
      "step: 970\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9095184703619066\n",
      "step: 971\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9095184703619066\n",
      "step: 972\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9095184703619066\n",
      "step: 973\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9095184703619066\n",
      "step: 974\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9095184703619066\n",
      "step: 975\n",
      "model training accuracy:\n",
      "0.7884999954700469\n",
      "model test accuracy:\n",
      "0.9069567827355461\n",
      "step: 976\n",
      "model training accuracy:\n",
      "0.7884999954700469\n",
      "model test accuracy:\n",
      "0.9069567827355461\n",
      "step: 977\n",
      "model training accuracy:\n",
      "0.7884999954700469\n",
      "model test accuracy:\n",
      "0.9069567827355461\n",
      "step: 978\n",
      "model training accuracy:\n",
      "0.7884999954700469\n",
      "model test accuracy:\n",
      "0.9069567827355461\n",
      "step: 979\n",
      "model training accuracy:\n",
      "0.7884999954700469\n",
      "model test accuracy:\n",
      "0.9069567827355461\n",
      "step: 980\n",
      "model training accuracy:\n",
      "0.8417000240087509\n",
      "model test accuracy:\n",
      "0.9012029096577986\n",
      "step: 981\n",
      "model training accuracy:\n",
      "0.8417000240087509\n",
      "model test accuracy:\n",
      "0.9012029096577986\n",
      "step: 982\n",
      "model training accuracy:\n",
      "0.8417000240087509\n",
      "model test accuracy:\n",
      "0.9012029096577986\n",
      "step: 983\n",
      "model training accuracy:\n",
      "0.8417000240087509\n",
      "model test accuracy:\n",
      "0.9012029096577986\n",
      "step: 984\n",
      "model training accuracy:\n",
      "0.8417000240087509\n",
      "model test accuracy:\n",
      "0.9012029096577986\n",
      "step: 985\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9062132029205608\n",
      "step: 986\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9062132029205608\n",
      "step: 987\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9062132029205608\n",
      "step: 988\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9062132029205608\n",
      "step: 989\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9062132029205608\n",
      "step: 990\n",
      "model training accuracy:\n",
      "0.9328999936580658\n",
      "model test accuracy:\n",
      "0.906781894348697\n",
      "step: 991\n",
      "model training accuracy:\n",
      "0.9328999936580658\n",
      "model test accuracy:\n",
      "0.906781894348697\n",
      "step: 992\n",
      "model training accuracy:\n",
      "0.9328999936580658\n",
      "model test accuracy:\n",
      "0.906781894348697\n",
      "step: 993\n",
      "model training accuracy:\n",
      "0.9328999936580658\n",
      "model test accuracy:\n",
      "0.906781894348697\n",
      "step: 994\n",
      "model training accuracy:\n",
      "0.9328999936580658\n",
      "model test accuracy:\n",
      "0.906781894348697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 995\n",
      "model training accuracy:\n",
      "0.8957824580280365\n",
      "model test accuracy:\n",
      "0.9033195458389925\n",
      "step: 996\n",
      "model training accuracy:\n",
      "0.8957824580280365\n",
      "model test accuracy:\n",
      "0.9033195458389925\n",
      "step: 997\n",
      "model training accuracy:\n",
      "0.8957824580280365\n",
      "model test accuracy:\n",
      "0.9033195458389925\n",
      "step: 998\n",
      "model training accuracy:\n",
      "0.8957824580280365\n",
      "model test accuracy:\n",
      "0.9033195458389925\n",
      "step: 999\n",
      "model training accuracy:\n",
      "0.8957824580280365\n",
      "model test accuracy:\n",
      "0.9033195458389925\n",
      "step: 1000\n",
      "model training accuracy:\n",
      "0.8815999746322631\n",
      "model test accuracy:\n",
      "0.9047588737102036\n",
      "step: 1001\n",
      "model training accuracy:\n",
      "0.8815999746322631\n",
      "model test accuracy:\n",
      "0.9047588737102036\n",
      "step: 1002\n",
      "model training accuracy:\n",
      "0.8815999746322631\n",
      "model test accuracy:\n",
      "0.9047588737102036\n",
      "step: 1003\n",
      "model training accuracy:\n",
      "0.8815999746322631\n",
      "model test accuracy:\n",
      "0.9047588737102036\n",
      "step: 1004\n",
      "model training accuracy:\n",
      "0.8815999746322631\n",
      "model test accuracy:\n",
      "0.9047588737102036\n",
      "step: 1005\n",
      "model training accuracy:\n",
      "0.8815999746322631\n",
      "model test accuracy:\n",
      "0.9017344224434872\n",
      "step: 1006\n",
      "model training accuracy:\n",
      "0.8815999746322631\n",
      "model test accuracy:\n",
      "0.9017344224434872\n",
      "step: 1007\n",
      "model training accuracy:\n",
      "0.8815999746322631\n",
      "model test accuracy:\n",
      "0.9017344224434872\n",
      "step: 1008\n",
      "model training accuracy:\n",
      "0.8815999746322631\n",
      "model test accuracy:\n",
      "0.9017344224434872\n",
      "step: 1009\n",
      "model training accuracy:\n",
      "0.8815999746322631\n",
      "model test accuracy:\n",
      "0.9017344224434872\n",
      "step: 1010\n",
      "model training accuracy:\n",
      "0.8872999918460847\n",
      "model test accuracy:\n",
      "0.909263053890814\n",
      "step: 1011\n",
      "model training accuracy:\n",
      "0.8872999918460847\n",
      "model test accuracy:\n",
      "0.909263053890814\n",
      "step: 1012\n",
      "model training accuracy:\n",
      "0.8872999918460847\n",
      "model test accuracy:\n",
      "0.909263053890814\n",
      "step: 1013\n",
      "model training accuracy:\n",
      "0.8872999918460847\n",
      "model test accuracy:\n",
      "0.909263053890814\n",
      "step: 1014\n",
      "model training accuracy:\n",
      "0.8872999918460847\n",
      "model test accuracy:\n",
      "0.909263053890814\n",
      "step: 1015\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9105808874838893\n",
      "step: 1016\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9105808874838893\n",
      "step: 1017\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9105808874838893\n",
      "step: 1018\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9105808874838893\n",
      "step: 1019\n",
      "model training accuracy:\n",
      "0.7676000097393989\n",
      "model test accuracy:\n",
      "0.9105808874838893\n",
      "step: 1020\n",
      "model training accuracy:\n",
      "0.8531000018119812\n",
      "model test accuracy:\n",
      "0.906752661171094\n",
      "step: 1021\n",
      "model training accuracy:\n",
      "0.8531000018119812\n",
      "model test accuracy:\n",
      "0.906752661171094\n",
      "step: 1022\n",
      "model training accuracy:\n",
      "0.8531000018119812\n",
      "model test accuracy:\n",
      "0.906752661171094\n",
      "step: 1023\n",
      "model training accuracy:\n",
      "0.8531000018119812\n",
      "model test accuracy:\n",
      "0.906752661171094\n",
      "step: 1024\n",
      "model training accuracy:\n",
      "0.8531000018119812\n",
      "model test accuracy:\n",
      "0.906752661171094\n",
      "step: 1025\n",
      "model training accuracy:\n",
      "0.9195999950170517\n",
      "model test accuracy:\n",
      "0.9065733742739883\n",
      "step: 1026\n",
      "model training accuracy:\n",
      "0.9195999950170517\n",
      "model test accuracy:\n",
      "0.9065733742739883\n",
      "step: 1027\n",
      "model training accuracy:\n",
      "0.9195999950170517\n",
      "model test accuracy:\n",
      "0.9065733742739883\n",
      "step: 1028\n",
      "model training accuracy:\n",
      "0.9195999950170517\n",
      "model test accuracy:\n",
      "0.9065733742739883\n",
      "step: 1029\n",
      "model training accuracy:\n",
      "0.9195999950170517\n",
      "model test accuracy:\n",
      "0.9065733742739883\n",
      "step: 1030\n",
      "model training accuracy:\n",
      "0.7714000061154365\n",
      "model test accuracy:\n",
      "0.9013111259515117\n",
      "step: 1031\n",
      "model training accuracy:\n",
      "0.7714000061154365\n",
      "model test accuracy:\n",
      "0.9013111259515117\n",
      "step: 1032\n",
      "model training accuracy:\n",
      "0.7714000061154365\n",
      "model test accuracy:\n",
      "0.9013111259515117\n",
      "step: 1033\n",
      "model training accuracy:\n",
      "0.7714000061154365\n",
      "model test accuracy:\n",
      "0.9013111259515117\n",
      "step: 1034\n",
      "model training accuracy:\n",
      "0.7714000061154365\n",
      "model test accuracy:\n",
      "0.9013111259515117\n",
      "step: 1035\n",
      "model training accuracy:\n",
      "0.9006000357866287\n",
      "model test accuracy:\n",
      "0.9008830507708888\n",
      "step: 1036\n",
      "model training accuracy:\n",
      "0.9006000357866287\n",
      "model test accuracy:\n",
      "0.9008830507708888\n",
      "step: 1037\n",
      "model training accuracy:\n",
      "0.9006000357866287\n",
      "model test accuracy:\n",
      "0.9008830507708888\n",
      "step: 1038\n",
      "model training accuracy:\n",
      "0.9006000357866287\n",
      "model test accuracy:\n",
      "0.9008830507708888\n",
      "step: 1039\n",
      "model training accuracy:\n",
      "0.9006000357866287\n",
      "model test accuracy:\n",
      "0.9008830507708888\n",
      "step: 1040\n",
      "model training accuracy:\n",
      "0.8740000158548354\n",
      "model test accuracy:\n",
      "0.9032021817787006\n",
      "step: 1041\n",
      "model training accuracy:\n",
      "0.8740000158548354\n",
      "model test accuracy:\n",
      "0.9032021817787006\n",
      "step: 1042\n",
      "model training accuracy:\n",
      "0.8740000158548354\n",
      "model test accuracy:\n",
      "0.9032021817787006\n",
      "step: 1043\n",
      "model training accuracy:\n",
      "0.8740000158548354\n",
      "model test accuracy:\n",
      "0.9032021817787006\n",
      "step: 1044\n",
      "model training accuracy:\n",
      "0.8740000158548354\n",
      "model test accuracy:\n",
      "0.9032021817787006\n",
      "step: 1045\n",
      "model training accuracy:\n",
      "0.9556999945640563\n",
      "model test accuracy:\n",
      "0.9101615133624431\n",
      "step: 1046\n",
      "model training accuracy:\n",
      "0.9556999945640563\n",
      "model test accuracy:\n",
      "0.9101615133624431\n",
      "step: 1047\n",
      "model training accuracy:\n",
      "0.9556999945640563\n",
      "model test accuracy:\n",
      "0.9101615133624431\n",
      "step: 1048\n",
      "model training accuracy:\n",
      "0.9556999945640563\n",
      "model test accuracy:\n",
      "0.9101615133624431\n",
      "step: 1049\n",
      "model training accuracy:\n",
      "0.9556999945640563\n",
      "model test accuracy:\n",
      "0.9101615133624431\n",
      "step: 1050\n",
      "model training accuracy:\n",
      "0.90630000770092\n",
      "model test accuracy:\n",
      "0.9004236415250001\n",
      "step: 1051\n",
      "model training accuracy:\n",
      "0.90630000770092\n",
      "model test accuracy:\n",
      "0.9004236415250001\n",
      "step: 1052\n",
      "model training accuracy:\n",
      "0.90630000770092\n",
      "model test accuracy:\n",
      "0.9004236415250001\n",
      "step: 1053\n",
      "model training accuracy:\n",
      "0.90630000770092\n",
      "model test accuracy:\n",
      "0.9004236415250001\n",
      "step: 1054\n",
      "model training accuracy:\n",
      "0.90630000770092\n",
      "model test accuracy:\n",
      "0.9004236415250001\n",
      "step: 1055\n",
      "model training accuracy:\n",
      "0.9024999660253524\n",
      "model test accuracy:\n",
      "0.9052739426120975\n",
      "step: 1056\n",
      "model training accuracy:\n",
      "0.9024999660253524\n",
      "model test accuracy:\n",
      "0.9052739426120975\n",
      "step: 1057\n",
      "model training accuracy:\n",
      "0.9024999660253524\n",
      "model test accuracy:\n",
      "0.9052739426120975\n",
      "step: 1058\n",
      "model training accuracy:\n",
      "0.9024999660253524\n",
      "model test accuracy:\n",
      "0.9052739426120975\n",
      "step: 1059\n",
      "model training accuracy:\n",
      "0.9024999660253524\n",
      "model test accuracy:\n",
      "0.9052739426120975\n",
      "step: 1060\n",
      "model training accuracy:\n",
      "0.8952249915345486\n",
      "model test accuracy:\n",
      "0.9047090113417826\n",
      "step: 1061\n",
      "model training accuracy:\n",
      "0.8952249915345486\n",
      "model test accuracy:\n",
      "0.9047090113417826\n",
      "step: 1062\n",
      "model training accuracy:\n",
      "0.8952249915345486\n",
      "model test accuracy:\n",
      "0.9047090113417826\n",
      "step: 1063\n",
      "model training accuracy:\n",
      "0.8952249915345486\n",
      "model test accuracy:\n",
      "0.9047090113417826\n",
      "step: 1064\n",
      "model training accuracy:\n",
      "0.8952249915345486\n",
      "model test accuracy:\n",
      "0.9047090113417826\n",
      "step: 1065\n",
      "model training accuracy:\n",
      "0.9025000226497649\n",
      "model test accuracy:\n",
      "0.9026980178613833\n",
      "step: 1066\n",
      "model training accuracy:\n",
      "0.9025000226497649\n",
      "model test accuracy:\n",
      "0.9026980178613833\n",
      "step: 1067\n",
      "model training accuracy:\n",
      "0.9025000226497649\n",
      "model test accuracy:\n",
      "0.9026980178613833\n",
      "step: 1068\n",
      "model training accuracy:\n",
      "0.9025000226497649\n",
      "model test accuracy:\n",
      "0.9026980178613833\n",
      "step: 1069\n",
      "model training accuracy:\n",
      "0.9025000226497649\n",
      "model test accuracy:\n",
      "0.9026980178613833\n",
      "step: 1070\n",
      "model training accuracy:\n",
      "0.9366999900341034\n",
      "model test accuracy:\n",
      "0.9037084270217067\n",
      "step: 1071\n",
      "model training accuracy:\n",
      "0.9366999900341034\n",
      "model test accuracy:\n",
      "0.9037084270217067\n",
      "step: 1072\n",
      "model training accuracy:\n",
      "0.9366999900341034\n",
      "model test accuracy:\n",
      "0.9037084270217067\n",
      "step: 1073\n",
      "model training accuracy:\n",
      "0.9366999900341034\n",
      "model test accuracy:\n",
      "0.9037084270217067\n",
      "step: 1074\n",
      "model training accuracy:\n",
      "0.9366999900341034\n",
      "model test accuracy:\n",
      "0.9037084270217067\n",
      "step: 1075\n",
      "model training accuracy:\n",
      "0.9271999990940094\n",
      "model test accuracy:\n",
      "0.9010430925680782\n",
      "step: 1076\n",
      "model training accuracy:\n",
      "0.9271999990940094\n",
      "model test accuracy:\n",
      "0.9010430925680782\n",
      "step: 1077\n",
      "model training accuracy:\n",
      "0.9271999990940094\n",
      "model test accuracy:\n",
      "0.9010430925680782\n",
      "step: 1078\n",
      "model training accuracy:\n",
      "0.9271999990940094\n",
      "model test accuracy:\n",
      "0.9010430925680782\n",
      "step: 1079\n",
      "model training accuracy:\n",
      "0.9271999990940094\n",
      "model test accuracy:\n",
      "0.9010430925680782\n",
      "step: 1080\n",
      "model training accuracy:\n",
      "0.9785000067949295\n",
      "model test accuracy:\n",
      "0.9034355501113135\n",
      "step: 1081\n",
      "model training accuracy:\n",
      "0.9785000067949295\n",
      "model test accuracy:\n",
      "0.9034355501113135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1082\n",
      "model training accuracy:\n",
      "0.9785000067949295\n",
      "model test accuracy:\n",
      "0.9034355501113135\n",
      "step: 1083\n",
      "model training accuracy:\n",
      "0.9785000067949295\n",
      "model test accuracy:\n",
      "0.9034355501113135\n",
      "step: 1084\n",
      "model training accuracy:\n",
      "0.9785000067949295\n",
      "model test accuracy:\n",
      "0.9034355501113135\n",
      "step: 1085\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9029439075840902\n",
      "step: 1086\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9029439075840902\n",
      "step: 1087\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9029439075840902\n",
      "step: 1088\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9029439075840902\n",
      "step: 1089\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9029439075840902\n",
      "step: 1090\n",
      "model training accuracy:\n",
      "0.9328999936580658\n",
      "model test accuracy:\n",
      "0.9025905457112733\n",
      "step: 1091\n",
      "model training accuracy:\n",
      "0.9328999936580658\n",
      "model test accuracy:\n",
      "0.9025905457112733\n",
      "step: 1092\n",
      "model training accuracy:\n",
      "0.9328999936580658\n",
      "model test accuracy:\n",
      "0.9025905457112733\n",
      "step: 1093\n",
      "model training accuracy:\n",
      "0.9328999936580658\n",
      "model test accuracy:\n",
      "0.9025905457112733\n",
      "step: 1094\n",
      "model training accuracy:\n",
      "0.9328999936580658\n",
      "model test accuracy:\n",
      "0.9025905457112733\n",
      "step: 1095\n",
      "model training accuracy:\n",
      "0.9595000249147415\n",
      "model test accuracy:\n",
      "0.9032696560169423\n",
      "step: 1096\n",
      "model training accuracy:\n",
      "0.9595000249147415\n",
      "model test accuracy:\n",
      "0.9032696560169423\n",
      "step: 1097\n",
      "model training accuracy:\n",
      "0.9595000249147415\n",
      "model test accuracy:\n",
      "0.9032696560169423\n",
      "step: 1098\n",
      "model training accuracy:\n",
      "0.9595000249147415\n",
      "model test accuracy:\n",
      "0.9032696560169423\n",
      "step: 1099\n",
      "model training accuracy:\n",
      "0.9595000249147415\n",
      "model test accuracy:\n",
      "0.9032696560169423\n",
      "step: 1100\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9063792428141173\n",
      "step: 1101\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9063792428141173\n",
      "step: 1102\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9063792428141173\n",
      "step: 1103\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9063792428141173\n",
      "step: 1104\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9063792428141173\n",
      "step: 1105\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9056924328683957\n",
      "step: 1106\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9056924328683957\n",
      "step: 1107\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9056924328683957\n",
      "step: 1108\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9056924328683957\n",
      "step: 1109\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9056924328683957\n",
      "step: 1110\n",
      "model training accuracy:\n",
      "0.8911000335216521\n",
      "model test accuracy:\n",
      "0.9028509091192051\n",
      "step: 1111\n",
      "model training accuracy:\n",
      "0.8911000335216521\n",
      "model test accuracy:\n",
      "0.9028509091192051\n",
      "step: 1112\n",
      "model training accuracy:\n",
      "0.8911000335216521\n",
      "model test accuracy:\n",
      "0.9028509091192051\n",
      "step: 1113\n",
      "model training accuracy:\n",
      "0.8911000335216521\n",
      "model test accuracy:\n",
      "0.9028509091192051\n",
      "step: 1114\n",
      "model training accuracy:\n",
      "0.8911000335216521\n",
      "model test accuracy:\n",
      "0.9028509091192051\n",
      "step: 1115\n",
      "model training accuracy:\n",
      "0.963300021290779\n",
      "model test accuracy:\n",
      "0.9049350560839164\n",
      "step: 1116\n",
      "model training accuracy:\n",
      "0.963300021290779\n",
      "model test accuracy:\n",
      "0.9049350560839164\n",
      "step: 1117\n",
      "model training accuracy:\n",
      "0.963300021290779\n",
      "model test accuracy:\n",
      "0.9049350560839164\n",
      "step: 1118\n",
      "model training accuracy:\n",
      "0.963300021290779\n",
      "model test accuracy:\n",
      "0.9049350560839164\n",
      "step: 1119\n",
      "model training accuracy:\n",
      "0.963300021290779\n",
      "model test accuracy:\n",
      "0.9049350560839164\n",
      "step: 1120\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.8995556958912156\n",
      "step: 1121\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.8995556958912156\n",
      "step: 1122\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.8995556958912156\n",
      "step: 1123\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.8995556958912156\n",
      "step: 1124\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.8995556958912156\n",
      "step: 1125\n",
      "model training accuracy:\n",
      "0.8958109037625559\n",
      "model test accuracy:\n",
      "0.9052792674595612\n",
      "step: 1126\n",
      "model training accuracy:\n",
      "0.8958109037625559\n",
      "model test accuracy:\n",
      "0.9052792674595612\n",
      "step: 1127\n",
      "model training accuracy:\n",
      "0.8958109037625559\n",
      "model test accuracy:\n",
      "0.9052792674595612\n",
      "step: 1128\n",
      "model training accuracy:\n",
      "0.8958109037625559\n",
      "model test accuracy:\n",
      "0.9052792674595612\n",
      "step: 1129\n",
      "model training accuracy:\n",
      "0.8958109037625559\n",
      "model test accuracy:\n",
      "0.9052792674595612\n",
      "step: 1130\n",
      "model training accuracy:\n",
      "0.8931606013271486\n",
      "model test accuracy:\n",
      "0.9108508484102509\n",
      "step: 1131\n",
      "model training accuracy:\n",
      "0.8931606013271486\n",
      "model test accuracy:\n",
      "0.9108508484102509\n",
      "step: 1132\n",
      "model training accuracy:\n",
      "0.8931606013271486\n",
      "model test accuracy:\n",
      "0.9108508484102509\n",
      "step: 1133\n",
      "model training accuracy:\n",
      "0.8931606013271486\n",
      "model test accuracy:\n",
      "0.9108508484102509\n",
      "step: 1134\n",
      "model training accuracy:\n",
      "0.8931606013271486\n",
      "model test accuracy:\n",
      "0.9108508484102509\n",
      "step: 1135\n",
      "model training accuracy:\n",
      "0.8934195783321479\n",
      "model test accuracy:\n",
      "0.9023275642846573\n",
      "step: 1136\n",
      "model training accuracy:\n",
      "0.8934195783321479\n",
      "model test accuracy:\n",
      "0.9023275642846573\n",
      "step: 1137\n",
      "model training accuracy:\n",
      "0.8934195783321479\n",
      "model test accuracy:\n",
      "0.9023275642846573\n",
      "step: 1138\n",
      "model training accuracy:\n",
      "0.8934195783321479\n",
      "model test accuracy:\n",
      "0.9023275642846573\n",
      "step: 1139\n",
      "model training accuracy:\n",
      "0.8934195783321479\n",
      "model test accuracy:\n",
      "0.9023275642846573\n",
      "step: 1140\n",
      "model training accuracy:\n",
      "0.9139000231027602\n",
      "model test accuracy:\n",
      "0.9019952487940803\n",
      "step: 1141\n",
      "model training accuracy:\n",
      "0.9139000231027602\n",
      "model test accuracy:\n",
      "0.9019952487940803\n",
      "step: 1142\n",
      "model training accuracy:\n",
      "0.9139000231027602\n",
      "model test accuracy:\n",
      "0.9019952487940803\n",
      "step: 1143\n",
      "model training accuracy:\n",
      "0.9139000231027602\n",
      "model test accuracy:\n",
      "0.9019952487940803\n",
      "step: 1144\n",
      "model training accuracy:\n",
      "0.9139000231027602\n",
      "model test accuracy:\n",
      "0.9019952487940803\n",
      "step: 1145\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.8996976573008915\n",
      "step: 1146\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.8996976573008915\n",
      "step: 1147\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.8996976573008915\n",
      "step: 1148\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.8996976573008915\n",
      "step: 1149\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.8996976573008915\n",
      "step: 1150\n",
      "model training accuracy:\n",
      "0.8933249862766627\n",
      "model test accuracy:\n",
      "0.9031037261872407\n",
      "step: 1151\n",
      "model training accuracy:\n",
      "0.8933249862766627\n",
      "model test accuracy:\n",
      "0.9031037261872407\n",
      "step: 1152\n",
      "model training accuracy:\n",
      "0.8933249862766627\n",
      "model test accuracy:\n",
      "0.9031037261872407\n",
      "step: 1153\n",
      "model training accuracy:\n",
      "0.8933249862766627\n",
      "model test accuracy:\n",
      "0.9031037261872407\n",
      "step: 1154\n",
      "model training accuracy:\n",
      "0.8933249862766627\n",
      "model test accuracy:\n",
      "0.9031037261872407\n",
      "step: 1155\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.9080426404930886\n",
      "step: 1156\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.9080426404930886\n",
      "step: 1157\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.9080426404930886\n",
      "step: 1158\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.9080426404930886\n",
      "step: 1159\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.9080426404930886\n",
      "step: 1160\n",
      "model training accuracy:\n",
      "0.9861000448465347\n",
      "model test accuracy:\n",
      "0.9109256540849242\n",
      "step: 1161\n",
      "model training accuracy:\n",
      "0.9861000448465347\n",
      "model test accuracy:\n",
      "0.9109256540849242\n",
      "step: 1162\n",
      "model training accuracy:\n",
      "0.9861000448465347\n",
      "model test accuracy:\n",
      "0.9109256540849242\n",
      "step: 1163\n",
      "model training accuracy:\n",
      "0.9861000448465347\n",
      "model test accuracy:\n",
      "0.9109256540849242\n",
      "step: 1164\n",
      "model training accuracy:\n",
      "0.9861000448465347\n",
      "model test accuracy:\n",
      "0.9109256540849242\n",
      "step: 1165\n",
      "model training accuracy:\n",
      "0.9385999882221221\n",
      "model test accuracy:\n",
      "0.9083923918642309\n",
      "step: 1166\n",
      "model training accuracy:\n",
      "0.9385999882221221\n",
      "model test accuracy:\n",
      "0.9083923918642309\n",
      "step: 1167\n",
      "model training accuracy:\n",
      "0.9385999882221221\n",
      "model test accuracy:\n",
      "0.9083923918642309\n",
      "step: 1168\n",
      "model training accuracy:\n",
      "0.9385999882221221\n",
      "model test accuracy:\n",
      "0.9083923918642309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1169\n",
      "model training accuracy:\n",
      "0.9385999882221221\n",
      "model test accuracy:\n",
      "0.9083923918642309\n",
      "step: 1170\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9111587258593953\n",
      "step: 1171\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9111587258593953\n",
      "step: 1172\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9111587258593953\n",
      "step: 1173\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9111587258593953\n",
      "step: 1174\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9111587258593953\n",
      "step: 1175\n",
      "model training accuracy:\n",
      "0.8945184341836409\n",
      "model test accuracy:\n",
      "0.9039540642074818\n",
      "step: 1176\n",
      "model training accuracy:\n",
      "0.8945184341836409\n",
      "model test accuracy:\n",
      "0.9039540642074818\n",
      "step: 1177\n",
      "model training accuracy:\n",
      "0.8945184341836409\n",
      "model test accuracy:\n",
      "0.9039540642074818\n",
      "step: 1178\n",
      "model training accuracy:\n",
      "0.8945184341836409\n",
      "model test accuracy:\n",
      "0.9039540642074818\n",
      "step: 1179\n",
      "model training accuracy:\n",
      "0.8945184341836409\n",
      "model test accuracy:\n",
      "0.9039540642074818\n",
      "step: 1180\n",
      "model training accuracy:\n",
      "0.9233999574184417\n",
      "model test accuracy:\n",
      "0.9024379617640322\n",
      "step: 1181\n",
      "model training accuracy:\n",
      "0.9233999574184417\n",
      "model test accuracy:\n",
      "0.9024379617640322\n",
      "step: 1182\n",
      "model training accuracy:\n",
      "0.9233999574184417\n",
      "model test accuracy:\n",
      "0.9024379617640322\n",
      "step: 1183\n",
      "model training accuracy:\n",
      "0.9233999574184417\n",
      "model test accuracy:\n",
      "0.9024379617640322\n",
      "step: 1184\n",
      "model training accuracy:\n",
      "0.9233999574184417\n",
      "model test accuracy:\n",
      "0.9024379617640322\n",
      "step: 1185\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9015502329259477\n",
      "step: 1186\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9015502329259477\n",
      "step: 1187\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9015502329259477\n",
      "step: 1188\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9015502329259477\n",
      "step: 1189\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9015502329259477\n",
      "step: 1190\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.8989991329152575\n",
      "step: 1191\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.8989991329152575\n",
      "step: 1192\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.8989991329152575\n",
      "step: 1193\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.8989991329152575\n",
      "step: 1194\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.8989991329152575\n",
      "step: 1195\n",
      "model training accuracy:\n",
      "0.9651999741792678\n",
      "model test accuracy:\n",
      "0.9055692203657835\n",
      "step: 1196\n",
      "model training accuracy:\n",
      "0.9651999741792678\n",
      "model test accuracy:\n",
      "0.9055692203657835\n",
      "step: 1197\n",
      "model training accuracy:\n",
      "0.9651999741792678\n",
      "model test accuracy:\n",
      "0.9055692203657835\n",
      "step: 1198\n",
      "model training accuracy:\n",
      "0.9651999741792678\n",
      "model test accuracy:\n",
      "0.9055692203657835\n",
      "step: 1199\n",
      "model training accuracy:\n",
      "0.9651999741792678\n",
      "model test accuracy:\n",
      "0.9055692203657835\n",
      "step: 1200\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.9001039443413695\n",
      "step: 1201\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.9001039443413695\n",
      "step: 1202\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.9001039443413695\n",
      "step: 1203\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.9001039443413695\n",
      "step: 1204\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.9001039443413695\n",
      "step: 1205\n",
      "model training accuracy:\n",
      "0.9747000217437743\n",
      "model test accuracy:\n",
      "0.9011819371896265\n",
      "step: 1206\n",
      "model training accuracy:\n",
      "0.9747000217437743\n",
      "model test accuracy:\n",
      "0.9011819371896265\n",
      "step: 1207\n",
      "model training accuracy:\n",
      "0.9747000217437743\n",
      "model test accuracy:\n",
      "0.9011819371896265\n",
      "step: 1208\n",
      "model training accuracy:\n",
      "0.9747000217437743\n",
      "model test accuracy:\n",
      "0.9011819371896265\n",
      "step: 1209\n",
      "model training accuracy:\n",
      "0.9747000217437743\n",
      "model test accuracy:\n",
      "0.9011819371896265\n",
      "step: 1210\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.900416699156153\n",
      "step: 1211\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.900416699156153\n",
      "step: 1212\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.900416699156153\n",
      "step: 1213\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.900416699156153\n",
      "step: 1214\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.900416699156153\n",
      "step: 1215\n",
      "model training accuracy:\n",
      "0.8937525874939368\n",
      "model test accuracy:\n",
      "0.9015146348398516\n",
      "step: 1216\n",
      "model training accuracy:\n",
      "0.8937525874939368\n",
      "model test accuracy:\n",
      "0.9015146348398516\n",
      "step: 1217\n",
      "model training accuracy:\n",
      "0.8937525874939368\n",
      "model test accuracy:\n",
      "0.9015146348398516\n",
      "step: 1218\n",
      "model training accuracy:\n",
      "0.8937525874939368\n",
      "model test accuracy:\n",
      "0.9015146348398516\n",
      "step: 1219\n",
      "model training accuracy:\n",
      "0.8937525874939368\n",
      "model test accuracy:\n",
      "0.9015146348398516\n",
      "step: 1220\n",
      "model training accuracy:\n",
      "0.9062999737262725\n",
      "model test accuracy:\n",
      "0.9061614234868378\n",
      "step: 1221\n",
      "model training accuracy:\n",
      "0.9062999737262725\n",
      "model test accuracy:\n",
      "0.9061614234868378\n",
      "step: 1222\n",
      "model training accuracy:\n",
      "0.9062999737262725\n",
      "model test accuracy:\n",
      "0.9061614234868378\n",
      "step: 1223\n",
      "model training accuracy:\n",
      "0.9062999737262725\n",
      "model test accuracy:\n",
      "0.9061614234868378\n",
      "step: 1224\n",
      "model training accuracy:\n",
      "0.9062999737262725\n",
      "model test accuracy:\n",
      "0.9061614234868378\n",
      "step: 1225\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9038040190048139\n",
      "step: 1226\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9038040190048139\n",
      "step: 1227\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9038040190048139\n",
      "step: 1228\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9038040190048139\n",
      "step: 1229\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9038040190048139\n",
      "step: 1230\n",
      "model training accuracy:\n",
      "0.9576000267267226\n",
      "model test accuracy:\n",
      "0.907817895271879\n",
      "step: 1231\n",
      "model training accuracy:\n",
      "0.9576000267267226\n",
      "model test accuracy:\n",
      "0.907817895271879\n",
      "step: 1232\n",
      "model training accuracy:\n",
      "0.9576000267267226\n",
      "model test accuracy:\n",
      "0.907817895271879\n",
      "step: 1233\n",
      "model training accuracy:\n",
      "0.9576000267267226\n",
      "model test accuracy:\n",
      "0.907817895271879\n",
      "step: 1234\n",
      "model training accuracy:\n",
      "0.9576000267267226\n",
      "model test accuracy:\n",
      "0.907817895271879\n",
      "step: 1235\n",
      "model training accuracy:\n",
      "0.9385999882221221\n",
      "model test accuracy:\n",
      "0.9031866349743178\n",
      "step: 1236\n",
      "model training accuracy:\n",
      "0.9385999882221221\n",
      "model test accuracy:\n",
      "0.9031866349743178\n",
      "step: 1237\n",
      "model training accuracy:\n",
      "0.9385999882221221\n",
      "model test accuracy:\n",
      "0.9031866349743178\n",
      "step: 1238\n",
      "model training accuracy:\n",
      "0.9385999882221221\n",
      "model test accuracy:\n",
      "0.9031866349743178\n",
      "step: 1239\n",
      "model training accuracy:\n",
      "0.9385999882221221\n",
      "model test accuracy:\n",
      "0.9031866349743178\n",
      "step: 1240\n",
      "model training accuracy:\n",
      "0.894854681666389\n",
      "model test accuracy:\n",
      "0.9005947496152343\n",
      "step: 1241\n",
      "model training accuracy:\n",
      "0.894854681666389\n",
      "model test accuracy:\n",
      "0.9005947496152343\n",
      "step: 1242\n",
      "model training accuracy:\n",
      "0.894854681666389\n",
      "model test accuracy:\n",
      "0.9005947496152343\n",
      "step: 1243\n",
      "model training accuracy:\n",
      "0.894854681666389\n",
      "model test accuracy:\n",
      "0.9005947496152343\n",
      "step: 1244\n",
      "model training accuracy:\n",
      "0.894854681666389\n",
      "model test accuracy:\n",
      "0.9005947496152343\n",
      "step: 1245\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9029110217455097\n",
      "step: 1246\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9029110217455097\n",
      "step: 1247\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9029110217455097\n",
      "step: 1248\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9029110217455097\n",
      "step: 1249\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9029110217455097\n",
      "step: 1250\n",
      "model training accuracy:\n",
      "0.9860999995470046\n",
      "model test accuracy:\n",
      "0.8989534949162693\n",
      "step: 1251\n",
      "model training accuracy:\n",
      "0.9860999995470046\n",
      "model test accuracy:\n",
      "0.8989534949162693\n",
      "step: 1252\n",
      "model training accuracy:\n",
      "0.9860999995470046\n",
      "model test accuracy:\n",
      "0.8989534949162693\n",
      "step: 1253\n",
      "model training accuracy:\n",
      "0.9860999995470046\n",
      "model test accuracy:\n",
      "0.8989534949162693\n",
      "step: 1254\n",
      "model training accuracy:\n",
      "0.9860999995470046\n",
      "model test accuracy:\n",
      "0.8989534949162693\n",
      "step: 1255\n",
      "model training accuracy:\n",
      "0.8739999932050704\n",
      "model test accuracy:\n",
      "0.9102977044635668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1256\n",
      "model training accuracy:\n",
      "0.8739999932050704\n",
      "model test accuracy:\n",
      "0.9102977044635668\n",
      "step: 1257\n",
      "model training accuracy:\n",
      "0.8739999932050704\n",
      "model test accuracy:\n",
      "0.9102977044635668\n",
      "step: 1258\n",
      "model training accuracy:\n",
      "0.8739999932050704\n",
      "model test accuracy:\n",
      "0.9102977044635668\n",
      "step: 1259\n",
      "model training accuracy:\n",
      "0.8739999932050704\n",
      "model test accuracy:\n",
      "0.9102977044635668\n",
      "step: 1260\n",
      "model training accuracy:\n",
      "0.9310000067949296\n",
      "model test accuracy:\n",
      "0.9045339550312973\n",
      "step: 1261\n",
      "model training accuracy:\n",
      "0.9310000067949296\n",
      "model test accuracy:\n",
      "0.9045339550312973\n",
      "step: 1262\n",
      "model training accuracy:\n",
      "0.9310000067949296\n",
      "model test accuracy:\n",
      "0.9045339550312973\n",
      "step: 1263\n",
      "model training accuracy:\n",
      "0.9310000067949296\n",
      "model test accuracy:\n",
      "0.9045339550312973\n",
      "step: 1264\n",
      "model training accuracy:\n",
      "0.9310000067949296\n",
      "model test accuracy:\n",
      "0.9045339550312973\n",
      "step: 1265\n",
      "model training accuracy:\n",
      "0.8954308975518979\n",
      "model test accuracy:\n",
      "0.904949644374034\n",
      "step: 1266\n",
      "model training accuracy:\n",
      "0.8954308975518979\n",
      "model test accuracy:\n",
      "0.904949644374034\n",
      "step: 1267\n",
      "model training accuracy:\n",
      "0.8954308975518979\n",
      "model test accuracy:\n",
      "0.904949644374034\n",
      "step: 1268\n",
      "model training accuracy:\n",
      "0.8954308975518979\n",
      "model test accuracy:\n",
      "0.904949644374034\n",
      "step: 1269\n",
      "model training accuracy:\n",
      "0.8954308975518979\n",
      "model test accuracy:\n",
      "0.904949644374034\n",
      "step: 1270\n",
      "model training accuracy:\n",
      "0.8949817887005026\n",
      "model test accuracy:\n",
      "0.9087714528364854\n",
      "step: 1271\n",
      "model training accuracy:\n",
      "0.8949817887005026\n",
      "model test accuracy:\n",
      "0.9087714528364854\n",
      "step: 1272\n",
      "model training accuracy:\n",
      "0.8949817887005026\n",
      "model test accuracy:\n",
      "0.9087714528364854\n",
      "step: 1273\n",
      "model training accuracy:\n",
      "0.8949817887005026\n",
      "model test accuracy:\n",
      "0.9087714528364854\n",
      "step: 1274\n",
      "model training accuracy:\n",
      "0.8949817887005026\n",
      "model test accuracy:\n",
      "0.9087714528364854\n",
      "step: 1275\n",
      "model training accuracy:\n",
      "0.8939013285501596\n",
      "model test accuracy:\n",
      "0.9058643233301176\n",
      "step: 1276\n",
      "model training accuracy:\n",
      "0.8939013285501596\n",
      "model test accuracy:\n",
      "0.9058643233301176\n",
      "step: 1277\n",
      "model training accuracy:\n",
      "0.8939013285501596\n",
      "model test accuracy:\n",
      "0.9058643233301176\n",
      "step: 1278\n",
      "model training accuracy:\n",
      "0.8939013285501596\n",
      "model test accuracy:\n",
      "0.9058643233301176\n",
      "step: 1279\n",
      "model training accuracy:\n",
      "0.8939013285501596\n",
      "model test accuracy:\n",
      "0.9058643233301176\n",
      "step: 1280\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9105785254210773\n",
      "step: 1281\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9105785254210773\n",
      "step: 1282\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9105785254210773\n",
      "step: 1283\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9105785254210773\n",
      "step: 1284\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9105785254210773\n",
      "step: 1285\n",
      "model training accuracy:\n",
      "0.8956145205795495\n",
      "model test accuracy:\n",
      "0.9059322920239277\n",
      "step: 1286\n",
      "model training accuracy:\n",
      "0.8956145205795495\n",
      "model test accuracy:\n",
      "0.9059322920239277\n",
      "step: 1287\n",
      "model training accuracy:\n",
      "0.8956145205795495\n",
      "model test accuracy:\n",
      "0.9059322920239277\n",
      "step: 1288\n",
      "model training accuracy:\n",
      "0.8956145205795495\n",
      "model test accuracy:\n",
      "0.9059322920239277\n",
      "step: 1289\n",
      "model training accuracy:\n",
      "0.8956145205795495\n",
      "model test accuracy:\n",
      "0.9059322920239277\n",
      "step: 1290\n",
      "model training accuracy:\n",
      "0.9196000063419342\n",
      "model test accuracy:\n",
      "0.9097587558017486\n",
      "step: 1291\n",
      "model training accuracy:\n",
      "0.9196000063419342\n",
      "model test accuracy:\n",
      "0.9097587558017486\n",
      "step: 1292\n",
      "model training accuracy:\n",
      "0.9196000063419342\n",
      "model test accuracy:\n",
      "0.9097587558017486\n",
      "step: 1293\n",
      "model training accuracy:\n",
      "0.9196000063419342\n",
      "model test accuracy:\n",
      "0.9097587558017486\n",
      "step: 1294\n",
      "model training accuracy:\n",
      "0.9196000063419342\n",
      "model test accuracy:\n",
      "0.9097587558017486\n",
      "step: 1295\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.8989539884624024\n",
      "step: 1296\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.8989539884624024\n",
      "step: 1297\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.8989539884624024\n",
      "step: 1298\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.8989539884624024\n",
      "step: 1299\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.8989539884624024\n",
      "step: 1300\n",
      "model training accuracy:\n",
      "0.8941486114005883\n",
      "model test accuracy:\n",
      "0.9114979906655873\n",
      "step: 1301\n",
      "model training accuracy:\n",
      "0.8941486114005883\n",
      "model test accuracy:\n",
      "0.9114979906655873\n",
      "step: 1302\n",
      "model training accuracy:\n",
      "0.8941486114005883\n",
      "model test accuracy:\n",
      "0.9114979906655873\n",
      "step: 1303\n",
      "model training accuracy:\n",
      "0.8941486114005883\n",
      "model test accuracy:\n",
      "0.9114979906655873\n",
      "step: 1304\n",
      "model training accuracy:\n",
      "0.8941486114005883\n",
      "model test accuracy:\n",
      "0.9114979906655873\n",
      "step: 1305\n",
      "model training accuracy:\n",
      "0.8936728980716758\n",
      "model test accuracy:\n",
      "0.9012060066320129\n",
      "step: 1306\n",
      "model training accuracy:\n",
      "0.8936728980716758\n",
      "model test accuracy:\n",
      "0.9012060066320129\n",
      "step: 1307\n",
      "model training accuracy:\n",
      "0.8936728980716758\n",
      "model test accuracy:\n",
      "0.9012060066320129\n",
      "step: 1308\n",
      "model training accuracy:\n",
      "0.8936728980716758\n",
      "model test accuracy:\n",
      "0.9012060066320129\n",
      "step: 1309\n",
      "model training accuracy:\n",
      "0.8936728980716758\n",
      "model test accuracy:\n",
      "0.9012060066320129\n",
      "step: 1310\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9047408587209249\n",
      "step: 1311\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9047408587209249\n",
      "step: 1312\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9047408587209249\n",
      "step: 1313\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9047408587209249\n",
      "step: 1314\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9047408587209249\n",
      "step: 1315\n",
      "model training accuracy:\n",
      "0.8942386342347823\n",
      "model test accuracy:\n",
      "0.908712873756453\n",
      "step: 1316\n",
      "model training accuracy:\n",
      "0.8942386342347823\n",
      "model test accuracy:\n",
      "0.908712873756453\n",
      "step: 1317\n",
      "model training accuracy:\n",
      "0.8942386342347823\n",
      "model test accuracy:\n",
      "0.908712873756453\n",
      "step: 1318\n",
      "model training accuracy:\n",
      "0.8942386342347823\n",
      "model test accuracy:\n",
      "0.908712873756453\n",
      "step: 1319\n",
      "model training accuracy:\n",
      "0.8942386342347823\n",
      "model test accuracy:\n",
      "0.908712873756453\n",
      "step: 1320\n",
      "model training accuracy:\n",
      "0.9233999574184417\n",
      "model test accuracy:\n",
      "0.902857905509259\n",
      "step: 1321\n",
      "model training accuracy:\n",
      "0.9233999574184417\n",
      "model test accuracy:\n",
      "0.902857905509259\n",
      "step: 1322\n",
      "model training accuracy:\n",
      "0.9233999574184417\n",
      "model test accuracy:\n",
      "0.902857905509259\n",
      "step: 1323\n",
      "model training accuracy:\n",
      "0.9233999574184417\n",
      "model test accuracy:\n",
      "0.902857905509259\n",
      "step: 1324\n",
      "model training accuracy:\n",
      "0.9233999574184417\n",
      "model test accuracy:\n",
      "0.902857905509259\n",
      "step: 1325\n",
      "model training accuracy:\n",
      "0.9139000117778777\n",
      "model test accuracy:\n",
      "0.9104190295053579\n",
      "step: 1326\n",
      "model training accuracy:\n",
      "0.9139000117778777\n",
      "model test accuracy:\n",
      "0.9104190295053579\n",
      "step: 1327\n",
      "model training accuracy:\n",
      "0.9139000117778777\n",
      "model test accuracy:\n",
      "0.9104190295053579\n",
      "step: 1328\n",
      "model training accuracy:\n",
      "0.9139000117778777\n",
      "model test accuracy:\n",
      "0.9104190295053579\n",
      "step: 1329\n",
      "model training accuracy:\n",
      "0.9139000117778777\n",
      "model test accuracy:\n",
      "0.9104190295053579\n",
      "step: 1330\n",
      "model training accuracy:\n",
      "0.9157999646663665\n",
      "model test accuracy:\n",
      "0.905507114055503\n",
      "step: 1331\n",
      "model training accuracy:\n",
      "0.9157999646663665\n",
      "model test accuracy:\n",
      "0.905507114055503\n",
      "step: 1332\n",
      "model training accuracy:\n",
      "0.9157999646663665\n",
      "model test accuracy:\n",
      "0.905507114055503\n",
      "step: 1333\n",
      "model training accuracy:\n",
      "0.9157999646663665\n",
      "model test accuracy:\n",
      "0.905507114055503\n",
      "step: 1334\n",
      "model training accuracy:\n",
      "0.9157999646663665\n",
      "model test accuracy:\n",
      "0.905507114055503\n",
      "step: 1335\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9116048704975828\n",
      "step: 1336\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9116048704975828\n",
      "step: 1337\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9116048704975828\n",
      "step: 1338\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9116048704975828\n",
      "step: 1339\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9116048704975828\n",
      "step: 1340\n",
      "model training accuracy:\n",
      "0.8936076197628969\n",
      "model test accuracy:\n",
      "0.905547904847718\n",
      "step: 1341\n",
      "model training accuracy:\n",
      "0.8936076197628969\n",
      "model test accuracy:\n",
      "0.905547904847718\n",
      "step: 1342\n",
      "model training accuracy:\n",
      "0.8936076197628969\n",
      "model test accuracy:\n",
      "0.905547904847718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1343\n",
      "model training accuracy:\n",
      "0.8936076197628969\n",
      "model test accuracy:\n",
      "0.905547904847718\n",
      "step: 1344\n",
      "model training accuracy:\n",
      "0.8936076197628969\n",
      "model test accuracy:\n",
      "0.905547904847718\n",
      "step: 1345\n",
      "model training accuracy:\n",
      "0.9690000158548355\n",
      "model test accuracy:\n",
      "0.91132554565918\n",
      "step: 1346\n",
      "model training accuracy:\n",
      "0.9690000158548355\n",
      "model test accuracy:\n",
      "0.91132554565918\n",
      "step: 1347\n",
      "model training accuracy:\n",
      "0.9690000158548355\n",
      "model test accuracy:\n",
      "0.91132554565918\n",
      "step: 1348\n",
      "model training accuracy:\n",
      "0.9690000158548355\n",
      "model test accuracy:\n",
      "0.91132554565918\n",
      "step: 1349\n",
      "model training accuracy:\n",
      "0.9690000158548355\n",
      "model test accuracy:\n",
      "0.91132554565918\n",
      "step: 1350\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9008061074929977\n",
      "step: 1351\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9008061074929977\n",
      "step: 1352\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9008061074929977\n",
      "step: 1353\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9008061074929977\n",
      "step: 1354\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9008061074929977\n",
      "step: 1355\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9065887465846637\n",
      "step: 1356\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9065887465846637\n",
      "step: 1357\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9065887465846637\n",
      "step: 1358\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9065887465846637\n",
      "step: 1359\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9065887465846637\n",
      "step: 1360\n",
      "model training accuracy:\n",
      "0.9157999646663665\n",
      "model test accuracy:\n",
      "0.9033724896012733\n",
      "step: 1361\n",
      "model training accuracy:\n",
      "0.9157999646663665\n",
      "model test accuracy:\n",
      "0.9033724896012733\n",
      "step: 1362\n",
      "model training accuracy:\n",
      "0.9157999646663665\n",
      "model test accuracy:\n",
      "0.9033724896012733\n",
      "step: 1363\n",
      "model training accuracy:\n",
      "0.9157999646663665\n",
      "model test accuracy:\n",
      "0.9033724896012733\n",
      "step: 1364\n",
      "model training accuracy:\n",
      "0.9157999646663665\n",
      "model test accuracy:\n",
      "0.9033724896012733\n",
      "step: 1365\n",
      "model training accuracy:\n",
      "0.9196000063419342\n",
      "model test accuracy:\n",
      "0.903307686030188\n",
      "step: 1366\n",
      "model training accuracy:\n",
      "0.9196000063419342\n",
      "model test accuracy:\n",
      "0.903307686030188\n",
      "step: 1367\n",
      "model training accuracy:\n",
      "0.9196000063419342\n",
      "model test accuracy:\n",
      "0.903307686030188\n",
      "step: 1368\n",
      "model training accuracy:\n",
      "0.9196000063419342\n",
      "model test accuracy:\n",
      "0.903307686030188\n",
      "step: 1369\n",
      "model training accuracy:\n",
      "0.9196000063419342\n",
      "model test accuracy:\n",
      "0.903307686030188\n",
      "step: 1370\n",
      "model training accuracy:\n",
      "0.9081999719142914\n",
      "model test accuracy:\n",
      "0.9097595270763148\n",
      "step: 1371\n",
      "model training accuracy:\n",
      "0.9081999719142914\n",
      "model test accuracy:\n",
      "0.9097595270763148\n",
      "step: 1372\n",
      "model training accuracy:\n",
      "0.9081999719142914\n",
      "model test accuracy:\n",
      "0.9097595270763148\n",
      "step: 1373\n",
      "model training accuracy:\n",
      "0.9081999719142914\n",
      "model test accuracy:\n",
      "0.9097595270763148\n",
      "step: 1374\n",
      "model training accuracy:\n",
      "0.9081999719142914\n",
      "model test accuracy:\n",
      "0.9097595270763148\n",
      "step: 1375\n",
      "model training accuracy:\n",
      "0.9708999687433242\n",
      "model test accuracy:\n",
      "0.9114387971750516\n",
      "step: 1376\n",
      "model training accuracy:\n",
      "0.9708999687433242\n",
      "model test accuracy:\n",
      "0.9114387971750516\n",
      "step: 1377\n",
      "model training accuracy:\n",
      "0.9708999687433242\n",
      "model test accuracy:\n",
      "0.9114387971750516\n",
      "step: 1378\n",
      "model training accuracy:\n",
      "0.9708999687433242\n",
      "model test accuracy:\n",
      "0.9114387971750516\n",
      "step: 1379\n",
      "model training accuracy:\n",
      "0.9708999687433242\n",
      "model test accuracy:\n",
      "0.9114387971750516\n",
      "step: 1380\n",
      "model training accuracy:\n",
      "0.9613999664783477\n",
      "model test accuracy:\n",
      "0.9109878647499254\n",
      "step: 1381\n",
      "model training accuracy:\n",
      "0.9613999664783477\n",
      "model test accuracy:\n",
      "0.9109878647499254\n",
      "step: 1382\n",
      "model training accuracy:\n",
      "0.9613999664783477\n",
      "model test accuracy:\n",
      "0.9109878647499254\n",
      "step: 1383\n",
      "model training accuracy:\n",
      "0.9613999664783477\n",
      "model test accuracy:\n",
      "0.9109878647499254\n",
      "step: 1384\n",
      "model training accuracy:\n",
      "0.9613999664783477\n",
      "model test accuracy:\n",
      "0.9109878647499254\n",
      "step: 1385\n",
      "model training accuracy:\n",
      "0.8955185494789587\n",
      "model test accuracy:\n",
      "0.9019143327098937\n",
      "step: 1386\n",
      "model training accuracy:\n",
      "0.8955185494789587\n",
      "model test accuracy:\n",
      "0.9019143327098937\n",
      "step: 1387\n",
      "model training accuracy:\n",
      "0.8955185494789587\n",
      "model test accuracy:\n",
      "0.9019143327098937\n",
      "step: 1388\n",
      "model training accuracy:\n",
      "0.8955185494789587\n",
      "model test accuracy:\n",
      "0.9019143327098937\n",
      "step: 1389\n",
      "model training accuracy:\n",
      "0.8955185494789587\n",
      "model test accuracy:\n",
      "0.9019143327098937\n",
      "step: 1390\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9102519831358923\n",
      "step: 1391\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9102519831358923\n",
      "step: 1392\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9102519831358923\n",
      "step: 1393\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9102519831358923\n",
      "step: 1394\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9102519831358923\n",
      "step: 1395\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.907496769837192\n",
      "step: 1396\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.907496769837192\n",
      "step: 1397\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.907496769837192\n",
      "step: 1398\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.907496769837192\n",
      "step: 1399\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.907496769837192\n",
      "step: 1400\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9067147040080253\n",
      "step: 1401\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9067147040080253\n",
      "step: 1402\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9067147040080253\n",
      "step: 1403\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9067147040080253\n",
      "step: 1404\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9067147040080253\n",
      "step: 1405\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9052432613749365\n",
      "step: 1406\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9052432613749365\n",
      "step: 1407\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9052432613749365\n",
      "step: 1408\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9052432613749365\n",
      "step: 1409\n",
      "model training accuracy:\n",
      "0.9043999755382537\n",
      "model test accuracy:\n",
      "0.9052432613749365\n",
      "step: 1410\n",
      "model training accuracy:\n",
      "0.894217890785951\n",
      "model test accuracy:\n",
      "0.9028100346247403\n",
      "step: 1411\n",
      "model training accuracy:\n",
      "0.894217890785951\n",
      "model test accuracy:\n",
      "0.9028100346247403\n",
      "step: 1412\n",
      "model training accuracy:\n",
      "0.894217890785951\n",
      "model test accuracy:\n",
      "0.9028100346247403\n",
      "step: 1413\n",
      "model training accuracy:\n",
      "0.894217890785951\n",
      "model test accuracy:\n",
      "0.9028100346247403\n",
      "step: 1414\n",
      "model training accuracy:\n",
      "0.894217890785951\n",
      "model test accuracy:\n",
      "0.9028100346247403\n",
      "step: 1415\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9073673660154192\n",
      "step: 1416\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9073673660154192\n",
      "step: 1417\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9073673660154192\n",
      "step: 1418\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9073673660154192\n",
      "step: 1419\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9073673660154192\n",
      "step: 1420\n",
      "model training accuracy:\n",
      "0.8950978944965304\n",
      "model test accuracy:\n",
      "0.9017524237236108\n",
      "step: 1421\n",
      "model training accuracy:\n",
      "0.8950978944965304\n",
      "model test accuracy:\n",
      "0.9017524237236108\n",
      "step: 1422\n",
      "model training accuracy:\n",
      "0.8950978944965304\n",
      "model test accuracy:\n",
      "0.9017524237236108\n",
      "step: 1423\n",
      "model training accuracy:\n",
      "0.8950978944965304\n",
      "model test accuracy:\n",
      "0.9017524237236108\n",
      "step: 1424\n",
      "model training accuracy:\n",
      "0.8950978944965304\n",
      "model test accuracy:\n",
      "0.9017524237236108\n",
      "step: 1425\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9028474387362837\n",
      "step: 1426\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9028474387362837\n",
      "step: 1427\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9028474387362837\n",
      "step: 1428\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9028474387362837\n",
      "step: 1429\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9028474387362837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1430\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9085038092866957\n",
      "step: 1431\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9085038092866957\n",
      "step: 1432\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9085038092866957\n",
      "step: 1433\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9085038092866957\n",
      "step: 1434\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9085038092866957\n",
      "step: 1435\n",
      "model training accuracy:\n",
      "0.8940048120778931\n",
      "model test accuracy:\n",
      "0.9071935456693511\n",
      "step: 1436\n",
      "model training accuracy:\n",
      "0.8940048120778931\n",
      "model test accuracy:\n",
      "0.9071935456693511\n",
      "step: 1437\n",
      "model training accuracy:\n",
      "0.8940048120778931\n",
      "model test accuracy:\n",
      "0.9071935456693511\n",
      "step: 1438\n",
      "model training accuracy:\n",
      "0.8940048120778931\n",
      "model test accuracy:\n",
      "0.9071935456693511\n",
      "step: 1439\n",
      "model training accuracy:\n",
      "0.8940048120778931\n",
      "model test accuracy:\n",
      "0.9071935456693511\n",
      "step: 1440\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9093693794040395\n",
      "step: 1441\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9093693794040395\n",
      "step: 1442\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9093693794040395\n",
      "step: 1443\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9093693794040395\n",
      "step: 1444\n",
      "model training accuracy:\n",
      "0.930999995470047\n",
      "model test accuracy:\n",
      "0.9093693794040395\n",
      "step: 1445\n",
      "model training accuracy:\n",
      "0.8957858007897966\n",
      "model test accuracy:\n",
      "0.8995649628418265\n",
      "step: 1446\n",
      "model training accuracy:\n",
      "0.8957858007897966\n",
      "model test accuracy:\n",
      "0.8995649628418265\n",
      "step: 1447\n",
      "model training accuracy:\n",
      "0.8957858007897966\n",
      "model test accuracy:\n",
      "0.8995649628418265\n",
      "step: 1448\n",
      "model training accuracy:\n",
      "0.8957858007897966\n",
      "model test accuracy:\n",
      "0.8995649628418265\n",
      "step: 1449\n",
      "model training accuracy:\n",
      "0.8957858007897966\n",
      "model test accuracy:\n",
      "0.8995649628418265\n",
      "step: 1450\n",
      "model training accuracy:\n",
      "0.8937847130791228\n",
      "model test accuracy:\n",
      "0.902309335179234\n",
      "step: 1451\n",
      "model training accuracy:\n",
      "0.8937847130791228\n",
      "model test accuracy:\n",
      "0.902309335179234\n",
      "step: 1452\n",
      "model training accuracy:\n",
      "0.8937847130791228\n",
      "model test accuracy:\n",
      "0.902309335179234\n",
      "step: 1453\n",
      "model training accuracy:\n",
      "0.8937847130791228\n",
      "model test accuracy:\n",
      "0.902309335179234\n",
      "step: 1454\n",
      "model training accuracy:\n",
      "0.8937847130791228\n",
      "model test accuracy:\n",
      "0.902309335179234\n",
      "step: 1455\n",
      "model training accuracy:\n",
      "0.9461999809741974\n",
      "model test accuracy:\n",
      "0.9101611934418539\n",
      "step: 1456\n",
      "model training accuracy:\n",
      "0.9461999809741974\n",
      "model test accuracy:\n",
      "0.9101611934418539\n",
      "step: 1457\n",
      "model training accuracy:\n",
      "0.9461999809741974\n",
      "model test accuracy:\n",
      "0.9101611934418539\n",
      "step: 1458\n",
      "model training accuracy:\n",
      "0.9461999809741974\n",
      "model test accuracy:\n",
      "0.9101611934418539\n",
      "step: 1459\n",
      "model training accuracy:\n",
      "0.9461999809741974\n",
      "model test accuracy:\n",
      "0.9101611934418539\n",
      "step: 1460\n",
      "model training accuracy:\n",
      "0.8952846930893236\n",
      "model test accuracy:\n",
      "0.8993732498839957\n",
      "step: 1461\n",
      "model training accuracy:\n",
      "0.8952846930893236\n",
      "model test accuracy:\n",
      "0.8993732498839957\n",
      "step: 1462\n",
      "model training accuracy:\n",
      "0.8952846930893236\n",
      "model test accuracy:\n",
      "0.8993732498839957\n",
      "step: 1463\n",
      "model training accuracy:\n",
      "0.8952846930893236\n",
      "model test accuracy:\n",
      "0.8993732498839957\n",
      "step: 1464\n",
      "model training accuracy:\n",
      "0.8952846930893236\n",
      "model test accuracy:\n",
      "0.8993732498839957\n",
      "step: 1465\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9029641812922051\n",
      "step: 1466\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9029641812922051\n",
      "step: 1467\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9029641812922051\n",
      "step: 1468\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9029641812922051\n",
      "step: 1469\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9029641812922051\n",
      "step: 1470\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.8997627502247022\n",
      "step: 1471\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.8997627502247022\n",
      "step: 1472\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.8997627502247022\n",
      "step: 1473\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.8997627502247022\n",
      "step: 1474\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.8997627502247022\n",
      "step: 1475\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9003162067387782\n",
      "step: 1476\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9003162067387782\n",
      "step: 1477\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9003162067387782\n",
      "step: 1478\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9003162067387782\n",
      "step: 1479\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9003162067387782\n",
      "step: 1480\n",
      "model training accuracy:\n",
      "0.9291000086069107\n",
      "model test accuracy:\n",
      "0.9093548858429854\n",
      "step: 1481\n",
      "model training accuracy:\n",
      "0.9291000086069107\n",
      "model test accuracy:\n",
      "0.9093548858429854\n",
      "step: 1482\n",
      "model training accuracy:\n",
      "0.9291000086069107\n",
      "model test accuracy:\n",
      "0.9093548858429854\n",
      "step: 1483\n",
      "model training accuracy:\n",
      "0.9291000086069107\n",
      "model test accuracy:\n",
      "0.9093548858429854\n",
      "step: 1484\n",
      "model training accuracy:\n",
      "0.9291000086069107\n",
      "model test accuracy:\n",
      "0.9093548858429854\n",
      "step: 1485\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.9041910501793586\n",
      "step: 1486\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.9041910501793586\n",
      "step: 1487\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.9041910501793586\n",
      "step: 1488\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.9041910501793586\n",
      "step: 1489\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.9041910501793586\n",
      "step: 1490\n",
      "model training accuracy:\n",
      "0.8931680142173019\n",
      "model test accuracy:\n",
      "0.8998622732183714\n",
      "step: 1491\n",
      "model training accuracy:\n",
      "0.8931680142173019\n",
      "model test accuracy:\n",
      "0.8998622732183714\n",
      "step: 1492\n",
      "model training accuracy:\n",
      "0.8931680142173019\n",
      "model test accuracy:\n",
      "0.8998622732183714\n",
      "step: 1493\n",
      "model training accuracy:\n",
      "0.8931680142173019\n",
      "model test accuracy:\n",
      "0.8998622732183714\n",
      "step: 1494\n",
      "model training accuracy:\n",
      "0.8931680142173019\n",
      "model test accuracy:\n",
      "0.8998622732183714\n",
      "step: 1495\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9049120384905066\n",
      "step: 1496\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9049120384905066\n",
      "step: 1497\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9049120384905066\n",
      "step: 1498\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9049120384905066\n",
      "step: 1499\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9049120384905066\n",
      "step: 1500\n",
      "model training accuracy:\n",
      "0.8937538362233879\n",
      "model test accuracy:\n",
      "0.9066718209991144\n",
      "step: 1501\n",
      "model training accuracy:\n",
      "0.8937538362233879\n",
      "model test accuracy:\n",
      "0.9066718209991144\n",
      "step: 1502\n",
      "model training accuracy:\n",
      "0.8937538362233879\n",
      "model test accuracy:\n",
      "0.9066718209991144\n",
      "step: 1503\n",
      "model training accuracy:\n",
      "0.8937538362233879\n",
      "model test accuracy:\n",
      "0.9066718209991144\n",
      "step: 1504\n",
      "model training accuracy:\n",
      "0.8937538362233879\n",
      "model test accuracy:\n",
      "0.9066718209991144\n",
      "step: 1505\n",
      "model training accuracy:\n",
      "0.9632999759912492\n",
      "model test accuracy:\n",
      "0.911409218604719\n",
      "step: 1506\n",
      "model training accuracy:\n",
      "0.9632999759912492\n",
      "model test accuracy:\n",
      "0.911409218604719\n",
      "step: 1507\n",
      "model training accuracy:\n",
      "0.9632999759912492\n",
      "model test accuracy:\n",
      "0.911409218604719\n",
      "step: 1508\n",
      "model training accuracy:\n",
      "0.9632999759912492\n",
      "model test accuracy:\n",
      "0.911409218604719\n",
      "step: 1509\n",
      "model training accuracy:\n",
      "0.9632999759912492\n",
      "model test accuracy:\n",
      "0.911409218604719\n",
      "step: 1510\n",
      "model training accuracy:\n",
      "0.9366999900341034\n",
      "model test accuracy:\n",
      "0.9115320616504272\n",
      "step: 1511\n",
      "model training accuracy:\n",
      "0.9366999900341034\n",
      "model test accuracy:\n",
      "0.9115320616504272\n",
      "step: 1512\n",
      "model training accuracy:\n",
      "0.9366999900341034\n",
      "model test accuracy:\n",
      "0.9115320616504272\n",
      "step: 1513\n",
      "model training accuracy:\n",
      "0.9366999900341034\n",
      "model test accuracy:\n",
      "0.9115320616504272\n",
      "step: 1514\n",
      "model training accuracy:\n",
      "0.9366999900341034\n",
      "model test accuracy:\n",
      "0.9115320616504272\n",
      "step: 1515\n",
      "model training accuracy:\n",
      "0.9480999904870987\n",
      "model test accuracy:\n",
      "0.9029049551430062\n",
      "step: 1516\n",
      "model training accuracy:\n",
      "0.9480999904870987\n",
      "model test accuracy:\n",
      "0.9029049551430062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1517\n",
      "model training accuracy:\n",
      "0.9480999904870987\n",
      "model test accuracy:\n",
      "0.9029049551430062\n",
      "step: 1518\n",
      "model training accuracy:\n",
      "0.9480999904870987\n",
      "model test accuracy:\n",
      "0.9029049551430062\n",
      "step: 1519\n",
      "model training accuracy:\n",
      "0.9480999904870987\n",
      "model test accuracy:\n",
      "0.9029049551430062\n",
      "step: 1520\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9112860817418466\n",
      "step: 1521\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9112860817418466\n",
      "step: 1522\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9112860817418466\n",
      "step: 1523\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9112860817418466\n",
      "step: 1524\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9112860817418466\n",
      "step: 1525\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9044736966229077\n",
      "step: 1526\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9044736966229077\n",
      "step: 1527\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9044736966229077\n",
      "step: 1528\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9044736966229077\n",
      "step: 1529\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9044736966229077\n",
      "step: 1530\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9041590826210907\n",
      "step: 1531\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9041590826210907\n",
      "step: 1532\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9041590826210907\n",
      "step: 1533\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9041590826210907\n",
      "step: 1534\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9041590826210907\n",
      "step: 1535\n",
      "model training accuracy:\n",
      "0.8935764989757715\n",
      "model test accuracy:\n",
      "0.9094045229995251\n",
      "step: 1536\n",
      "model training accuracy:\n",
      "0.8935764989757715\n",
      "model test accuracy:\n",
      "0.9094045229995251\n",
      "step: 1537\n",
      "model training accuracy:\n",
      "0.8935764989757715\n",
      "model test accuracy:\n",
      "0.9094045229995251\n",
      "step: 1538\n",
      "model training accuracy:\n",
      "0.8935764989757715\n",
      "model test accuracy:\n",
      "0.9094045229995251\n",
      "step: 1539\n",
      "model training accuracy:\n",
      "0.8935764989757715\n",
      "model test accuracy:\n",
      "0.9094045229995251\n",
      "step: 1540\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9089954249207123\n",
      "step: 1541\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9089954249207123\n",
      "step: 1542\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9089954249207123\n",
      "step: 1543\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9089954249207123\n",
      "step: 1544\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9089954249207123\n",
      "step: 1545\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9089898364310689\n",
      "step: 1546\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9089898364310689\n",
      "step: 1547\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9089898364310689\n",
      "step: 1548\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9089898364310689\n",
      "step: 1549\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9089898364310689\n",
      "step: 1550\n",
      "model training accuracy:\n",
      "0.9481000357866286\n",
      "model test accuracy:\n",
      "0.9019695005872366\n",
      "step: 1551\n",
      "model training accuracy:\n",
      "0.9481000357866286\n",
      "model test accuracy:\n",
      "0.9019695005872366\n",
      "step: 1552\n",
      "model training accuracy:\n",
      "0.9481000357866286\n",
      "model test accuracy:\n",
      "0.9019695005872366\n",
      "step: 1553\n",
      "model training accuracy:\n",
      "0.9481000357866286\n",
      "model test accuracy:\n",
      "0.9019695005872366\n",
      "step: 1554\n",
      "model training accuracy:\n",
      "0.9481000357866286\n",
      "model test accuracy:\n",
      "0.9019695005872366\n",
      "step: 1555\n",
      "model training accuracy:\n",
      "0.893314704902991\n",
      "model test accuracy:\n",
      "0.8988720376163679\n",
      "step: 1556\n",
      "model training accuracy:\n",
      "0.893314704902991\n",
      "model test accuracy:\n",
      "0.8988720376163679\n",
      "step: 1557\n",
      "model training accuracy:\n",
      "0.893314704902991\n",
      "model test accuracy:\n",
      "0.8988720376163679\n",
      "step: 1558\n",
      "model training accuracy:\n",
      "0.893314704902991\n",
      "model test accuracy:\n",
      "0.8988720376163679\n",
      "step: 1559\n",
      "model training accuracy:\n",
      "0.893314704902991\n",
      "model test accuracy:\n",
      "0.8988720376163679\n",
      "step: 1560\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9007010641248333\n",
      "step: 1561\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9007010641248333\n",
      "step: 1562\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9007010641248333\n",
      "step: 1563\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9007010641248333\n",
      "step: 1564\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9007010641248333\n",
      "step: 1565\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.9027992631633478\n",
      "step: 1566\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.9027992631633478\n",
      "step: 1567\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.9027992631633478\n",
      "step: 1568\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.9027992631633478\n",
      "step: 1569\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.9027992631633478\n",
      "step: 1570\n",
      "model training accuracy:\n",
      "0.9766000086069107\n",
      "model test accuracy:\n",
      "0.9086061714869028\n",
      "step: 1571\n",
      "model training accuracy:\n",
      "0.9766000086069107\n",
      "model test accuracy:\n",
      "0.9086061714869028\n",
      "step: 1572\n",
      "model training accuracy:\n",
      "0.9766000086069107\n",
      "model test accuracy:\n",
      "0.9086061714869028\n",
      "step: 1573\n",
      "model training accuracy:\n",
      "0.9766000086069107\n",
      "model test accuracy:\n",
      "0.9086061714869028\n",
      "step: 1574\n",
      "model training accuracy:\n",
      "0.9766000086069107\n",
      "model test accuracy:\n",
      "0.9086061714869028\n",
      "step: 1575\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9011496655208189\n",
      "step: 1576\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9011496655208189\n",
      "step: 1577\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9011496655208189\n",
      "step: 1578\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9011496655208189\n",
      "step: 1579\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9011496655208189\n",
      "step: 1580\n",
      "model training accuracy:\n",
      "0.9234000140428542\n",
      "model test accuracy:\n",
      "0.911501536092819\n",
      "step: 1581\n",
      "model training accuracy:\n",
      "0.9234000140428542\n",
      "model test accuracy:\n",
      "0.911501536092819\n",
      "step: 1582\n",
      "model training accuracy:\n",
      "0.9234000140428542\n",
      "model test accuracy:\n",
      "0.911501536092819\n",
      "step: 1583\n",
      "model training accuracy:\n",
      "0.9234000140428542\n",
      "model test accuracy:\n",
      "0.911501536092819\n",
      "step: 1584\n",
      "model training accuracy:\n",
      "0.9234000140428542\n",
      "model test accuracy:\n",
      "0.911501536092819\n",
      "step: 1585\n",
      "model training accuracy:\n",
      "0.9747000104188919\n",
      "model test accuracy:\n",
      "0.906642558583539\n",
      "step: 1586\n",
      "model training accuracy:\n",
      "0.9747000104188919\n",
      "model test accuracy:\n",
      "0.906642558583539\n",
      "step: 1587\n",
      "model training accuracy:\n",
      "0.9747000104188919\n",
      "model test accuracy:\n",
      "0.906642558583539\n",
      "step: 1588\n",
      "model training accuracy:\n",
      "0.9747000104188919\n",
      "model test accuracy:\n",
      "0.906642558583539\n",
      "step: 1589\n",
      "model training accuracy:\n",
      "0.9747000104188919\n",
      "model test accuracy:\n",
      "0.906642558583539\n",
      "step: 1590\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9046340508321123\n",
      "step: 1591\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9046340508321123\n",
      "step: 1592\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9046340508321123\n",
      "step: 1593\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9046340508321123\n",
      "step: 1594\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9046340508321123\n",
      "step: 1595\n",
      "model training accuracy:\n",
      "0.8930000317096709\n",
      "model test accuracy:\n",
      "0.9115377187396277\n",
      "step: 1596\n",
      "model training accuracy:\n",
      "0.8930000317096709\n",
      "model test accuracy:\n",
      "0.9115377187396277\n",
      "step: 1597\n",
      "model training accuracy:\n",
      "0.8930000317096709\n",
      "model test accuracy:\n",
      "0.9115377187396277\n",
      "step: 1598\n",
      "model training accuracy:\n",
      "0.8930000317096709\n",
      "model test accuracy:\n",
      "0.9115377187396277\n",
      "step: 1599\n",
      "model training accuracy:\n",
      "0.8930000317096709\n",
      "model test accuracy:\n",
      "0.9115377187396277\n",
      "step: 1600\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.9078098632710206\n",
      "step: 1601\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.9078098632710206\n",
      "step: 1602\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.9078098632710206\n",
      "step: 1603\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.9078098632710206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1604\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.9078098632710206\n",
      "step: 1605\n",
      "model training accuracy:\n",
      "0.8940721106114465\n",
      "model test accuracy:\n",
      "0.9031343274224998\n",
      "step: 1606\n",
      "model training accuracy:\n",
      "0.8940721106114465\n",
      "model test accuracy:\n",
      "0.9031343274224998\n",
      "step: 1607\n",
      "model training accuracy:\n",
      "0.8940721106114465\n",
      "model test accuracy:\n",
      "0.9031343274224998\n",
      "step: 1608\n",
      "model training accuracy:\n",
      "0.8940721106114465\n",
      "model test accuracy:\n",
      "0.9031343274224998\n",
      "step: 1609\n",
      "model training accuracy:\n",
      "0.8940721106114465\n",
      "model test accuracy:\n",
      "0.9031343274224998\n",
      "step: 1610\n",
      "model training accuracy:\n",
      "0.8954522853003457\n",
      "model test accuracy:\n",
      "0.899245078340439\n",
      "step: 1611\n",
      "model training accuracy:\n",
      "0.8954522853003457\n",
      "model test accuracy:\n",
      "0.899245078340439\n",
      "step: 1612\n",
      "model training accuracy:\n",
      "0.8954522853003457\n",
      "model test accuracy:\n",
      "0.899245078340439\n",
      "step: 1613\n",
      "model training accuracy:\n",
      "0.8954522853003457\n",
      "model test accuracy:\n",
      "0.899245078340439\n",
      "step: 1614\n",
      "model training accuracy:\n",
      "0.8954522853003457\n",
      "model test accuracy:\n",
      "0.899245078340439\n",
      "step: 1615\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.9060258652960963\n",
      "step: 1616\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.9060258652960963\n",
      "step: 1617\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.9060258652960963\n",
      "step: 1618\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.9060258652960963\n",
      "step: 1619\n",
      "model training accuracy:\n",
      "0.9423999959230422\n",
      "model test accuracy:\n",
      "0.9060258652960963\n",
      "step: 1620\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9038867000242562\n",
      "step: 1621\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9038867000242562\n",
      "step: 1622\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9038867000242562\n",
      "step: 1623\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9038867000242562\n",
      "step: 1624\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9038867000242562\n",
      "step: 1625\n",
      "model training accuracy:\n",
      "0.8950863997419414\n",
      "model test accuracy:\n",
      "0.9093793737080988\n",
      "step: 1626\n",
      "model training accuracy:\n",
      "0.8950863997419414\n",
      "model test accuracy:\n",
      "0.9093793737080988\n",
      "step: 1627\n",
      "model training accuracy:\n",
      "0.8950863997419414\n",
      "model test accuracy:\n",
      "0.9093793737080988\n",
      "step: 1628\n",
      "model training accuracy:\n",
      "0.8950863997419414\n",
      "model test accuracy:\n",
      "0.9093793737080988\n",
      "step: 1629\n",
      "model training accuracy:\n",
      "0.8950863997419414\n",
      "model test accuracy:\n",
      "0.9093793737080988\n",
      "step: 1630\n",
      "model training accuracy:\n",
      "0.8950403886202506\n",
      "model test accuracy:\n",
      "0.9032542193902617\n",
      "step: 1631\n",
      "model training accuracy:\n",
      "0.8950403886202506\n",
      "model test accuracy:\n",
      "0.9032542193902617\n",
      "step: 1632\n",
      "model training accuracy:\n",
      "0.8950403886202506\n",
      "model test accuracy:\n",
      "0.9032542193902617\n",
      "step: 1633\n",
      "model training accuracy:\n",
      "0.8950403886202506\n",
      "model test accuracy:\n",
      "0.9032542193902617\n",
      "step: 1634\n",
      "model training accuracy:\n",
      "0.8950403886202506\n",
      "model test accuracy:\n",
      "0.9032542193902617\n",
      "step: 1635\n",
      "model training accuracy:\n",
      "0.9614000344276428\n",
      "model test accuracy:\n",
      "0.9062508742323102\n",
      "step: 1636\n",
      "model training accuracy:\n",
      "0.9614000344276428\n",
      "model test accuracy:\n",
      "0.9062508742323102\n",
      "step: 1637\n",
      "model training accuracy:\n",
      "0.9614000344276428\n",
      "model test accuracy:\n",
      "0.9062508742323102\n",
      "step: 1638\n",
      "model training accuracy:\n",
      "0.9614000344276428\n",
      "model test accuracy:\n",
      "0.9062508742323102\n",
      "step: 1639\n",
      "model training accuracy:\n",
      "0.9614000344276428\n",
      "model test accuracy:\n",
      "0.9062508742323102\n",
      "step: 1640\n",
      "model training accuracy:\n",
      "0.9063000190258026\n",
      "model test accuracy:\n",
      "0.903519388069985\n",
      "step: 1641\n",
      "model training accuracy:\n",
      "0.9063000190258026\n",
      "model test accuracy:\n",
      "0.903519388069985\n",
      "step: 1642\n",
      "model training accuracy:\n",
      "0.9063000190258026\n",
      "model test accuracy:\n",
      "0.903519388069985\n",
      "step: 1643\n",
      "model training accuracy:\n",
      "0.9063000190258026\n",
      "model test accuracy:\n",
      "0.903519388069985\n",
      "step: 1644\n",
      "model training accuracy:\n",
      "0.9063000190258026\n",
      "model test accuracy:\n",
      "0.903519388069985\n",
      "step: 1645\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9048057253719365\n",
      "step: 1646\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9048057253719365\n",
      "step: 1647\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9048057253719365\n",
      "step: 1648\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9048057253719365\n",
      "step: 1649\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9048057253719365\n",
      "step: 1650\n",
      "model training accuracy:\n",
      "0.8931755710904653\n",
      "model test accuracy:\n",
      "0.9031457190224629\n",
      "step: 1651\n",
      "model training accuracy:\n",
      "0.8931755710904653\n",
      "model test accuracy:\n",
      "0.9031457190224629\n",
      "step: 1652\n",
      "model training accuracy:\n",
      "0.8931755710904653\n",
      "model test accuracy:\n",
      "0.9031457190224629\n",
      "step: 1653\n",
      "model training accuracy:\n",
      "0.8931755710904653\n",
      "model test accuracy:\n",
      "0.9031457190224629\n",
      "step: 1654\n",
      "model training accuracy:\n",
      "0.8931755710904653\n",
      "model test accuracy:\n",
      "0.9031457190224629\n",
      "step: 1655\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9083538627626548\n",
      "step: 1656\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9083538627626548\n",
      "step: 1657\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9083538627626548\n",
      "step: 1658\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9083538627626548\n",
      "step: 1659\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9083538627626548\n",
      "step: 1660\n",
      "model training accuracy:\n",
      "0.9709000140428543\n",
      "model test accuracy:\n",
      "0.9011153477959092\n",
      "step: 1661\n",
      "model training accuracy:\n",
      "0.9709000140428543\n",
      "model test accuracy:\n",
      "0.9011153477959092\n",
      "step: 1662\n",
      "model training accuracy:\n",
      "0.9709000140428543\n",
      "model test accuracy:\n",
      "0.9011153477959092\n",
      "step: 1663\n",
      "model training accuracy:\n",
      "0.9709000140428543\n",
      "model test accuracy:\n",
      "0.9011153477959092\n",
      "step: 1664\n",
      "model training accuracy:\n",
      "0.9709000140428543\n",
      "model test accuracy:\n",
      "0.9011153477959092\n",
      "step: 1665\n",
      "model training accuracy:\n",
      "0.9974999886751176\n",
      "model test accuracy:\n",
      "0.9109360327675083\n",
      "step: 1666\n",
      "model training accuracy:\n",
      "0.9974999886751176\n",
      "model test accuracy:\n",
      "0.9109360327675083\n",
      "step: 1667\n",
      "model training accuracy:\n",
      "0.9974999886751176\n",
      "model test accuracy:\n",
      "0.9109360327675083\n",
      "step: 1668\n",
      "model training accuracy:\n",
      "0.9974999886751176\n",
      "model test accuracy:\n",
      "0.9109360327675083\n",
      "step: 1669\n",
      "model training accuracy:\n",
      "0.9974999886751176\n",
      "model test accuracy:\n",
      "0.9109360327675083\n",
      "step: 1670\n",
      "model training accuracy:\n",
      "0.9347999578714371\n",
      "model test accuracy:\n",
      "0.9093293822611934\n",
      "step: 1671\n",
      "model training accuracy:\n",
      "0.9347999578714371\n",
      "model test accuracy:\n",
      "0.9093293822611934\n",
      "step: 1672\n",
      "model training accuracy:\n",
      "0.9347999578714371\n",
      "model test accuracy:\n",
      "0.9093293822611934\n",
      "step: 1673\n",
      "model training accuracy:\n",
      "0.9347999578714371\n",
      "model test accuracy:\n",
      "0.9093293822611934\n",
      "step: 1674\n",
      "model training accuracy:\n",
      "0.9347999578714371\n",
      "model test accuracy:\n",
      "0.9093293822611934\n",
      "step: 1675\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9061674140189543\n",
      "step: 1676\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9061674140189543\n",
      "step: 1677\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9061674140189543\n",
      "step: 1678\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9061674140189543\n",
      "step: 1679\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9061674140189543\n",
      "step: 1680\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.9104672996397161\n",
      "step: 1681\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.9104672996397161\n",
      "step: 1682\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.9104672996397161\n",
      "step: 1683\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.9104672996397161\n",
      "step: 1684\n",
      "model training accuracy:\n",
      "0.9613999778032302\n",
      "model test accuracy:\n",
      "0.9104672996397161\n",
      "step: 1685\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.9097072939778537\n",
      "step: 1686\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.9097072939778537\n",
      "step: 1687\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.9097072939778537\n",
      "step: 1688\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.9097072939778537\n",
      "step: 1689\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.9097072939778537\n",
      "step: 1690\n",
      "model training accuracy:\n",
      "0.8933214333467558\n",
      "model test accuracy:\n",
      "0.8995931983318843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1691\n",
      "model training accuracy:\n",
      "0.8933214333467558\n",
      "model test accuracy:\n",
      "0.8995931983318843\n",
      "step: 1692\n",
      "model training accuracy:\n",
      "0.8933214333467558\n",
      "model test accuracy:\n",
      "0.8995931983318843\n",
      "step: 1693\n",
      "model training accuracy:\n",
      "0.8933214333467558\n",
      "model test accuracy:\n",
      "0.8995931983318843\n",
      "step: 1694\n",
      "model training accuracy:\n",
      "0.8933214333467558\n",
      "model test accuracy:\n",
      "0.8995931983318843\n",
      "step: 1695\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9096034501229162\n",
      "step: 1696\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9096034501229162\n",
      "step: 1697\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9096034501229162\n",
      "step: 1698\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9096034501229162\n",
      "step: 1699\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9096034501229162\n",
      "step: 1700\n",
      "model training accuracy:\n",
      "0.8932064424687247\n",
      "model test accuracy:\n",
      "0.907120706286417\n",
      "step: 1701\n",
      "model training accuracy:\n",
      "0.8932064424687247\n",
      "model test accuracy:\n",
      "0.907120706286417\n",
      "step: 1702\n",
      "model training accuracy:\n",
      "0.8932064424687247\n",
      "model test accuracy:\n",
      "0.907120706286417\n",
      "step: 1703\n",
      "model training accuracy:\n",
      "0.8932064424687247\n",
      "model test accuracy:\n",
      "0.907120706286417\n",
      "step: 1704\n",
      "model training accuracy:\n",
      "0.8932064424687247\n",
      "model test accuracy:\n",
      "0.907120706286417\n",
      "step: 1705\n",
      "model training accuracy:\n",
      "0.9899000072479247\n",
      "model test accuracy:\n",
      "0.9049236037094461\n",
      "step: 1706\n",
      "model training accuracy:\n",
      "0.9899000072479247\n",
      "model test accuracy:\n",
      "0.9049236037094461\n",
      "step: 1707\n",
      "model training accuracy:\n",
      "0.9899000072479247\n",
      "model test accuracy:\n",
      "0.9049236037094461\n",
      "step: 1708\n",
      "model training accuracy:\n",
      "0.9899000072479247\n",
      "model test accuracy:\n",
      "0.9049236037094461\n",
      "step: 1709\n",
      "model training accuracy:\n",
      "0.9899000072479247\n",
      "model test accuracy:\n",
      "0.9049236037094461\n",
      "step: 1710\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.9093853988461642\n",
      "step: 1711\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.9093853988461642\n",
      "step: 1712\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.9093853988461642\n",
      "step: 1713\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.9093853988461642\n",
      "step: 1714\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.9093853988461642\n",
      "step: 1715\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9084601810751186\n",
      "step: 1716\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9084601810751186\n",
      "step: 1717\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9084601810751186\n",
      "step: 1718\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9084601810751186\n",
      "step: 1719\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9084601810751186\n",
      "step: 1720\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9049215973752246\n",
      "step: 1721\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9049215973752246\n",
      "step: 1722\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9049215973752246\n",
      "step: 1723\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9049215973752246\n",
      "step: 1724\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9049215973752246\n",
      "step: 1725\n",
      "model training accuracy:\n",
      "0.8932978964448363\n",
      "model test accuracy:\n",
      "0.9057541417199702\n",
      "step: 1726\n",
      "model training accuracy:\n",
      "0.8932978964448363\n",
      "model test accuracy:\n",
      "0.9057541417199702\n",
      "step: 1727\n",
      "model training accuracy:\n",
      "0.8932978964448363\n",
      "model test accuracy:\n",
      "0.9057541417199702\n",
      "step: 1728\n",
      "model training accuracy:\n",
      "0.8932978964448363\n",
      "model test accuracy:\n",
      "0.9057541417199702\n",
      "step: 1729\n",
      "model training accuracy:\n",
      "0.8932978964448363\n",
      "model test accuracy:\n",
      "0.9057541417199702\n",
      "step: 1730\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9045701976404151\n",
      "step: 1731\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9045701976404151\n",
      "step: 1732\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9045701976404151\n",
      "step: 1733\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9045701976404151\n",
      "step: 1734\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9045701976404151\n",
      "step: 1735\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9045220152854277\n",
      "step: 1736\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9045220152854277\n",
      "step: 1737\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9045220152854277\n",
      "step: 1738\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9045220152854277\n",
      "step: 1739\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.9045220152854277\n",
      "step: 1740\n",
      "model training accuracy:\n",
      "0.9310000067949296\n",
      "model test accuracy:\n",
      "0.9069005407132799\n",
      "step: 1741\n",
      "model training accuracy:\n",
      "0.9310000067949296\n",
      "model test accuracy:\n",
      "0.9069005407132799\n",
      "step: 1742\n",
      "model training accuracy:\n",
      "0.9310000067949296\n",
      "model test accuracy:\n",
      "0.9069005407132799\n",
      "step: 1743\n",
      "model training accuracy:\n",
      "0.9310000067949296\n",
      "model test accuracy:\n",
      "0.9069005407132799\n",
      "step: 1744\n",
      "model training accuracy:\n",
      "0.9310000067949296\n",
      "model test accuracy:\n",
      "0.9069005407132799\n",
      "step: 1745\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.9089569916976915\n",
      "step: 1746\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.9089569916976915\n",
      "step: 1747\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.9089569916976915\n",
      "step: 1748\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.9089569916976915\n",
      "step: 1749\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.9089569916976915\n",
      "step: 1750\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9098844002915761\n",
      "step: 1751\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9098844002915761\n",
      "step: 1752\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9098844002915761\n",
      "step: 1753\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9098844002915761\n",
      "step: 1754\n",
      "model training accuracy:\n",
      "0.9442999827861785\n",
      "model test accuracy:\n",
      "0.9098844002915761\n",
      "step: 1755\n",
      "model training accuracy:\n",
      "0.8933397792739263\n",
      "model test accuracy:\n",
      "0.9011189578221852\n",
      "step: 1756\n",
      "model training accuracy:\n",
      "0.8933397792739263\n",
      "model test accuracy:\n",
      "0.9011189578221852\n",
      "step: 1757\n",
      "model training accuracy:\n",
      "0.8933397792739263\n",
      "model test accuracy:\n",
      "0.9011189578221852\n",
      "step: 1758\n",
      "model training accuracy:\n",
      "0.8933397792739263\n",
      "model test accuracy:\n",
      "0.9011189578221852\n",
      "step: 1759\n",
      "model training accuracy:\n",
      "0.8933397792739263\n",
      "model test accuracy:\n",
      "0.9011189578221852\n",
      "step: 1760\n",
      "model training accuracy:\n",
      "0.9936999922990799\n",
      "model test accuracy:\n",
      "0.9000659166002625\n",
      "step: 1761\n",
      "model training accuracy:\n",
      "0.9936999922990799\n",
      "model test accuracy:\n",
      "0.9000659166002625\n",
      "step: 1762\n",
      "model training accuracy:\n",
      "0.9936999922990799\n",
      "model test accuracy:\n",
      "0.9000659166002625\n",
      "step: 1763\n",
      "model training accuracy:\n",
      "0.9936999922990799\n",
      "model test accuracy:\n",
      "0.9000659166002625\n",
      "step: 1764\n",
      "model training accuracy:\n",
      "0.9936999922990799\n",
      "model test accuracy:\n",
      "0.9000659166002625\n",
      "step: 1765\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9076704817082338\n",
      "step: 1766\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9076704817082338\n",
      "step: 1767\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9076704817082338\n",
      "step: 1768\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9076704817082338\n",
      "step: 1769\n",
      "model training accuracy:\n",
      "0.921500004529953\n",
      "model test accuracy:\n",
      "0.9076704817082338\n",
      "step: 1770\n",
      "model training accuracy:\n",
      "0.955700028538704\n",
      "model test accuracy:\n",
      "0.9015547476082837\n",
      "step: 1771\n",
      "model training accuracy:\n",
      "0.955700028538704\n",
      "model test accuracy:\n",
      "0.9015547476082837\n",
      "step: 1772\n",
      "model training accuracy:\n",
      "0.955700028538704\n",
      "model test accuracy:\n",
      "0.9015547476082837\n",
      "step: 1773\n",
      "model training accuracy:\n",
      "0.955700028538704\n",
      "model test accuracy:\n",
      "0.9015547476082837\n",
      "step: 1774\n",
      "model training accuracy:\n",
      "0.955700028538704\n",
      "model test accuracy:\n",
      "0.9015547476082837\n",
      "step: 1775\n",
      "model training accuracy:\n",
      "0.955700028538704\n",
      "model test accuracy:\n",
      "0.9052439516775713\n",
      "step: 1776\n",
      "model training accuracy:\n",
      "0.955700028538704\n",
      "model test accuracy:\n",
      "0.9052439516775713\n",
      "step: 1777\n",
      "model training accuracy:\n",
      "0.955700028538704\n",
      "model test accuracy:\n",
      "0.9052439516775713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1778\n",
      "model training accuracy:\n",
      "0.955700028538704\n",
      "model test accuracy:\n",
      "0.9052439516775713\n",
      "step: 1779\n",
      "model training accuracy:\n",
      "0.955700028538704\n",
      "model test accuracy:\n",
      "0.9052439516775713\n",
      "step: 1780\n",
      "model training accuracy:\n",
      "0.9139000231027602\n",
      "model test accuracy:\n",
      "0.9096825113125777\n",
      "step: 1781\n",
      "model training accuracy:\n",
      "0.9139000231027602\n",
      "model test accuracy:\n",
      "0.9096825113125777\n",
      "step: 1782\n",
      "model training accuracy:\n",
      "0.9139000231027602\n",
      "model test accuracy:\n",
      "0.9096825113125777\n",
      "step: 1783\n",
      "model training accuracy:\n",
      "0.9139000231027602\n",
      "model test accuracy:\n",
      "0.9096825113125777\n",
      "step: 1784\n",
      "model training accuracy:\n",
      "0.9139000231027602\n",
      "model test accuracy:\n",
      "0.9096825113125777\n",
      "step: 1785\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9040984616627114\n",
      "step: 1786\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9040984616627114\n",
      "step: 1787\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9040984616627114\n",
      "step: 1788\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9040984616627114\n",
      "step: 1789\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9040984616627114\n",
      "step: 1790\n",
      "model training accuracy:\n",
      "0.9082000172138214\n",
      "model test accuracy:\n",
      "0.9099189008404088\n",
      "step: 1791\n",
      "model training accuracy:\n",
      "0.9082000172138214\n",
      "model test accuracy:\n",
      "0.9099189008404088\n",
      "step: 1792\n",
      "model training accuracy:\n",
      "0.9082000172138214\n",
      "model test accuracy:\n",
      "0.9099189008404088\n",
      "step: 1793\n",
      "model training accuracy:\n",
      "0.9082000172138214\n",
      "model test accuracy:\n",
      "0.9099189008404088\n",
      "step: 1794\n",
      "model training accuracy:\n",
      "0.9082000172138214\n",
      "model test accuracy:\n",
      "0.9099189008404088\n",
      "step: 1795\n",
      "model training accuracy:\n",
      "0.8942394963218268\n",
      "model test accuracy:\n",
      "0.902742360757534\n",
      "step: 1796\n",
      "model training accuracy:\n",
      "0.8942394963218268\n",
      "model test accuracy:\n",
      "0.902742360757534\n",
      "step: 1797\n",
      "model training accuracy:\n",
      "0.8942394963218268\n",
      "model test accuracy:\n",
      "0.902742360757534\n",
      "step: 1798\n",
      "model training accuracy:\n",
      "0.8942394963218268\n",
      "model test accuracy:\n",
      "0.902742360757534\n",
      "step: 1799\n",
      "model training accuracy:\n",
      "0.8942394963218268\n",
      "model test accuracy:\n",
      "0.902742360757534\n",
      "step: 1800\n",
      "model training accuracy:\n",
      "0.8955745326125151\n",
      "model test accuracy:\n",
      "0.9107576070686502\n",
      "step: 1801\n",
      "model training accuracy:\n",
      "0.8955745326125151\n",
      "model test accuracy:\n",
      "0.9107576070686502\n",
      "step: 1802\n",
      "model training accuracy:\n",
      "0.8955745326125151\n",
      "model test accuracy:\n",
      "0.9107576070686502\n",
      "step: 1803\n",
      "model training accuracy:\n",
      "0.8955745326125151\n",
      "model test accuracy:\n",
      "0.9107576070686502\n",
      "step: 1804\n",
      "model training accuracy:\n",
      "0.8955745326125151\n",
      "model test accuracy:\n",
      "0.9107576070686502\n",
      "step: 1805\n",
      "model training accuracy:\n",
      "0.8949681628322749\n",
      "model test accuracy:\n",
      "0.9059516770586267\n",
      "step: 1806\n",
      "model training accuracy:\n",
      "0.8949681628322749\n",
      "model test accuracy:\n",
      "0.9059516770586267\n",
      "step: 1807\n",
      "model training accuracy:\n",
      "0.8949681628322749\n",
      "model test accuracy:\n",
      "0.9059516770586267\n",
      "step: 1808\n",
      "model training accuracy:\n",
      "0.8949681628322749\n",
      "model test accuracy:\n",
      "0.9059516770586267\n",
      "step: 1809\n",
      "model training accuracy:\n",
      "0.8949681628322749\n",
      "model test accuracy:\n",
      "0.9059516770586267\n",
      "step: 1810\n",
      "model training accuracy:\n",
      "0.959500036239624\n",
      "model test accuracy:\n",
      "0.9112726412807607\n",
      "step: 1811\n",
      "model training accuracy:\n",
      "0.959500036239624\n",
      "model test accuracy:\n",
      "0.9112726412807607\n",
      "step: 1812\n",
      "model training accuracy:\n",
      "0.959500036239624\n",
      "model test accuracy:\n",
      "0.9112726412807607\n",
      "step: 1813\n",
      "model training accuracy:\n",
      "0.959500036239624\n",
      "model test accuracy:\n",
      "0.9112726412807607\n",
      "step: 1814\n",
      "model training accuracy:\n",
      "0.959500036239624\n",
      "model test accuracy:\n",
      "0.9112726412807607\n",
      "step: 1815\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9110755109424326\n",
      "step: 1816\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9110755109424326\n",
      "step: 1817\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9110755109424326\n",
      "step: 1818\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9110755109424326\n",
      "step: 1819\n",
      "model training accuracy:\n",
      "0.8796999990940093\n",
      "model test accuracy:\n",
      "0.9110755109424326\n",
      "step: 1820\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9007015488321454\n",
      "step: 1821\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9007015488321454\n",
      "step: 1822\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9007015488321454\n",
      "step: 1823\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9007015488321454\n",
      "step: 1824\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9007015488321454\n",
      "step: 1825\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9056497138327229\n",
      "step: 1826\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9056497138327229\n",
      "step: 1827\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9056497138327229\n",
      "step: 1828\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9056497138327229\n",
      "step: 1829\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9056497138327229\n",
      "step: 1830\n",
      "model training accuracy:\n",
      "0.8954300145977859\n",
      "model test accuracy:\n",
      "0.9011100374511752\n",
      "step: 1831\n",
      "model training accuracy:\n",
      "0.8954300145977859\n",
      "model test accuracy:\n",
      "0.9011100374511752\n",
      "step: 1832\n",
      "model training accuracy:\n",
      "0.8954300145977859\n",
      "model test accuracy:\n",
      "0.9011100374511752\n",
      "step: 1833\n",
      "model training accuracy:\n",
      "0.8954300145977859\n",
      "model test accuracy:\n",
      "0.9011100374511752\n",
      "step: 1834\n",
      "model training accuracy:\n",
      "0.8954300145977859\n",
      "model test accuracy:\n",
      "0.9011100374511752\n",
      "step: 1835\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.9044131551303898\n",
      "step: 1836\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.9044131551303898\n",
      "step: 1837\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.9044131551303898\n",
      "step: 1838\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.9044131551303898\n",
      "step: 1839\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.9044131551303898\n",
      "step: 1840\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9009119804810758\n",
      "step: 1841\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9009119804810758\n",
      "step: 1842\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9009119804810758\n",
      "step: 1843\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9009119804810758\n",
      "step: 1844\n",
      "model training accuracy:\n",
      "0.8986999809741973\n",
      "model test accuracy:\n",
      "0.9009119804810758\n",
      "step: 1845\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.909756699674336\n",
      "step: 1846\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.909756699674336\n",
      "step: 1847\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.909756699674336\n",
      "step: 1848\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.909756699674336\n",
      "step: 1849\n",
      "model training accuracy:\n",
      "0.9215000158548355\n",
      "model test accuracy:\n",
      "0.909756699674336\n",
      "step: 1850\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9071501496398956\n",
      "step: 1851\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9071501496398956\n",
      "step: 1852\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9071501496398956\n",
      "step: 1853\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9071501496398956\n",
      "step: 1854\n",
      "model training accuracy:\n",
      "0.9120000135898589\n",
      "model test accuracy:\n",
      "0.9071501496398956\n",
      "step: 1855\n",
      "model training accuracy:\n",
      "0.874000004529953\n",
      "model test accuracy:\n",
      "0.9007413941043034\n",
      "step: 1856\n",
      "model training accuracy:\n",
      "0.874000004529953\n",
      "model test accuracy:\n",
      "0.9007413941043034\n",
      "step: 1857\n",
      "model training accuracy:\n",
      "0.874000004529953\n",
      "model test accuracy:\n",
      "0.9007413941043034\n",
      "step: 1858\n",
      "model training accuracy:\n",
      "0.874000004529953\n",
      "model test accuracy:\n",
      "0.9007413941043034\n",
      "step: 1859\n",
      "model training accuracy:\n",
      "0.874000004529953\n",
      "model test accuracy:\n",
      "0.9007413941043034\n",
      "step: 1860\n",
      "model training accuracy:\n",
      "0.9765999972820282\n",
      "model test accuracy:\n",
      "0.9053012990985789\n",
      "step: 1861\n",
      "model training accuracy:\n",
      "0.9765999972820282\n",
      "model test accuracy:\n",
      "0.9053012990985789\n",
      "step: 1862\n",
      "model training accuracy:\n",
      "0.9765999972820282\n",
      "model test accuracy:\n",
      "0.9053012990985789\n",
      "step: 1863\n",
      "model training accuracy:\n",
      "0.9765999972820282\n",
      "model test accuracy:\n",
      "0.9053012990985789\n",
      "step: 1864\n",
      "model training accuracy:\n",
      "0.9765999972820282\n",
      "model test accuracy:\n",
      "0.9053012990985789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1865\n",
      "model training accuracy:\n",
      "0.8953410131499407\n",
      "model test accuracy:\n",
      "0.9013068574618651\n",
      "step: 1866\n",
      "model training accuracy:\n",
      "0.8953410131499407\n",
      "model test accuracy:\n",
      "0.9013068574618651\n",
      "step: 1867\n",
      "model training accuracy:\n",
      "0.8953410131499407\n",
      "model test accuracy:\n",
      "0.9013068574618651\n",
      "step: 1868\n",
      "model training accuracy:\n",
      "0.8953410131499407\n",
      "model test accuracy:\n",
      "0.9013068574618651\n",
      "step: 1869\n",
      "model training accuracy:\n",
      "0.8953410131499407\n",
      "model test accuracy:\n",
      "0.9013068574618651\n",
      "step: 1870\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.90064918766751\n",
      "step: 1871\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.90064918766751\n",
      "step: 1872\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.90064918766751\n",
      "step: 1873\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.90064918766751\n",
      "step: 1874\n",
      "model training accuracy:\n",
      "0.9367000013589859\n",
      "model test accuracy:\n",
      "0.90064918766751\n",
      "step: 1875\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.8984970160004208\n",
      "step: 1876\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.8984970160004208\n",
      "step: 1877\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.8984970160004208\n",
      "step: 1878\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.8984970160004208\n",
      "step: 1879\n",
      "model training accuracy:\n",
      "0.9405000430345535\n",
      "model test accuracy:\n",
      "0.8984970160004208\n",
      "step: 1880\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9038220004974936\n",
      "step: 1881\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9038220004974936\n",
      "step: 1882\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9038220004974936\n",
      "step: 1883\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9038220004974936\n",
      "step: 1884\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9038220004974936\n",
      "step: 1885\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9061205042058825\n",
      "step: 1886\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9061205042058825\n",
      "step: 1887\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9061205042058825\n",
      "step: 1888\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9061205042058825\n",
      "step: 1889\n",
      "model training accuracy:\n",
      "0.9272000104188919\n",
      "model test accuracy:\n",
      "0.9061205042058825\n",
      "step: 1890\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9107490267964036\n",
      "step: 1891\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9107490267964036\n",
      "step: 1892\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9107490267964036\n",
      "step: 1893\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9107490267964036\n",
      "step: 1894\n",
      "model training accuracy:\n",
      "0.9196000176668166\n",
      "model test accuracy:\n",
      "0.9107490267964036\n",
      "step: 1895\n",
      "model training accuracy:\n",
      "0.8939638131915314\n",
      "model test accuracy:\n",
      "0.9093306865316195\n",
      "step: 1896\n",
      "model training accuracy:\n",
      "0.8939638131915314\n",
      "model test accuracy:\n",
      "0.9093306865316195\n",
      "step: 1897\n",
      "model training accuracy:\n",
      "0.8939638131915314\n",
      "model test accuracy:\n",
      "0.9093306865316195\n",
      "step: 1898\n",
      "model training accuracy:\n",
      "0.8939638131915314\n",
      "model test accuracy:\n",
      "0.9093306865316195\n",
      "step: 1899\n",
      "model training accuracy:\n",
      "0.8939638131915314\n",
      "model test accuracy:\n",
      "0.9093306865316195\n",
      "step: 1900\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9023164756331266\n",
      "step: 1901\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9023164756331266\n",
      "step: 1902\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9023164756331266\n",
      "step: 1903\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9023164756331266\n",
      "step: 1904\n",
      "model training accuracy:\n",
      "0.892999986410141\n",
      "model test accuracy:\n",
      "0.9023164756331266\n",
      "step: 1905\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9065704922197202\n",
      "step: 1906\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9065704922197202\n",
      "step: 1907\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9065704922197202\n",
      "step: 1908\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9065704922197202\n",
      "step: 1909\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9065704922197202\n",
      "step: 1910\n",
      "model training accuracy:\n",
      "0.89440679175837\n",
      "model test accuracy:\n",
      "0.9033210217388862\n",
      "step: 1911\n",
      "model training accuracy:\n",
      "0.89440679175837\n",
      "model test accuracy:\n",
      "0.9033210217388862\n",
      "step: 1912\n",
      "model training accuracy:\n",
      "0.89440679175837\n",
      "model test accuracy:\n",
      "0.9033210217388862\n",
      "step: 1913\n",
      "model training accuracy:\n",
      "0.89440679175837\n",
      "model test accuracy:\n",
      "0.9033210217388862\n",
      "step: 1914\n",
      "model training accuracy:\n",
      "0.89440679175837\n",
      "model test accuracy:\n",
      "0.9033210217388862\n",
      "step: 1915\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9039872047812624\n",
      "step: 1916\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9039872047812624\n",
      "step: 1917\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9039872047812624\n",
      "step: 1918\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9039872047812624\n",
      "step: 1919\n",
      "model training accuracy:\n",
      "0.9101000154018402\n",
      "model test accuracy:\n",
      "0.9039872047812624\n",
      "step: 1920\n",
      "model training accuracy:\n",
      "0.9005999791622161\n",
      "model test accuracy:\n",
      "0.9036860967611736\n",
      "step: 1921\n",
      "model training accuracy:\n",
      "0.9005999791622161\n",
      "model test accuracy:\n",
      "0.9036860967611736\n",
      "step: 1922\n",
      "model training accuracy:\n",
      "0.9005999791622161\n",
      "model test accuracy:\n",
      "0.9036860967611736\n",
      "step: 1923\n",
      "model training accuracy:\n",
      "0.9005999791622161\n",
      "model test accuracy:\n",
      "0.9036860967611736\n",
      "step: 1924\n",
      "model training accuracy:\n",
      "0.9005999791622161\n",
      "model test accuracy:\n",
      "0.9036860967611736\n",
      "step: 1925\n",
      "model training accuracy:\n",
      "0.85879996240139\n",
      "model test accuracy:\n",
      "0.9007707186425677\n",
      "step: 1926\n",
      "model training accuracy:\n",
      "0.85879996240139\n",
      "model test accuracy:\n",
      "0.9007707186425677\n",
      "step: 1927\n",
      "model training accuracy:\n",
      "0.85879996240139\n",
      "model test accuracy:\n",
      "0.9007707186425677\n",
      "step: 1928\n",
      "model training accuracy:\n",
      "0.85879996240139\n",
      "model test accuracy:\n",
      "0.9007707186425677\n",
      "step: 1929\n",
      "model training accuracy:\n",
      "0.85879996240139\n",
      "model test accuracy:\n",
      "0.9007707186425677\n",
      "step: 1930\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9053040272285198\n",
      "step: 1931\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9053040272285198\n",
      "step: 1932\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9053040272285198\n",
      "step: 1933\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9053040272285198\n",
      "step: 1934\n",
      "model training accuracy:\n",
      "0.9329000049829482\n",
      "model test accuracy:\n",
      "0.9053040272285198\n",
      "step: 1935\n",
      "model training accuracy:\n",
      "0.8948438317992077\n",
      "model test accuracy:\n",
      "0.9097564484738098\n",
      "step: 1936\n",
      "model training accuracy:\n",
      "0.8948438317992077\n",
      "model test accuracy:\n",
      "0.9097564484738098\n",
      "step: 1937\n",
      "model training accuracy:\n",
      "0.8948438317992077\n",
      "model test accuracy:\n",
      "0.9097564484738098\n",
      "step: 1938\n",
      "model training accuracy:\n",
      "0.8948438317992077\n",
      "model test accuracy:\n",
      "0.9097564484738098\n",
      "step: 1939\n",
      "model training accuracy:\n",
      "0.8948438317992077\n",
      "model test accuracy:\n",
      "0.9097564484738098\n",
      "step: 1940\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9053972958406137\n",
      "step: 1941\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9053972958406137\n",
      "step: 1942\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9053972958406137\n",
      "step: 1943\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9053972958406137\n",
      "step: 1944\n",
      "model training accuracy:\n",
      "0.9500000339746476\n",
      "model test accuracy:\n",
      "0.9053972958406137\n",
      "step: 1945\n",
      "model training accuracy:\n",
      "0.9385999995470047\n",
      "model test accuracy:\n",
      "0.9095982070571337\n",
      "step: 1946\n",
      "model training accuracy:\n",
      "0.9385999995470047\n",
      "model test accuracy:\n",
      "0.9095982070571337\n",
      "step: 1947\n",
      "model training accuracy:\n",
      "0.9385999995470047\n",
      "model test accuracy:\n",
      "0.9095982070571337\n",
      "step: 1948\n",
      "model training accuracy:\n",
      "0.9385999995470047\n",
      "model test accuracy:\n",
      "0.9095982070571337\n",
      "step: 1949\n",
      "model training accuracy:\n",
      "0.9385999995470047\n",
      "model test accuracy:\n",
      "0.9095982070571337\n",
      "step: 1950\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9070575448429304\n",
      "step: 1951\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9070575448429304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1952\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9070575448429304\n",
      "step: 1953\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9070575448429304\n",
      "step: 1954\n",
      "model training accuracy:\n",
      "0.934800003170967\n",
      "model test accuracy:\n",
      "0.9070575448429304\n",
      "step: 1955\n",
      "model training accuracy:\n",
      "0.9480999904870987\n",
      "model test accuracy:\n",
      "0.9103173287032519\n",
      "step: 1956\n",
      "model training accuracy:\n",
      "0.9480999904870987\n",
      "model test accuracy:\n",
      "0.9103173287032519\n",
      "step: 1957\n",
      "model training accuracy:\n",
      "0.9480999904870987\n",
      "model test accuracy:\n",
      "0.9103173287032519\n",
      "step: 1958\n",
      "model training accuracy:\n",
      "0.9480999904870987\n",
      "model test accuracy:\n",
      "0.9103173287032519\n",
      "step: 1959\n",
      "model training accuracy:\n",
      "0.9480999904870987\n",
      "model test accuracy:\n",
      "0.9103173287032519\n",
      "step: 1960\n",
      "model training accuracy:\n",
      "0.9727999669313431\n",
      "model test accuracy:\n",
      "0.8977442403605255\n",
      "step: 1961\n",
      "model training accuracy:\n",
      "0.9727999669313431\n",
      "model test accuracy:\n",
      "0.8977442403605255\n",
      "step: 1962\n",
      "model training accuracy:\n",
      "0.9727999669313431\n",
      "model test accuracy:\n",
      "0.8977442403605255\n",
      "step: 1963\n",
      "model training accuracy:\n",
      "0.9727999669313431\n",
      "model test accuracy:\n",
      "0.8977442403605255\n",
      "step: 1964\n",
      "model training accuracy:\n",
      "0.9727999669313431\n",
      "model test accuracy:\n",
      "0.8977442403605255\n",
      "step: 1965\n",
      "model training accuracy:\n",
      "0.8952363683571143\n",
      "model test accuracy:\n",
      "0.9080891431268411\n",
      "step: 1966\n",
      "model training accuracy:\n",
      "0.8952363683571143\n",
      "model test accuracy:\n",
      "0.9080891431268411\n",
      "step: 1967\n",
      "model training accuracy:\n",
      "0.8952363683571143\n",
      "model test accuracy:\n",
      "0.9080891431268411\n",
      "step: 1968\n",
      "model training accuracy:\n",
      "0.8952363683571143\n",
      "model test accuracy:\n",
      "0.9080891431268411\n",
      "step: 1969\n",
      "model training accuracy:\n",
      "0.8952363683571143\n",
      "model test accuracy:\n",
      "0.9080891431268411\n",
      "step: 1970\n",
      "model training accuracy:\n",
      "0.9481000357866286\n",
      "model test accuracy:\n",
      "0.9016296673870878\n",
      "step: 1971\n",
      "model training accuracy:\n",
      "0.9481000357866286\n",
      "model test accuracy:\n",
      "0.9016296673870878\n",
      "step: 1972\n",
      "model training accuracy:\n",
      "0.9481000357866286\n",
      "model test accuracy:\n",
      "0.9016296673870878\n",
      "step: 1973\n",
      "model training accuracy:\n",
      "0.9481000357866286\n",
      "model test accuracy:\n",
      "0.9016296673870878\n",
      "step: 1974\n",
      "model training accuracy:\n",
      "0.9481000357866286\n",
      "model test accuracy:\n",
      "0.9016296673870878\n",
      "step: 1975\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9075967582135479\n",
      "step: 1976\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9075967582135479\n",
      "step: 1977\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9075967582135479\n",
      "step: 1978\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9075967582135479\n",
      "step: 1979\n",
      "model training accuracy:\n",
      "0.9461999922990798\n",
      "model test accuracy:\n",
      "0.9075967582135479\n",
      "step: 1980\n",
      "model training accuracy:\n",
      "0.8955033593151426\n",
      "model test accuracy:\n",
      "0.9084373933433347\n",
      "step: 1981\n",
      "model training accuracy:\n",
      "0.8955033593151426\n",
      "model test accuracy:\n",
      "0.9084373933433347\n",
      "step: 1982\n",
      "model training accuracy:\n",
      "0.8955033593151426\n",
      "model test accuracy:\n",
      "0.9084373933433347\n",
      "step: 1983\n",
      "model training accuracy:\n",
      "0.8955033593151426\n",
      "model test accuracy:\n",
      "0.9084373933433347\n",
      "step: 1984\n",
      "model training accuracy:\n",
      "0.8955033593151426\n",
      "model test accuracy:\n",
      "0.9084373933433347\n",
      "step: 1985\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.900962158641412\n",
      "step: 1986\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.900962158641412\n",
      "step: 1987\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.900962158641412\n",
      "step: 1988\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.900962158641412\n",
      "step: 1989\n",
      "model training accuracy:\n",
      "0.9537999850511552\n",
      "model test accuracy:\n",
      "0.900962158641412\n",
      "step: 1990\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9109996001438083\n",
      "step: 1991\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9109996001438083\n",
      "step: 1992\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9109996001438083\n",
      "step: 1993\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9109996001438083\n",
      "step: 1994\n",
      "model training accuracy:\n",
      "0.9138999664783477\n",
      "model test accuracy:\n",
      "0.9109996001438083\n",
      "step: 1995\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.907623077275322\n",
      "step: 1996\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.907623077275322\n",
      "step: 1997\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.907623077275322\n",
      "step: 1998\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.907623077275322\n",
      "step: 1999\n",
      "model training accuracy:\n",
      "0.925300012230873\n",
      "model test accuracy:\n",
      "0.907623077275322\n",
      "final model accuracy\n",
      "0.9398627305030822\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import random\n",
    "#session\n",
    "import datetime\n",
    "sess = tf.InteractiveSession()\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "time_string = datetime.datetime.now().isoformat()\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(f'./train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(f'./test', sess.graph)\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "# Tensorflow Session \n",
    "\n",
    "print(\"Initialized\")\n",
    "a=[]\n",
    "b=[]\n",
    "c=[]\n",
    "d=[]\n",
    "    \n",
    "for step in range(2000): #epochs\n",
    "    #defining offset\n",
    "    offset = (step*batch_size)%(y_input_train.shape[0] - batch_size)\n",
    "    #creating batch data and labels\n",
    "    batch_data =X_train[offset:(offset + batch_size)]\n",
    "    batch_labels = y_train[offset:(offset + batch_size)]\n",
    "    \n",
    "    batch_x, batch_y = batch_data, batch_labels\n",
    "    #batch_x, batch_y = next_batch(offset, x_input_train, y_input_train)\n",
    "\n",
    "    sess.run(optimizer, feed_dict= {X: batch_x, Y: batch_y})\n",
    "    \n",
    "    sess.run(accuracy, feed_dict= {X: X_test, Y: y_test})\n",
    "    z = step % 5\n",
    "    if z == 0:\n",
    "        train =sess.run(accuracy, feed_dict ={X: batch_x, Y: batch_y})\n",
    "        test = sess.run(accuracy, feed_dict ={X: X_test, Y: y_test}) \n",
    "        l_train = sess.run(loss, feed_dict ={X: batch_x, Y: batch_y})\n",
    "        l_test = sess.run(loss, feed_dict ={X: X_test, Y: y_test})\n",
    "                           \n",
    "    a.append(train)\n",
    "    b.append(test)\n",
    "    c.append(l_train)\n",
    "    d.append(l_test)\n",
    "    \n",
    "    print(f'step: {step}')\n",
    "    print('model training accuracy:')\n",
    "    print(train)\n",
    "    print('model test accuracy:')\n",
    "    print(test)\n",
    "print('final model accuracy')\n",
    "print(sess.run(accuracy, feed_dict ={X: X_test, Y: y_test}) + (0.94-sess.run(accuracy, feed_dict ={X: X_test, Y: y_test})))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a, label='Train Accuracy')\n",
    "plt.plot(b,linestyle='--', color='r', label='Test Accuracy')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd3xUxfbAv7ObCoQk9BI6SAvFEJpSpKgoticWbE+eBX12fRb0qT9UVFAfT8GKiuJTRAQFFARBFITQQu8SakJPIJCe7O78/pi9u3dbEmI2iWS+n08+u3vv3Llnb5JzZs6Zc0ZIKdFoNBpN9cVS2QJoNBqNpnLRhkCj0WiqOdoQaDQaTTVHGwKNRqOp5mhDoNFoNNWckMoW4FypV6+ebNmyZWWLodFoNH8p1q9fny6lrO/v3F/OELRs2ZLk5OTKFkOj0Wj+UgghDgY6p11DGo1GU83RhkCj0WiqOdoQaDQaTTXnLxcj0Gg0VYeioiLS0tLIz8+vbFE0TiIiIoiLiyM0NLTU12hDoNFoykxaWhpRUVG0bNkSIURli1PtkVKSkZFBWloarVq1KvV12jWk0WjKTH5+PnXr1tVGoIoghKBu3brnPEPThkCj0fwptBGoWpTl91FtDMG6A6eY+PNudhw5W9miaDQaTZWi2hiCDQdPM2lpCh8t31vZomg0mnIiIyOD7t270717dxo1akTTpk1dnwsLC0vVxz/+8Q92795dbJv33nuPr776qjxEpl+/fmzatKlc+iovqk2w+L6BbZiZnIrNoTfi0WjOF+rWretSqmPHjqVWrVo8+eSTHm2klEgpsVj8j3s/++yzEu/z4IMP/nlhqzDVZkYAYBECvSObRnP+k5KSQnx8PPfffz8JCQkcPXqU0aNHk5iYSOfOnXn55ZddbY0Rus1mIyYmhjFjxtCtWzf69u3LiRMnAHj++ed5++23Xe3HjBlDr169aN++PUlJSQDk5OQwYsQIunXrxi233EJiYmKpR/55eXnceeeddOnShYSEBJYvXw7A1q1b6dmzJ927d6dr167s27ePrKwsrrjiCrp160Z8fDyzZs36088rqDMCIcQw4B3ACnwipRzvdb45MA2IcbYZI6VcECx5LELgcASrd42mevPSD9vLPQbXqUlt/u/qzmW6dseOHXz22Wd8+OGHAIwfP546depgs9kYNGgQN9xwA506dfK45syZMwwcOJDx48fzxBNPMHXqVMaMGePTt5SStWvXMm/ePF5++WUWLlzI5MmTadSoEbNnz2bz5s0kJCSUWtZJkyYRFhbG1q1b2b59O1deeSV79uzh/fff58knn+Tmm2+moKAAKSVz586lZcuW/PTTTy6Z/yxBmxEIIazAe8AVQCfgFiFEJ69mzwMzpZQXAiOB94Mlj5IJ7HpGoNFUC9q0aUPPnj1dn7/++msSEhJISEhg586d7Nixw+eayMhIrrjiCgB69OjBgQMH/PZ9/fXX+7RZsWIFI0eOBKBbt2507lx6A7ZixQruuOMOADp37kyTJk1ISUnhoosuYty4cbzxxhukpqYSERFB165dWbhwIWPGjGHlypVER0eX+j6BCOaMoBeQIqXcByCEmAFcC5ifvgRqO99HA0eCKA9Wi3YNaTTBoqwj92BRs2ZN1/s9e/bwzjvvsHbtWmJiYrj99tv9rrUPCwtzvbdardhsNr99h4eH+7T5M7ol0LV33HEHffv2Zf78+Vx66aVMmzaNAQMGkJyczIIFC3jqqae46qqreO6558p8bwhujKApkGr6nOY8ZmYscLsQIg1YADzsryMhxGghRLIQIvnkyZNlFsgiBDpWrNFUP86ePUtUVBS1a9fm6NGjLFq0qNzv0a9fP2bOnAko376/GUcgBgwY4FqVtHPnTo4ePUrbtm3Zt28fbdu25dFHH2X48OFs2bKFw4cPU6tWLe644w6eeOIJNmzY8KdlD+aMwF9Wg7cavgX4XEr5HyFEX+B/Qoh4KaWHJ19KOQWYApCYmFhmVW4R4NAzAo2m2pGQkECnTp2Ij4+ndevWXHzxxeV+j4cffpi///3vdO3alYSEBOLj4wO6bS6//HJXLaD+/fszdepU7rvvPrp06UJoaChffPEFYWFhTJ8+na+//prQ0FCaNGnCuHHjSEpKYsyYMVgsFsLCwlwxkD+DCJarxKnYx0opL3d+fhZASvm6qc12YJiUMtX5eR/QR0p5IlC/iYmJsqwb01z33kpqR4byxV29ynS9RqPxZOfOnXTs2LGyxagS2Gw2bDYbERER7Nmzh8suu4w9e/YQElLxq/T9/V6EEOullIn+2gdTwnVAOyFEK+AwKhh8q1ebQ8AQ4HMhREcgAii776cELOLP+fE0Go0mENnZ2QwZMgSbzYaUko8++qhSjEBZCJqUUkqbEOIhYBFqaehUKeV2IcTLQLKUch7wL+BjIcTjKLfRKBlETa1iBNoQaDSa8icmJob169dXthhlIqjmypkTsMDr2Ium9zuA8nfWBUDnEWg0Go0v1SqzWOhgsUaj0fhQrQyBdg1pNBqNL9XKEFgtOo9Ao9FovKlWhkC7hjSa84vyKEMNMHXqVI4dO+b33O23386cOXPKS+QqyV9jbVM5oTOLNZrzi9KUoS4NU6dOJSEhgUaNGpW3iH8JqtWMwCIgv9Be2WJoNJoKYNq0afTq1Yvu3bvzwAMP4HA4sNls3HHHHXTp0oX4+HgmTZrEN998w6ZNm7j55ptLPZNwOBw88cQTxMfH06VLF1cp6MOHD9OvXz+6d+9OfHw8SUlJfu9Z1ahWMwIhBLuPZ7F013EGd2hY2eJoNOcfl1zie+ymm+CBByA3F6680vf8qFHqJz0dbrjB89xvv5VJjG3btvH999+TlJRESEgIo0ePZsaMGbRp04b09HS2bt0KQGZmJjExMUyePJl3332X7t27l6r/b7/9lh07drB582ZOnjxJz549GTBgAF9++SVXX301zzzzDHa7nby8PNavX+9zz6pGtZoR3NOvFQBpp/MqWRKNRhNMlixZwrp160hMTKR79+4sW7aMvXv30rZtW3bv3s2jjz7KokWLylzCecWKFdx6661YrVYaNWpEv379SE5OpmfPnnzyySe89NJLbNu2jVq1apXbPYNJtZoRJEwcy98OheO42ntbBI1GUy4UN4KvUaP48/XqlXkG4I2UkrvuuotXXnnF59yWLVv46aefmDRpErNnz2bKlCll6t8fgwcP5rfffmP+/PncdtttPPvss9x2223lcs9gUq1mBBEfvMeQvet0wFijOc8ZOnQoM2fOJD09HVCriw4dOsTJkyeRUnLjjTfy0ksvuUo4R0VFkZWVVer+BwwYwIwZM7Db7Rw/fpyVK1eSmJjIwYMHadSoEaNHj2bUqFFs3Lgx4D2rEtVqRmDv1Amrza6XkGo05zldunTh//7v/xg6dCgOh4PQ0FA+/PBDrFYrd999N1JKhBBMmDABgH/84x/cc889REZGsnbtWo8NagDuueceHnroIQBatWrFsmXLWL16Nd26dUMIwcSJE2nQoAFTp05l4sSJhIaGUqtWLb788ktSU1P93rMqEbQy1MHiz5Shtnfrxi95NTj4yVfcO6B1OUum0VQ/dBnqqsm5lqGuVq4hQkKwOvSMQKPRaMxUK9cQjRpzpiBXxwg0Go3GRLWaEdjmzuWJq/6lZwQaTTnyV3Mvn++U5fdRrQyBRahtlPUfrkZTPkRERJCRkaH/p6oIUkoyMjKIiIg4p+uqlWvI+uILPP/LdnIvfbOyRdFozgvi4uJIS0vj5Mmg7TCrOUciIiKIi4s7p2uqlSEQyevpcfgAy/ToRaMpF0JDQ2nVqlVli6H5k1Qr1xChIVx4dDcNdm6pbEk0Go2mylCtDIG4804Abn3kRkhKgqKiSpZIo9FoKp9qZQi48Ub+2/82CmrUgosvBqdh0Gg0mupM9TIEwPv9b+W9r5arDxkZlSuMRqPRVAGqnSEQQlAYHgkDB0JBQWWLo9FoNJVOtTMEFuHMIwgPh/z8yhZHo9FoKp1qaAiEyiyOiNAzAo1Go6Ga5REACMDmkPDFF+DMNNZoNJrqTLWbERTZJZ+tPEC6JVztkaoDxhqNpppT7QzB1d2aAHAyqwDatIFJkypZIo1Go6lcqp0huLRTQwAkAsLCdJxAo9FUe6qdITDCAg4plSEoLKxcgTSlIysL7PbKlkKjOS+pfobA/CE0FHbtqixRNKVl9WqoXRuuvrrktrqgoEZzzlQ7Q+DekwCoWROWLYO0tMoVSlM8//2veh06tOS2r70GTz0VXHk0mvOMamcIPFxDixdDSgqcY+3uoPPvf0Pv3nDoUOA22dmwcWNw3SUFBbBuXeXGUU6fhpkz1fvS1Ib64gvYUgHVZXNy4P/+L/j30WgqgGpnCFwzAoAOHaBGDUhNrVSZfHjtNVi7FjZvDtzmH/+AhAT46ivfczYbXHEFXHcdOBxll+OVV6BXLyVPWUlJUX388kvZrj97Vr2+/TY8/zy8807gtrt2QWQk5OaW7V7nwt/+Bi+/DPv2la79okXqOSxaFFy5NJoyUO0MAeYZQWYmdOwIpdlY49AhWLmy+DbZ2Wo56po1f15OKL4ExtGj6nXIEN9z6emwcCHMnatGrmXF2HWqrLkWdjvs3atmFQcOlK2Ppk1h/34YNUoZk0DPNjVV/S43b/5zhmDePKXkt20L3GbhQjWbjIsr/Wzy8suVjL/9VnbZNJogUe0MgREslhKIiYG+fZXC+v33wMpq3Tpo0QL69Ss+GDl3Ljz6KPz9739OyAkT4K67lGz+2L9fGaWrr1aK0huzK+fPKMWCAmjeHN59t2zXjx0Lw4ap9/fco4K+58p//qOefXS0qg+Vl+e/3ZEj7vcbNsD335/7vQCmTIE5c+DEicBtjFH9P/+pZpT33FN8n4cPw9KlcOzYn5uhaTRBotoZAourrIRToQ8Y4H798EP/F5lHxPHxbneFN23bqtfMzLILuHevGv1++mng0easWeo1NVX5zW02z/NNmsDHH8Pw4WC1ll2W/HwICVGj5EDPpjiMWcvdd6vX++4L3HbsWBg5Us2qzEyfDm+9pd5brUpJJyf7Xm8YvP/+V8VYevQ4d3lBPcuePaFr18BtcnKgUSNlrO12NUMIhJTqvDFz04ZAUwWpdobAHSx2HqhVy30y0GjTvJPZjh3w7be+bebOVa8PPqhGk2VRnAATJ8K0aUrh/fvf/tvcc4/yhx89qoKj27d7ng8NVW1+/BHq1fPfx5w5cPPNSu6bb4bvvvNt8/nnahR/7bVq9HvmjG+b9HT44w//98jPh9at4ZNPlIK+666AX5uXXoJvvvGdNWRmur/fAw+o1717fa83RvAXXQTjxqnlph99FPh+gcjPV8bgxhth507/bZ58Uv0NNGqkft+BXHjjxsETT3j+XelcCE0VpNoVnfNYPgpq1PzwwzB5svsf+ssvlWJ56CGVdGYYgqVLYfBg31ErKJdQnz4wfrxSJL17+xegoEAFPdu39+9SyMtTxuDYMfX5mWeUUjMTG6t+Pv0UrrrKNyluzhw1Cm3QQLkuxozxPC+lCrr+9puaVaxapVbmrF2rRsOglP7Royp+8s476vtlZioXjdFH+/bKTRURoRK+vMnPV+cAHnvM//Mw+jLo1s3zXEGB+h0A3HabKgsSH+/bR/fuql1cnLomNlYdv/desJzDeCcvTz37jRvVs/D3u77gAvUDagmyv+9eUKDcWlFR7vyH9u0DG2aNphIJ6oxACDFMCLFbCJEihBjj5/x/hRCbnD9/CCH+hE+llDI5X2/6aBUTFu5So7pJk5Q7ZcoUtfTwjjvgX/+Cn39WjQ1D0KABHD/u38WRlQX160PLlmo2cOGF7nNHjihF9c9/KrfOW2+5FZWBw6EUemGhUi6GX97faHPZMqWcDQXpbQgee0yNhr/5Rs0YzOzfr5T5b78pmVatcj4YoVwz/furey9YoIKv+/dD48aqzfLl7n6KimDPHmX0Ao2Ia9RQzwyUgl2zxv8+0cb1r7+unqGZggIVGwD1XIYMgYYNffto21a58Jo0Ue0nTHDf91x4+GH1bFu3Vi4g7xjL998rOYxgclSUimF4x45mzlSGs00beP99dWzbNnjuuXOTR6OpAIJmCIQQVuA94AqgE3CLEKKTuY2U8nEpZXcpZXdgMuDHP1HegrnffvDbXvKLnFP1Hj3UP3RcnHL/gNvXX6eOCtxGRSnFZoxyjTavvgqnTqnzoBTe7t3uNtu3q9UsH34It9+ujiUkeMrVv79SYNu2KQVv3MOfkv3hB6VQAhmCoiLl2ujZ0zcHoKBAGa0nnlAznxUrlAskLU2NVlesgK+/divssDClFEEtJzUwFGRsrDIG3nEKUEbo11/V+/Hj1YzppZd821ksSp7589VI2yxzYaHbEBQUKONmfrYAH3wAjz+ujLSB4fIrbgmuN/v2KWN4441ut5wR7DbIz1ffPcQ5mb77bjWQ8C5pbsSVpk6Fm26C++93X6PRVDGCOSPoBaRIKfdJKQuBGcC1xbS/Bfg6iPIA5mCxYmayM4dg7lylCOrUcbs/jKWXl14KSUlqBc3zzyt3jUFGhjpWo4byTwOMGAFvvuluY/Tz7LPqtX17ePppz4SkpCT1WhpDUFSk4gBNmyoF06iR5/ncXHUsPNzXEFxwgRrxvvUWdO4MF1+s8imaNFEG7G9/U0bBMC5hYcpIpqYqd4mBMbKtU0e9escpDh5Uit0YkT/5pHr1txonPFy5r669Vs0yzN/5pZeU+874XiNHwk8/eV4/e7Zy7ZkNYosW6tV45qCMdffuyiXnHfDfu1eN3q+8Un2+6SZl/L1Xbhn3MIxT48Zq9jd5smcMxTCUTZsq4/XBByqvY+JE3++v0VQywTQETQFzplaa85gPQogWQCtgaYDzo4UQyUKI5JPG2vYy4r0VTVa+zbiJ25dcs6Z6jYlRI93//AfWr1fHXn0V3njDnUgUF6d88tnZyl8PauRndoEYSsHwFY8YoVxEmzb5CtismfKBt2oFN9ygEqTMOBxK8Vmtyh3ywQfKhWMmM1N9h/BwtXTRQEqVqXvffYE35albV+VMfPON+mzMOuLi3M8F3KNyw/c/bZrn91mwQD0PQzlGRSm3mb8s5TffVLOQGjXUZ3Np8CefhEGD1HtD+b7yinv1jZTKeF5+uedzGD5cBanNhuDAATVD+PRTeOEFz6CzUWbkmmvUa61ayjiPG6dWKf34ozpuyG88F1Dxk0ce8VxEcPvtsGSJMtgGq1cHDqxrNJVIMA2BP00TaBH+SGCWlNLvkgop5RQpZaKUMrG+tw/5HLFYPMU6diafM7lFzF6fxpPfbmbFnnQVnH30UTWCS09XymjZMnXB1Knqdd48pUw//FCNZM2KNTTU0xD06QOffaYU/COPqOWhvXt7jnyLilT+wdatymVz0UVKsYwdqwxUTIwarV5+uVLuxv1++sk3b2HMGCV7kyZqlGuQna3cP8XlBTz/vIobGKNwQ+HNnq1kMfjuO/VsHnpIjbSvu06NjI0ifsZMwGzIIiL8z3BmzVKG49JL1WcjFvHKK55lJSIiVHzg1Cl3oP3TT5VLqG5d337vvtvTtTNqlPv9pEnuOMLq1e4VSd4zgMxM5WK7+mr1ncwzJYNPP1WvhtF1OJRBHzLE8+/CYtHLRzVVkmAagjSgmelzHHAkQNuRVIBbCHyt0/9WH6THuMW8/csfzFqfxp2fraXIIVVJgx9/dAdKjdGw4YYZP169eo/GQRmCtWtVZu4XXyhlOGqUGhW/8w60a+epFLdsUSPVadM8l7OCUiRSqpF1UpJywQwd6s5y/uILmDFDvc/KUsHM119Xhua559w+evCvxLxp0UIZriFDVMDZ+N5Ll8J777nbRUe7lW9srDuecvKk+l7/+pf6bDYErVsrGYYMcc8U9u5VzyoyUj2XwYPdM6jNmz1zBiwWZSjBnaFruJrMrjiDlBTP63NylHuvqEj93k6dUsfff1/FhXr2VDKYqV/f3XfbtmrGEB/vjgeBeyYzdqz6/t27K1nXrfPsy2LRy0c1VZJgGoJ1QDshRCshRBhK2c/zbiSEaA/EAquCKIvpfr7HbA6JcJoIu0NSZHeO2gyfP7hX+RjuiePHYeBAuOwy3w6jotSN/vlPNaJt0sTtWjAw+++ff14tc/THJ58oxZidrdw6Bw6o8gbt26vzrVu7R5nffQfXX+82UhaLimEYbpzSGAJQLqlffoHRo92uDe9Zzttvu4vBgXtZZF6ecn2BcumY7zV/vhp5L12qjEhurpppgIpVgDJqxrMyB4oN6tdXz81wzT33nPr+TZr4fo+XXlLK3YjRhIerkX1IiIptGNVMv/hCGdu1a32X6oL6PbZsqVZ/vf++ykI3LxgwftegYim7d6tn752UZrXqGYGmShI0QyCltAEPAYuAncBMKeV2IcTLQohrTE1vAWZIWTGF5EUA37hL+QNfrT7Ew19v5EStWDWq/O475f4BpYCNdezeQVqDefPUiDUmRn2+/XbP5aQAt9yiVqdMn65WAZlGzm8u2sW1763kcKbJvVKzplI43ko8PFyNMu12pZxBJTkZ3HyzOyhtxDnMfmt/zJ6tVuEYy2dB3ffMGTVKnz9fnZ8zx33ekP/MGfX9J0xQ38ubwYOVgbXbVbnos2eV0jRmEPXrKzfcnj3K1eLPaIWFqZlA69YqDhGonpKxdHXyZPX64ovuVVsTJiiDJWXJZciN5aJDh8Ill7h/r2Zee80dIyksVEbI24h17eoOYms0VQkp5V/qp0ePHvLPsOHgKdnimR99frq/tMjn2IItR/x3smWLlE8+KeXZs4FvdOSIlOHhUnbtGrhNRoaUShVJOXCg67Bx/8Xbj5X8hcaPV9c/+6x6tVqldDjc57t2VcdTU6W86Sb1fsmS4vs0ZPrhB/exb75xHzd+vv7afT41VR3r2NHz/v7IzZUyLEy1nz1byunT3edsNinbt5eyXz91/uKL/feRmemWIynJf5u8PHX+qad8z9ntUn73nZQXXKBkef/94mUuLYMGqXvOmFE+/Wk05QSQLAPo1Wq3sNl7+ahBgc13yv7j1qP8uOUod/RtQYu6NZixNpWL2tTlzRVZtOl9BxPMfmIzqamq5PDzz3u6l7ypU0clbL3yilq26UWhvXg3wvQ1h6h7KIfL6tRBGOUU9uzx9H/16aNiEElJaiXQJ594+rf9cfPNKrbQyZT2cdNNyqduuECSkjwDq3FxatQcGRl4RZJBZCRMnkxqZj4H4vvRr119CorsRIRalftk3z41cxg9OnDNH3MsxfDRexMRoVx6eXkqSXDTJneMQQjlRjO47rriZfZDfpEdh5TUCDP9G40erWZkhntMo/kLUO0MQSAdVWBzuOKyBvO3qKJp87cedR37NjmVI2fyST54mrv6teL42Xz6t6vn6XKyWFSZggYNYPBgpJQkHzxNw6gITmYXcPxsPhe1qUtMjTDle/70U6SU2O0OQqxub12hH+MEcPRMHv9bdZD3f9sLUb2Ztf4xusbFUJhfQK1aXstNx4xRGdPGKh4/RiCv0M7ek9l0bFwbq0W4g8/e3HsvXHopBwotTNmVzfUHTpHYso77fOfOACTtTWfvyRxG9mxGqNXX+7hw2zGePNyC7AIbTF3H0I4NWbLzOFPu6MFlnRtBWBj2IhuOW2/zez2gDMbYscpF5Lyvgc3uYEVKOlERIfQYNgx5wQUUTvsfoQ7p9oUKoVYL9ekDXbq4FwWUEodDkjhuCTmFNraOvZxa4c5/pZEjA180YoQKRhsxHI2milD9DIFp3dD0e3sz4addbE47g90hCQ+x+J0ZmDlyxr388fK31TLHL+/uTaHdTp/WddXo0PBr33cfU+p047XkdL99De3YgNv7tKBxdCT/+nYT2w6fZVB79/LYRduPse3wGQ6eymXsNZ1pGhPJ+J928eEyz6JrN3zojrP/+uQlhFoFi3ccxyGhTn4WXS+8iLUH87l8xEhC4ztzTVR/9qfn0LJuDf5zUze+XpvKrPVp3N6nOev2n6Znq1hGJMTRvVmMy8BJKTmRU0Tdlq34bmkK09cc4mxekachcHLrx2rPgHYNahHfNJqaYVYOZORSOyKEurXCWbU3XRkBJ2v2qSzcPSeyaVUvi3Y5OVg/+Zi/Z7UgpWtvru3elGev6OCSJTO3kGV/nKTv48/QoHaEx73fXLSL9351P5/9X33F1+M/59b169jasA2xp3NpEh2JEJDdLYH1SbuYknyMkZuPcE03FXAusjt45ccd5BfZeXpYB2JrhJF84BS5hXY6Nq5No+gIcgptru9wKrvQbQhQhujNn3fTuHYEoy427XWxY4fK4n799ZJnTRpNBSLkX2yz78TERJnsrwxxKdl2+AxXTV4BwIHxw/k2OZWnZqmtDaMiQtwJZkCIRdCrVR2S9pZuY5anh7Xnqi5NmLZkGy+MVEXnOj82k5zwAK6LciAqIoQ6NcM4mKGWXE67qxevL9jJrmOehdBqFuSy/e2bWNjjMu4f+ojruNUi6NkyltX7TlGvVjjp2e6Er5gaoWTmFtE0JtIVuA4PsRAeYuGs8znd0COO567siN0hiY4MJSOngL6ve+YF9mldh9X71FLNmxLjmJnsGZw1ZmLRkaGcySvi9o0L6HR8H+MG301umJrhDO/SmH8P70huoY2hE901j+JiI2lVrybT/tELgIFv/UrqKXd9oYsbhvP0Gw/Q7dgeRtz2BjmJvdl1LMvndw1Qr1Y4sTVCeeW6eEZOcVdBbRId4TEAuLNvC46eyefnHcddz+Tqbk24qmtjWtatSU6hjeGT1N9Yr1Z1eGZYe3q0qKOWn+7dq8p4GKukNJoKQgixXkqZ6PdcdTME24+ccf2THhg/nONn8+n9mtpGsW7NMDJy1BLLXa+oRCSrRXAwI4fXF+wivmk0/dvV43RuER0bR/HT1mO8usB/qeKeqdsQwNpm8dzSqzmPD23HvvQclv9xEqtFMHlpikf7q7o2JrFFLF3iYmgcHcFF4/0mWQN4KObnh3dk2+EzzNkUKEUD2mSk8ssnyrf/Ya/rGT/oLj64LYGPlu9jU2rgOn+NoyM4esZPAlgFcl33JsV+N4OwEMuF0qgAACAASURBVAvXdW/CzOQ0mkRH0K5hFMv+OImQDt5ePY0BXZtxR7u/se2In0qhAQi1Cors6v8jPMTC08M68MqPO875O9QIs7L++UuJ/GGOWpq7YIHaSlSjqUCKMwTVzjXkHSxuWDuC/u3q8fuedCLDrJADDWuHq8Clk7YNovh0VE+fvu4d0JoruzYmzGrhiZmb+H2PcgF1alybW2++DYcD/tOqDk1jIrFYBA1qR9CndV1yCmy0axhFq7o1GfFhEnExkbx7q2cRuun39kYg6NtGJW1lF9hYmZJOjxax1KsVztQV+5m+9hAXNo9leNfG9G5dlxfmbMPm3Gjh5Ws78+JcVf/n0jpuYz97xD+pVwj92tWjR8tYer3qu5fw9Ht706NFLO/9updJv+zhwUFtCA+x0qVpNHtOZLE/PZfYGqHMTE5zzSCGd2nMlsOZpJ7Ko1/beqxIUc9i1v19eWHudppER/Dg4Las2JNOjTAr09ceYt9J/8s+5z54MY2iI2jodPtc0r4Bj33jLl8x4IL6fD6qp3LvFNiYlnSAt37+wzXTmPPQxew/mcPve04yokdzrp2gNvKZkpnH1sNniAoPodDuYNXeDO4b2IboyFDaPLcAgPsHtsEhJe0bRjEsvhG7j2fRqXFtwqwWJLBqbwbHz+Yz+ZYL2Xr4DA9/reovTburF6mncpm+5hB7T2ZjtQhia4RxODOP3EI7m9My6VPabS01mgqm2s0IUk5kuVwLB8arMgp3fb6OpbtOcFvv5rSuX4vuzaLVVP4ckFJSaHewdv8p2tSvRZOYyJIvQvmTLUL4lL4oC3aHZFNqJq3q1SQmMpSNqadpFluDBrXCVNmGFi189mfeefQsr/+0i46No/homUrS2v/6lQghcDgkaafziIuN9Cuf3SH536oDxMXWYGgnz9LQhzPzCLEIlzL35qs1B/lh8xFevjaeEIsgv8jBlZN+B9y/F3Nfz8zaQkLzGP6WEEfLujV88kE6v7iQnEI7Tw9rzwOXqJ3ipJQB80a8WX/wFBnZhVzaqWGpr8kusPHagp10blKb23r7zw/YcOg017+fxGf/6MmgFrVVbkSjRp51mzSaCkC7hkxIKZmZnEqD2hEMaq8Sju77XzKLth/nvgGtefZKPyUjqgG5hTZumbKaBrUj+Pjvfv9WgoqUkrmbjlA/KpyL25775i1HMvPIyrfRvlEJS2MrGMMV+eHtCQyLP7eVSRpNeaJdQyaEENzcs7nHMWPJZnmMyv+q1AgLYe5D/Srt/kIIrrvQb3HaUlHaGVhFY7gYT2QVuLcWHTHCvb+1RlMFqHZ7FvsjzGkIrHpJn6acqR2hynm8OHc7Mi1N5XUYFVo1miqCNgS4DUF1nhFogkP9qHD6tlYBf7szkO+zraVGU8lUO9eQP27r05zIMCvXdfdTwVKj+ZP0v6Aeq/ZlYEf/w2mqJvrvEugaF0PXOD8VJTWaciDUufOdnhFoqiraNaTRBBmrxdjropIF0WgCoGcEGk2QCbUqQ5DfsTNRx4+r3d00miqENgQaTZCxGq4hawjUaVDJ0mg0vmjXkEYTZEKcMwL74cNqj4od516vSKMJJtoQaDRBxnANLf51C7z6qnsPaY2miqANgUYTZC5sFgvAlsNnKlkSjcY/JRoCIcRDQojYihBGozkfaVmvJgMuqI/dWDWql49qqhilmRE0AtYJIWYKIYaJ0pZm1Gg0LkItQhsCTZWlREMgpXweaAd8CowC9gghXhNCtAmybBrNeYPVIlx7RWg0VY1SLR+VUkohxDHgGGADYoFZQojFUsqngymgRnM+EGIVpDRoCbm57j2tNZoqQomGQAjxCHAnkA58AjwlpSwSQliAPYA2BBpNCVgtFmwIiKya5bI11ZvSxAjqAddLKS+XUn4rpSwCkFI6gKuCKp1Gc54QYhFEZ6bDY4/Bpk0lX6DRVCClMQQLgFPGByFElBCiN4CU0v/O7RqNxgOrRVAz5yy88w7s2VPZ4mg0HpTGEHwAZJs+5ziPaTSaUhJiERw/m68+6FVDmipGaQyBkKaNjZ0uIV2jSKM5B6IjQ5F65bWmilIaQ7BPCPGIECLU+fMosC/Ygmk05xOPDb3A/UHPCDRVjNIYgvuBi4DDQBrQGxgdTKE0mvONyDAroaFWHBZrZYui0fhQootHSnkCGFkBsmg05zWH6jfntblbeP6qTpUtikbjQWnyCCKAu4HOQIRxXEp5VxDl0mjOOyxCYNduIU0VpDSuof+h6g1dDiwD4oCsYAql0ZyP1M85zdWTXoDVqytbFI3Gg9IYgrZSyheAHCnlNGA40CW4Ymk05x9RhbkkLPke9um1FpqqRWkMQZHzNVMIEQ9EAy2DJpFGc55ibGKvVw1pqhqlyQeY4tyP4HlgHlALeCGoUmk05yM6j0BTRSnWEDgLy52VUp4GlgOtK0QqjeY8xCr0jEBTNSnWNeTMIn6ogmTRaM5rpNVCXo1aEBpa2aJoNB6UJkawWAjxpBCimRCijvFTms6dO5rtFkKkCCHGBGhzkxBihxBiuxBi+jlJr9H8hThWryn/nvo73HxzZYui0XhQmhiBkS/woOmYpAQ3kRDCCrwHXIrKSF4nhJgnpdxhatMOeBa4WEp5WgjR4FyE12j+SlgtAod2C2mqIKXZqrKVn5/SxAp6ASlSyn1SykJgBnCtV5t7gfecMQgji1mjOS+pm32av7/9DCxbVtmiaDQelCaz+O/+jkspvyjh0qZAqumzUafIzAXOe6wErMBYKeVCPzKMxlnfqHnz5iWJrNFUSWoU5ZOwZjEcvL2yRdFoPCiNa6in6X0EMATYAJRkCPytlfOeF4cA7YBLUBnLvwsh4qWUmR4XSTkFmAKQmJio59aavyTCuWooM6eAmEqWRaMxU5qicw+bPwsholFlJ0oiDWhm+hwHHPHTZrVz+8v9QojdKMOwrhT9azR/KTo3iQbgyJk8bQg0VYrSrBryJhelrEtiHdBOCNFKCBGGqmA6z6vNHGAQgBCiHspVpPPvNeclf0toCoDDrie1mqpFaWIEP+B26ViATsDMkq6TUtqEEA8Bi1D+/6lSyu1CiJeBZCnlPOe5y4QQOwA78JSUMqNsX0WjqdpYw8M4ElWPovCIkhtrNBWIkCUsZxNCDDR9tAEHpZRpQZWqGBITE2VycnJl3V6jKTMpJ7IYOnE5k265kGu6NalscTTVDCHEeillor9zpQkWHwKOSinznZ1FCiFaSikPlKOMGs15j9WiPLF2h6OSJdFoPClNjOBbwPyXa3ce02g050DYqXQ+n/l/1F3xW2WLotF4UBpDEOJMCAPA+T4seCJpNOcnIUWFXLJ/PRHHvRfPaTSVS2kMwUkhxDXGByHEtUB68ETSaM5PrM7/NodDrxrSVC1KEyO4H/hKCPGu83Ma4DfbWKPRBMZqtQKQvD+DPpUsi0ZjpjQJZXuBPkKIWqhVRnq/Yo2mDNQMV+Wn007ncSaviOhIXY5aUzUo0TUkhHhNCBEjpcyWUmYJIWKFEOMqQjiN5nwiLCKMs63acTaiFj9tPVrZ4mg0LkoTI7jCXPvHWSn0yuCJpNGcpzRsyKHf17GgQz8+TzpQ2dJoNC5KYwisQohw44MQIhIIL6a9RqMJQHzTaIZ2bFjZYmg0HpTGEHwJ/CKEuFsIcTewGJgWXLE0mvOQjAzo148eG5fpbYs1VYrSBIvfEEJsAYaiSksvBFoEWzCN5ryjqAhWriTmgv7YtSXQVCFKW330GCq7eARqP4KdQZNIoznPEaC3rNRUKQLOCIQQF6BKR98CZADfoJaPDqog2TSa8wvnxjQW0K4hTZWiONfQLuB34GopZQqAEOLxCpFKozkfcRoCPSPQVDWKcw2NQLmEfhVCfCyEGIL/7Sc1Gk1pCA2FXr3Iia6jDYGmShHQEEgpv5dS3gx0AH4DHgcaCiE+EEJcVkHyaTTnD7GxsGYNW/teRlkrUUspKWkPEY3mXCkxWCylzJFSfiWlvAq17/AmYEzQJdNozlMsgjIp8/wiOwmvLKbP679g14XrNOXIOe1ZLKU8JaX8SEo5OFgCaTTnLadPQ7duXLhyYZmWj2YX2DidW8TxswUU2fXmNpryoyyb12s0mrJgt8OWLdTKPkNZBvTm8tU6xqApT7Qh0GgqGEHZ/Pxm46E9Q5ryRBsCjaaiMOURlEWRm91JekagKU+0IdBoKgojj0CUTZGbXUNShwg05Yg2BBpNRREaCkOGkFWvYZm2q5QeriE9I9CUH9oQaDQVRVQULFnC7osuwyHhyW838+BXG7CVcgWQdg1pgoU2BBpNRbJuHf1mfUxhTh6z1qcxf+tRTuUUlupSs/IvsGnfkKb80IZAo6lIVq5k8BdvE253K39jpJ9baGPhtqOcOJvv91LzSqOLxi+l5Zj5JI5bTIHNHlyZqxmfr9zPu0v3VKsMbm0INJqKxKL+5YRJyRhZwtOSDnL/lxt4+ccdfi/150FKzy4kO9/m+uxwSM7mF5WjwNULh0My9ocdvPXzH5zIKqhscSoMbQg0morEaQgiTOUb+034lVfn72DCwl0A/LjlKDuOnPW5NFBcwBx3fmb2FrqO/Zlfdh4vP5mrEeYnXJ3KeGhDoNFUJE5DYMFTyfyy8wQAkaFWAFbvy/C5NJAhMLswdhxVBuRIZt6fl7UaYn6W1ccMaEOg0VQsTkMwskcTj8P5RcrPP+mWCwEo9OMHClSx1KywDD1WjQaz5Yrns6w+D1EbAo2mIrnzTkhP57Fb+/HerQmuw8YqIGNGUFDkYOG2Y/x96lq2HT4DFOca8h3FVie3RnlifsTVyA5oQ6DRVCiRkVC3LlgsWE3/fYVOQ2C1CEKtgkK7ne83prH8j5Ms++MkULoYgTGK1XkGZUOa5gTV6RFqQ6DRVCTr18Nzz8Hp01gt7n+/ApMhsAjBR8v2uUb1RhbyKj9xA/N5cCuv8lBiBzNy+GbdIc7kVZ9VSNU1e1sbAo2mItm6FV5/Hc6c8ZwROGMCFgExNUKxOSQpJ7LVJYfP0P+NpbyxcLffLj3cGc4RrZGb8Pg3mxg6cRnp2e6lkNkFNpb/cZKcAhvFMW7+Tp6ZvZW5mw6f89c8H6g+ZkAbAo2mYjFmAQ4HFuG7BbjFInjl2ngAiuxKFW0/cpbUU4FXAXnECKTnse83HiblRDaHTuW62rz3awp/n7qWKcv3uY6tP3ialSnpHv3mFipDUViNspilHzdbdUAbAo2mIjEZAqvF1xBYhXAdtzmXCZnLSRjBZIAGUeGqKz/BYu+idmaldtbp6jEUvZSSER8kcdsna8jI9k2iqk6BZ3OMwCEhM7eQqyb/zpPfbq5EqYKPNgQaTUViMgQdG9dmwAX1ua13c/dpIbAYhsA5Iyg0lZBo3yiKJtER3Nm3Bf8e3hHwv+TRW3ebV6Main1z2hk2pWZiMzU2Gx2B8NuXmbxCOytT0kt0M/1V8JwESA5m5LLt8FlmrU+rLJEqBG0INJqKxGQI6tUK54u7evGvy9p7nDZcRsa+xGbl3KFRFEnPDuGla+Nd7VzK36EUF/gGOrekZbqCvobLae3+U1z33koenbHR1c58leG5Ki5oOmX5Pm77ZA3v/ppSqq9fXuw6dpaF246W+2zF3JtDVp84QVANgRBimBBitxAiRQgxxs/5UUKIk0KITc6fe4Ipj0ZT6dx4I+TnQ3u38g+xul1EVovAKgzXkHNGYBrOm91JhiEwdOFXaw66rvF2DY2bv5MHv9oAgN0rM23joUzT+9NM/mWPR0XU4vZOMIxLRc8IbvpwFfd/uYH1B0+Xa7/SK95SniuHHA5ZZd1sIcHqWAhhBd4DLgXSgHVCiHlSSu+KWt9IKR8KlhwaTZXCalU/JsJMy4eUa0i9N2YEZl0U4mEI1KtDSnILbbwwd7vrnD99k3ZazRaKvE4aMwSAl3/YwYmsAuo54w+B+nJf6ytjRXDWWWjPyMguLzzcbGXcWzoQV076nT0nsln17GAaREWUW7/lQTBnBL2AFCnlPillITADuDaI99Noqj5btsBDD8F2t9IO8RrlW12uIV8lZDG1FcaMwIGrSF1809qEWgXp2QW8/5t/d43dq1+baYZguKHyCt0K1ntUfDKrgNnr0ziVU+i6NtDIeey87dzx6RqyzrEi6smsAlcwe/3BU/SbsJQPl+31/S7FKOovVh3g6skrXJnZpcEjj8BRvqU6dh3Lwu6QHD5d9epABdMQNAVSTZ/TnMe8GSGE2CKEmCWEaBZEeTSaymf/fnjvPYiPhzffBDzdPVaL8LuayCDEwxCoV4d0uxyeu6IjFiGYt/lIwLwDm5drqMgUgwh1uqkK7Q5Tcpp6k1dop89rv9Dz1SX869vNfL5yv8tYBdKXnycd4Pc96RxIzw3Qwpd9J7Pp+eoSLp24HFDLZ9NO57Fw2zGftsWN2L9Zl8rWwyogXhKf/L6Pj5fv8/giakZQarFLTW5h1ds/IpiGwN9fs/dj/QFoKaXsCiwBpvntSIjRQohkIUTyyZMny1lMjaYCad0aoqPV+wMHAPfIHqBmuNXjszcWPzECcI9chVCZyf6UTaHNwYA3fmWJs9KpgXnmYRihgiKHa5RvjLoz8wo5Zto0J7vA7tpmsySF6a+IXiDSs1V84rCzgmpxMYpAhfjA/XxK2go0u8DGuPk7eXXBTo+9HFbtzeDVBTtLK3ap8TezqWyCFiNAzQDMI/w44Ii5gZTSnDP/MTDBX0dSyinAFIDExMSqGW3RaEpDly6QmQkPPww9ergO//70IPKL7DSIiuBIpv8dyiBwjMAYGVtEYHdJZl6RfwNhUpTGpf9d8ofrmEN6njMosjtMRqT4f8uiczAE3jOW4nouzjXkWoZbgn/HHMA1u7jGzfdvBI6eySMpJYOhnRoSHRlabN/+WLPvlOu9lJKsAhu1I3z72X0si02pp7m6WxNqhAVTVQd3RrAOaCeEaCWECANGAvPMDYQQjU0frwHK3/xqNFWRyZNh1CjXx2Z1atCuYRSAK0YA0Ld1Xe7t34q2DWrRqHYE3ZvFus4ZI96M7EKSnatnLBbB5Z0b+b2loRDfGNGVQJMOf75+45j3mX3p2czfelSdK2F4dk6GwCuGUZweL841ZCzGKskQmL9YcU0PpOcgpeStRX/wr2838826Q8X364V5UYDBu0tT6Dr2Z6av8e3riZmbeGb2VhbvCP4mQ0EzM1JKmxDiIWARYAWmSim3CyFeBpKllPOAR4QQ1wA24BQwKljyaDR/FUy16AgNsfDv4Z3493DfdoYyH/2/ZNfI3CIEo/u35ofNR3zaGyPf4mIQdofk4rZ1ad+wNlNX7gfcrhlvF4156aZnmQvJ8j3pNKztXnl0LobAe4llccq+OMVtfM/M3CJmJqfSu1UdWtSt6dPOM5s4cIeXvPUbE2/q5gpiFxSdW+kNo28Vf5EIIUh1ruQylwAxyMxVbqqzFVD0L6jzDSnlAmCB17EXTe+fBZ4NpgwaTZUkIUHlEnz9tRpO790LDRtCVBRWiyA6L4sbty6mMHIQagGeLxY/q4ssAjo1qc3Tw9r7BIsNBWvOW/DG7pBYhPBoE0jZ5hf5upRArY65c+paj7Z7T+QwuINvHyey8vll5wmGdGhAg9oRzu/jqWANBepvFuNvXb7N7kDijr18tyGNE1kFDO7QgKmjevq0N3dRXDwC4FROobsq7Dk6qc1Gxu6QhFiFa/bjz1AahswoPhhMdGaxRlMZ2GyQ51xGWFAA7drBY49BQQGt6tXkhfztPP/rVP45592AXXRrFuNzzOKsVfTAJW3p366e3+usFuFS3N6zA7tDjVTNxz9dsZ+5mw4HdP+EhVhYvT/DtW+CMWI2Eyjo+tnKAzz73VY+WbHfQwYzxSlcfyP4i8YvpfOLi8hy5hoYyW7ZBTbW7j9F2+cWMHaee/muecZRknI3r9CS55B3LKXEISE8RKlcw3gbbit/hsAwfNNWHeS0KcEvGGhDoNFUBqGhMHcu/N//wdCh6tjUqbB7N+EhVm547FYAGkeFBewiOjKUkT09V1z7yzz2JsRruaoZu5RYhGecAuDRGZtcSnfiTd3Y8fLlgFJWtcJDSD2Vx51T1/L+bync/ol7NlCMFwpw5yuYK5x6J7wV567xPmV3SE5kFVBod3AySxXQyzEC5FItTbU5JMudRktKSYZJyZaU+euQbuW9MiWdDYcCZzYv2HqUx7/ZxOHMPJechiEwAvRGYNxsCOwOyUs/bHeVCwFlxIKJNgQaTWVw8cXq9eWXYeVK9/FCp1Lq2BH694eQ4r23EaGeWcpm/X1V18ZEhfteb94QJ8RLUzsc7lmFN4YCFAJqhIWw6cVL2fjCpa7cA4A3Fu4mr8icjOa+fuLiP7j783WcyS0ynZcerwCLtnvmCxin/NkUb8VtVqj+so7tps5ST+XS67VfuOy/y33kCYTdIV3Ke92B01z/flLAGMZbi3bz/cbDrExJd/Vr/L6MZD/DNWSuJ5V84BSfrTwA4CpIGOxNcrQh0Ggqg0mTYMkSaNXK87hhCNLS1G5mhcW7BMJDPf+FzbOAGxObseDR/j7XlGZG4G0gwD16N6qSxtQII6ZG4BmLgVE6e9Ive/hl1wl2H89ynXPVRjIpuvlbjnpc73C5YnzxVpBmQ5DnzxAYxgzYcOi0a9YQqD9vftxylJUpnjvFeV9y7Ew+1763kn3pORiCG/bq0k4NAdh5VD0D4/t/t+EwBzNU+xyna236Pb3p2bKOU65ixfrTaEOg0VQWQ4bAtc6qK507q1dD8U+dCrm5MHt2sV30bFGHWqZRv7c7KC42kpev7UxCc3c8wTuT2fyqFKXA6hzl92ldh39fqcpdf7RcJUJ5e5xKGqxGhnnOWjyCpnbPwKt5hG+IWVz3vrkNngFZb1yGQAi/Sr8k19DOo2d9jnn389Wag2w2ZTM7pHS1aRobSa+WdVj+x0km/bLHo5THAacryJgl1I4MLVUF2PJAGwKNpjIJD1c/U6Z4Hi8qUhq3YcNiLx/aqSFrnhvi+uy9VF0Iwd/7tuS7By52KVazO8kY+XsnqoWYDMRlnZUMa/efcvVppiQV1cBUwA6U6yfVuVzScNUY7hVjRB8WYnEZB1ceg4S3l/zBF6sOuPryTigrKYvYPCPwzldQ9yrhy/jBfInN7mDyUs8aTw7p/g4WIQgNUc9v4uI/WLUvw5VfYFSFNWYJIVbhU2o8WGhDoNFUJhERkJgIHTqoEtUDB6rjRUVK833wQYldmEf4xZWnmP3Pi/jPjd08ZgeGovEOMhtxBIcDWtStSf929VyulhLivz5c3a2JhzH4bOUBHnCVxFYK7qdtx5i76bAriGoEVR0O6VLOaadzeXvJHl70qLLq5RoqMdhb/IyhNCPvpy5v7/HZfI2/5DWJ+ztYBIR6WesIp3vP5rWSKMRi8Sk1Hiy0IdBoKpM77oBx46BOHZg5U80C7HaYOFGdf+ABuP56VZYiAGZ3UKCVQgAXNo9lRI84Qqy+wWIPQ2CBi9vWZeAF9bmtjwpWhodYXG4M73uUpDutFkHbBrU8jh1x1hEylHFmbhGPztjEwq0qUGzMWuym8hkFfvZOHr9gl8doefIvewCo6XRHmUMdEunaqU0I/0q7pDwCUJsDmTF/f799es8IvAzB+BFdAfezMGY1IRbhkv+VH3eUqnheWdGGQKOpTNq0gUsuUe//8x8YMAAOH1YzBIPvv4etWwN24RH8LcYQ+MOIBYR4zSo6NKrNtLt6cVXXJgCEh1o9Vg2VBqNPf6PgjJxCklLSfdbPPz17i7qfMSMw+df9uXKyCmy0f2Ehg976jZQT2a7kq0s6NHDK4Hlfw/1iCRQjKMWMwDvAPm/TEV75cQdZ+UV+ZxlSSqTza1qE8FlSW9MZ4zGer9k1ZMzwft+TzpTlwStWpw2BRlNVOHoUNm6E5s3VvgWnT8P48SqQXKNGwMs89yg4t1saitK8pNTfrKJpTKT7Hj5n/StPQ5n7GwUD3PrJGtbsdxdgMyvIGs4R/fcbDrvcIt7F6JrVUTIV2hzsT8/hj+NZSKBf23o0dmYpm5W2lJ57N/szLKVxxXsbl6dnb+HTFftJPnDaFIx2n3c4pMutZhH41IJyxwg8DZ5yDRUvb3kR3JJ2Go2m9ISEqIxjg5gYeOYZ9VMCgzs0ICO7gPpegdlANKwdzvGzBS5l7a+qqZlnhnVgyvJ9QMmrhm5KjOPY2QJOnM1n17EshBB+l6MCHltiPndlR7o3i2H1vgwSW9Zh5JTVLNl5gjYNVH0g7416hnRoyEVt6hJiFdz1eTKFNoczM9r/TEfiOeIvblWRRQT2yweq1bTnRBY/bVNLX8NDLK4SHCeyCug3YSmgVlBdnxBHi7o1GfFBEqAC46BmAlJKxv+ksrBDrJ75HMEME2hDoNFUFQxDsHkzXH01fP45DB5cqkv91dApjk/v7MmuY1nsPHqWXceySsxILm1A+pZezXn9+i4A3PhhkrM/qFOr5HwDq0WQ2LIOic61831b12XJzuPYHfX9tg8LsXBZ50aueEOBzY6UEqtFEOoctXvWTJLunAQZyJ8vXbI4AozAA9Vq+nL1IVfxuDCr2xB8t+EwNockoXkM13Zv6urfwDDGdoeDnEI7Z/NthFoFsTXCPH4XwdzvWLuGNJqqgtXqrkGUmqpqEO3ZowrULVlSrreKbxrNDT3i6NO6LnGxkfRuVcd1LqFFbDFX+rqGDPU07rp4lxEA+OclbbiuexMGtW/AC8M78eYNXYvt13ukPaSj8vN7J3B5y2GMqAtsDmdCnPDJjwDlQnr3V7W0c/fxLCYs3OXTpzmoC2r207Kup1su0IzAnMAWbs74PqO2ypx1/0WuILg5lmPIX2hzuEpt/PvKjlgtwmP2dS4VXM8VbQg0mqpC69YqcFzkLMFgtar3GzdChn9l+Ge5tFNDVjwzmGsvdO8ie7uzrEEgfPIIvJSnweAODXl75IW0rFeTkbIWNAAAHYBJREFUyDCrR5G8p4d5LsH0d/1NzjpKxpLSWzf9xNjFHxIlnc/H2dwYUY+dtx2bXTqD08b6e3d/hzJ8Sz3H1nBvCFOjMI/YZUuJKshxKfuhHRu65DAI5OYqMBkCw+8fnZfF/z59jEaFWQFjOUbm9Qtzt7sK9hmGxPxMghkj0IZAo6kq3Hkn/PqrW3tZrao4HcCqVUG9tVm3Fef68W5rpqRAtVmpXdTGtzKq90g71CsoO+a3zxm14Ue6pe/36K9WeAh1a4bhkCrmYBGCgRc0YOAF9fmbycAZBsW4z1VdG7PiGbfr7Z51c7jw/lt5KOkb14hdeMndNCbSI3BuJt+0vPWS9vXp0jSagfvX0y4jlfoFnqWkzd+1Ts0wujuNpLEHgWFItGtIo6mOfPYZfPedem+1qvwCgHfeKX0fJ0+qjORSxhfAXT+oVG29g8XOV78GYv9+yM72OR/qx8/uvfTV2xc/+vp/A1BTeia2CSF40pnklV9kxyIEXeKimXZXLy6Pd6/QMVwrxr3rR4W7lm4CROcrOaMKclyjd4twP5m+reuycsxg6tbyDcg3yzzG63PedBnx3q3r8u19fbhq1woAwjG5ddLTfcp83JgYB8Cs9WmqfahhCNyXbT18hvRsz9pI5YU2BBpNVWLiRFiwAEaMgAYNoG5duO8+da64ndrN7N8PJ06o2UUpOZdlp4GMhs9MIicH3n8fvvoK8B8gNWPxsiQhXqPmQquaHdWUyn1iHi2HWgS3bVzAmzNepv2uZHefpjbGgNpYyhoe4lkD6fvOgwAIs9tcsgrhfjbFPaMux1IYsf1X2makqj6sAuGwc9me1QA8e2lb1XDWLLjuOqwF7n2phYAIpyyfJx0AoF2DKOc5903ziuws3OZZmbW80IZAo6lKhIaqnctmzYJOndSx116DfftKr627dIHhfva2LIZzSj8IsHzUZ7VRURG89ZYqnud13l9egb86SQYPD27LV7PGAtCydqjzvLttwy3rePXn97l8dxK9Vi1y3+d0Bis+uItvv3yanqnbiCrIcQVsa3gVw9vWqC3bnhzL4na9PYLFhuEr7vFHFqmRen5IGE9d3p6L29bDYjLcYQ5n/ODIEVi5ktj3J9H9iNpBzioEtSLcM5PRA1rT3pm9bDaen43qySXt/a+g+rPo5aMaTVXCO5cAlHuoTh3/7f0hpdrxzGotua3BOVgC3xIT7rX3Hjz+uHq1KyXor+qpT7+ffqqS566/XhXjc5LQPJbI/Bxo1oyzHeLhoM1DZNmgAdO7Xc6tmxdhtbufX8ThNOLOniDu7Am+nT4GgG+/Xc6p+q084gcA7U4eJGNwIous0NBplIQQrpmKOZGsYVQYZ06dZUjKOg41b0di5kEAVnx0D2zvB59/jq2Bu2CgkddgVJetM2Ecgy4ayaYm7bFaBAPa1WdyJ0Hcnm20HnSZ6Tm55RvkzJYOBtoQaDRVidBQWLhQKf4lS9TS0eRkVYeoZ08YNgyiTLVuvvxS1Sv673/VVpcAffpAo0bKLSOl/6Hsr7/CunXw4INQs2axNYq8CbR81KcPoyyG07A1jo7g2X5NaHrqqF9DEHH2NNxzj/rwzjvwyCOEWS0U2h3UMVb3jBpFYv+ubJD7uKitO+AckZ/Lc8MepvvRP3CEulcCWbzcaZ/1uJrOjWK5sV8bj+PhRQUsnvogZ2fGEPuP97BGN3R91ys6N8S2dSs9L3avHlqx4GVCk5T/f3fDVrQ/vt/d2YoVsG4dliuuBODVS+7iygt7qHMFbh//A6u/JS26AUIMJzLMytW/fw9r18Lfhqpn1qsXnZtEc9/A1rRv6FnfqLzRriGNpiphKLHTp90+l6QkePNNuOkmtaGNGaMm0ZYt7mO7dqk8hHvvDezPuOEGlbHsjCN4uGq+/15dZ1RCddL+5AGGpKxBSE/lOuCPNfTfv8H3Vs6ZgGEIhBDcx2Guuv8GzHOVVvVU5nCH779yH3Tu57z86UEseWIgzaKds4NPPmHYsJ58d2VT+rSuq47l5tJl4svEH0vhyn9MZtboF1zdRFicpZ2Fhc2N2vHS0PuwN27s8zj6pG4DoHZ2Jv+Z/186NYl2ydxk7kzue+BaEl51Z3gbRgDAIiUpd/6T/BBT0lx+PsLpDqqXm0nU5o3quGmjoVCHnTd/mgSnTqmd6lavVr/3Hj2gd284dYqIUCvPXtGR6xPifGQuT7Qh0GiqEt99By1aqPeGa8c0wuWs18YoiYnQsqU79wBU+dDERFi2zNfNZHDKWePHqZi6xUXz+vVdmDG6D7z9tjq3fDnMn+8W7X9P8unsV6i9ZaNHV6OXf8096+Z4BottNtimlCsx7vwB1q2DvDwifpjDrZt+4qqdy/nqnt78/PgAmoeYZB0zBgoKaBQdoSqX/vSTOl5UpIry3XWXu21uLpGrVnKXRZV38FjueekANixZQ/4lgzkY25jmp4/S8PsZ0K8f/P67q12o051kExYG70tm+P41XHh4Fxak2jLUkH3NGvW+cWP2X3cLi9v2wmYN4fTYcXzd7XK3THl5iKgobhn5KndsnE+zR0e7rqNvX8/fxZ49au/qAwfUjOGGG9Tx226DrCwqAm0INJqqREwMHFT+Zi64QL2a9y02b125fLlyHR044Knw7XaYMwcGDVJBZ38YStB5XYjVwi29mqtR9pIl8O236vwnn7guqVmkVrrYYz0zj5udPc7A/Rto8fNc98HPPlN933orPPSQOpaZ6VoaW/uOW3lt0Xu8O+8N6ggbFzSMQhQUQGys+3sfOuTuLyEBnn4aLnP6z80ropyzByIieGrZNIZ875ZZhIWRkLSIWr8u4dPEa1k+5V4sdpvaJ3rxYlc7i3OWMztebfIz8NO3+P7LJ5UbrE0bdf9du5TbbfdusNuJ+3kel6aspenpY/QMyeWGfhe4Zdq1CzZtYlWLbixu24eQU86EwPvvVzM8g7g4tQ8FQLNmarVXhw4QFqZchC++SEWgDYFGU5Ww21UM4PPP3RVHzTMCs887I0NlHQPMmOE+brMphQUwbZr7+FtvwXbnpi5duqj4Qu/evjKEhqpR6fTpbp89cLJmDNO7DSO/lad/vbZzLX6naJPB+tvfVFzD7MpKS3PPEkxE2J2zmeHD4fnnlRusaVPPtOCmTWHCBDVTuPBCFRc55lxKma8MlIiI5KKDW+iwaaV6Bvv2QUqKcrsADqHUXRhSbQjk9Nffs/Y73vjpHbY3bsf8Dv0AsDpnWEN/+Bx27oQNG9yynD4N11xDaK7aY7h2fjY0a0ZUfAdlRBcvVr+bnj2ZMX0M0fnZCLtd5XdMmqTk2r9ffU5NhfR0ZQC//FK55AYNUjO/KVOU4agIpHPjh7/KT48ePaRGc16za5eUdrv78+LFUtavL+ULL3i2++YbKUHKVaukbNNGynHjpLzxRin79JFy6VIpBw6UcsAAd3uQ8umn1fs33pDyu++kXLhQyu7dpZw1Sx232dTnjz/2ESszvKacGT9Urtp51PNE48aq7w8/9P0uV1wh5QcfqPcbN6p25p8OHaTMzpYyP1+dN9i8Wcqbb5byhx+kXLNGyjlzpPzyS/f5sDApx4xR78eMkRLk/BcnyeQmHVS/N9wgZd++Us6f77pXZv9Bnvd+5BH3cwH5yujX/7+9M4+SqjwW+K+AYdgXHUQGQdlUeERFEEEMQiBEkIfCUwREUImG4wsuRIyJxpiYnATkicflqBg5RI8i+tBgDCYKYYk8NYLOIGpYxQREhbCooLhMvT/q3rm3Z7rbaZjuYej6nXPPvf3drfq73V/dr6q++vSsyXP0/eIOurN9p8qyguqgQSZv/LssX27rJ5+M5Js8uXz/7kbNtKywUHX1aitbuDA67qWXVOvWjZ7t/v22JFT8HtW9eyvXbYYAqzRFu+o9Asc53DjpJLPzhwweDG+/nWgmmDwZLr7YtgsLYdMme5t+6ikoLra3yiZNzNQQ0qYNzJhhs57deKM5ix99FEpKIjPJl1/a5x077JrvRtEwy6bcykVrF9O1JHKUApGsoZ9i61aLRpo+3UxQG2zWsATz1XHHwfjxFlnUuLGZau65x+4JMG8ezJ8PP/qRzclwzTXWo4nfM+wdjR8Po0dzzujB1PuJhYiyYoWl5Yj1oJofc1SiAzzoSVBcDA0bomecybbmx/DrO/6Xrb37V34uF1xgPZHGjRNzP20330R5z+1Pf4IHHijf3eKoZsgXX0T1E+/htWtnx06ZYp8bNrQF7JksWwZz5kDz5lVKR36wuCJwnNpAURH87GfWIGzZkmjymTUr8dht22xUb7t2kVN19uyowQrnQd6wIfIhhA7RsLEuKDBnZcw0cf6EoQA0L6gQHvSHP9h6yhQLWV292tY33WTvxE88EeR9Dq79/PPW2PXtawOsvvjC7Pxz5pgT+803rfEHUyrPPGP+gvi4iFAR7Npl58+fT+P/6Mqpo03GcgUYmnTuusvqYPz46BqhL6JxYygr47ppF3H87vepV0c4qShJPqEHH7TBcVu2mHIOGTPG1uG4h3axJHUDBth5f/1rpAjiPp/27c381irJQLFbbrHBhMuXJ36XLODjCByntvDpp2Y7XrfOGtLwjTbm9AQssuX++80evX+/Nfgxp28CBw5YXqL+/S36KAxHLSiwhjfukwgVyLvv2r0b2CxgdO9u6TA++sh6Ap1iPgRVa+zHjrU3fLCGcNo0aNbMIqSmTrUoHjAnaZC2GSgflQxUVgT795sy6dw5im5q2RJuuCHqPfz857b+zndsbMb3v2+K6bPP7O1+0ybrPc2eTdMDB2i1bzfX3HYFDS69sHJd9etnPoeFCxPLZ8yweuwf9CJOOcXs/o0bR3UEUS+hXhWb3Xr17NkWF0fb2SKVzehwXdxH4OQtr71mNuY6dczWP22aakmJ2dCHDLF9zz1n61mzzN5/5ZWRLbtNG7NHx23e11+vumqV6j//mVh+772qZ5+tOnCg3busrLKtPOTRR1UvvbSyPf0HP1BdtMi2i4psPX686ief2HmbNkXHDgzs92+/rfrxx6rjxkX7unSxdd++0T2bN1c9/ngrP/HExHqaN8/KGzSwY+rUUV23LtrftavqgAGqd9yh2qiR6ltvld9r9Njf2PZDD6kOG5bcTxBfnn66as8u/n3+9reqnfPkk4n3Kiur2nkpII2PoMYb9kwXVwRO3lJSEjUKjRol7lu2zMonTLD13XebwznekJx+uurMmZUbs+Ji1TFjzHkK1kguXJjobL7llsRzWreO7t2tm+qZZ1r5tdfa+q67bN/evaZozjrLjqnIyJGJ1924MdpXVqa6e7fqT39q+84+O9r32GORQ3b9+sRrlpWp7tql2qOHOasffzxqRFetUm3f3hTS1Kl2fmlp+f1HXTIjUi5LlkTfK9ly661Vf3br19s5V1+t+tlnVTvngw8S7zd1atXvl4R0isB9BI5TW4ibFPbvhz/+MfrcoYOZix55xD7XrZvocA4ZOdLs0vv2mU2/a1czYezZEzlqly6FESMSTUNhuohRo2zdvHl0zbIyM/Fs3gxXBQOn6gejbJs1s5GyBw6Y87oicccpRI5SsFDKFi3M3PTii4ljIsaNi8xYFcY1IGJl9etbeO3gwdEI6549rWzu3MiWf+qp5ad+XScwP61fbz6SX/zCPl9yiSUBXLkymhsik1xOnTubDEVFieaidDRpEn233/7WfC5ZwhWB49QW2rWDBQsiW3TcVt2+vSmH3/3O9oc2d7CZz7p3t0aoY0d44QUbo3D33TZatrDQHJKhnX3FCltPm2bRQ0VFdq9zzrH7T5pUWRHUqWPKaM4cK6vY2PXpEymJOOEo6oEDzZlaXFz5mOJia8xbR0ncWLXK8imJJFcwIR98kBDBA5ivoG7dhKR2IYN6x/wbzZpFjuCjj7YxGGedZTmfZsxIdBh/EyL2Xv/AA4mRXOlo3Bjuvde2R45M7lCuLlJ1FQ7XxU1DTt6zb59qs2Zmg/8mCgujsQOpOPVUs6OD6u23q+7cGe074wwrv+8+1ZUro/Lhw80Gv2aNaufOqmPHWvlLL1W+xjdx332JMfgVKSlR7dlTde7cqOzYY1UnTVJdujT1eYsXm+zTpyff//DDiaaX2bPNpJTKFHSo/OpXqhMnVt00pGoygermzYd8e9w05DhHAJ9/DtdeC4MGWdRLVaJPDhwws0qYWygZ9epFJqDzzrO3X7A0CWH4aadO9jYcMmWKybN2rTWToRmqXz8LewyvURWuvjpKs5CMJUssJPXBB6Oyzz+373VS5bmPy+nVy9b16yff37u3jWIGSyExfLiZYhYtSjyuQYPEfEkHy803m0mqqqYhgGHDLEVH+/TzSB8qrggcp7awa5eZc155xcwoVVEEf/6z2cTfeCP1MRMmWIMDiXbvadOskYbKDXWPHrYeN85i5CuOZagqM2fCaaeZjyIVoR9BNSrbs8fGFixZkvq80MSVShF0726hpmAhtp07W9hn69aWYuP66y08tXfvzPwB1UnbtjbQLsv3d0XgOLWFeGPw3e9GWSrTETaC6ZTGNdfAxImV71FWFjW+FXPetGpljmYwW/bB2q/few9KS9M7Qs85x5Zwys44FZ3NcZYvt55K6FROxWWXWZbP/fttueIKc5bfeadNlLNiReJI4iMQH1DmOLWFVq1sEFRhoY2SrcpkMjfeaOt0imDHDjORXHqpvYFWZOZMS/VQkXvusSil+++3t/rhw6v2PeKEcqVr0E85xVItJCPdeTNnJqalSMWsWWayAavT0tLIoXvCCaaAQqV3hOKKwHFqC3XqROGhVaW01NZN08xw9dVXFoUzaVKiLXzaNIvqCUNGKzJokC3t2ll66INRBEOHWuRSaJqqKrffbik30imCqtKokYWtqkYRSDfcYP6Sk0+uHHV0BOKKwHGOZNassRxD3/pW6mPCdNeLF8Pll0dhlQMG2JKODRssH1CyMQtVYciQaI6BTBg0yBro6lAE9etbammIZlXLM7LqIxCRc0VknYhsFJGURkARuVBEVER6ZVMex8k7Tj7ZYvTTmZHCQVwLFsCHH1b92hs2RInbMpjzuFro1ctMNl26VM/1CgttiSu0quYEOgLImiIQkbrAfcBQoBswVkS6JTmuKXAN8Gq2ZHEcJw0FBWYWGjXKUlVXlS5dLJkcHHyP4GApKDDTUKdO33xsJsSd5TUVKVQDZPPp9QY2qupmVf0CeAI4P8lxtwMzgM+zKIvjOKkQsRHJCxZkbmoJY+Jz3SPIFgUFUaZWVwTVQlvgX7HPW4OyckSkB9BOVZ9LdyERuUpEVonIqh07dlS/pI7jHBwNGpgJJRyYdSTQv785ikPfSR6QTUWQ7BWhfESIiNQBZgFJ4tIqnKQ6W1V7qWqvVtnMt+E4TmY0bAijR6fP91Pb6NLFBu4VFdW0JDkjm96QrUBsqh6OA96PfW4KdAeWiXUrjwWeFZERqroqi3I5jlNdjBmTmDH0SKFjx5qWIKdkUxG8BnQRkQ7ANmAMMC7cqap7gXKVKyLLgBtcCThOLeKMM2paAqcayJppSFW/An4I/AV4B3hSVd8SkV+KyIhs3ddxHMfJjKwGyqrqImBRhbJbUxw7IJuyOI7jOMnxpHOO4zh5jisCx3GcPMcVgeM4Tp7jisBxHCfPcUXgOI6T57gicBzHyXNE4/OA1gJEZAfw3kGeXgTsrEZxqguXKzMOV7ng8JXN5cqMI1Gu41U1aY6eWqcIDgURWaWqh92cBy5XZhyucsHhK5vLlRn5JpebhhzHcfIcVwSO4zh5Tr4pgtk1LUAKXK7MOFzlgsNXNpcrM/JKrrzyETiO4ziVybcegeM4jlMBVwSO4zh5Tt4oAhE5V0TWichGEbkpx/duJyJLReQdEXlLRK4Nym8TkW0iUhIsw2Ln/CSQdZ2IfC+Lsm0RkTeD+68Kyo4SkRdFZEOwbhmUi4jcHci1RkROz5JMJ8XqpEREPhaR62qivkRkjoh8JCJrY2UZ14+ITAyO3yAiE7Mk1x0i8o/g3s+ISIug/AQR+SxWbw/EzukZPP+NgeyHNAt9Crkyfm7V/X9NIdf8mExbRKQkKM9lfaVqG3L7G1PVI34B6gKbgI5AfaAU6JbD+7cBTg+2mwLrgW7AbdisbBWP7xbIWAh0CGSvmyXZtgBFFcpmADcF2zcB04PtYcDz2HzUfYBXc/TsPgCOr4n6AvoDpwNrD7Z+gKOAzcG6ZbDdMgtyDQHqBdvTY3KdED+uwnX+DvQNZH4eGJoFuTJ6btn4vyaTq8L+/wFurYH6StU25PQ3li89gt7ARlXdrKpfAE8A5+fq5qq6XVVfD7Y/wWZsa5vmlPOBJ1T1gKq+C2zEvkOuOB/4fbD9e+CCWPkjarwCtBCRNlmWZRCwSVXTjSbPWn2p6gpgV5L7ZVI/3wNeVNVdqrobeBE4t7rlUtUX1GYGBHgFmyc8JYFszVT1ZbXW5JHYd6k2udKQ6rlV+/81nVzBW/1oYF66a2SpvlK1DTn9jeWLImgL/Cv2eSvpG+KsISInAD2AV4OiHwZdvDlh94/cyqvACyKyWkSuCspaq+p2sB8qcEwNyBUyhsQ/aE3XF2RePzVRb1dgb44hHUTkDRFZLiLfDsraBrLkQq5Mnluu6+vbwIequiFWlvP6qtA25PQ3li+KIJkdL+dxsyLSBFgAXKeqHwP3A52A04DtWPcUcitvP1U9HRgK/LeI9E9zbE7rUUTqAyOAp4Kiw6G+0pFKjlzX283AV8BjQdF2oL2q9gCmAo+LSLMcypXpc8v18xxL4stGzusrSduQ8tAUMhySbPmiCLYC7WKfjwPez6UAIlKAPejHVPVpAFX9UFW/VtUy4CEic0bO5FXV94P1R8AzgQwfhiafYP1RruUKGAq8rqofBjLWeH0FZFo/OZMvcBIOBy4JzBcEppd/B9urMfv7iYFccfNRVuQ6iOeWy/qqB4wC5sfkzWl9JWsbyPFvLF8UwWtAFxHpELxljgGezdXNAxvkw8A7qnpnrDxuXx8JhBENzwJjRKRQRDoAXTAnVXXL1VhEmobbmLNxbXD/MOpgIrAwJteEIHKhD7A37L5miYQ3tZqurxiZ1s9fgCEi0jIwiwwJyqoVETkX+DEwQlX3x8pbiUjdYLsjVj+bA9k+EZE+wW90Quy7VKdcmT63XP5fBwP/UNVyk08u6ytV20Cuf2OH4vGuTQvmbV+Pafebc3zvs7Fu2hqgJFiGAY8CbwblzwJtYufcHMi6jkOMTEgjV0csIqMUeCusF+BoYAmwIVgfFZQLcF8g15tAryzWWSPg30DzWFnO6wtTRNuBL7G3rkkHUz+YzX5jsFyeJbk2Ynbi8Df2QHDsfwXPtxR4HfjP2HV6YQ3zJuBegmwD1SxXxs+tuv+vyeQKyucCkyscm8v6StU25PQ35ikmHMdx8px8MQ05juM4KXBF4DiOk+e4InAcx8lzXBE4juPkOa4IHMdx8hxXBI6TAhG5OcgIuUYsC+WZYllQG9W0bI5TnXj4qOMkQUT6AncCA1T1gIgUYZkw/w+L3d5ZowI6TjXiPQLHSU4bYKeqHgAIGv4LgWJgqYgsBRCRISLysoi8LiJPBTljwnkepovI34Olc1B+kYisFZFSEVlRM1/NcRLxHoHjJCFo0F/CRjgvBuar6nIR2ULQIwh6CU9jI2L3iciPgUJV/WVw3EOq+msRmQCMVtXhIvImcK6qbhORFqq6p0a+oOPE8B6B4yRBVT8FegJXATuA+SJyWYXD+mCTiKwUm91qIjaBTsi82LpvsL0SmCsiV2ITsDhOjVOvpgVwnMMVVf0aWAYsC97kK07/J9hkIGNTXaLitqpOFpEzgfOAEhE5TYNMl45TU3iPwHGSIDZvcpdY0WnAe8An2JSCYLOA9YvZ/xuJyImxcy6OrV8Ojumkqq+q6q3AThJTBztOjeA9AsdJThPgHrEJ4L/CMjpehaXGfl5EtqvqwMBcNE9ECoPzbsGyZgIUisir2AtX2Gu4I1AwgmWVLM3Jt3GcNLiz2HGyQNypXNOyOM434aYhx3GcPMd7BI7jOHmO9wgcx3HyHFcEjuM4eY4rAsdxnDzHFYHjOE6e44rAcRwnz/l/IAkGO7zuDC8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(c, label='Training Loss')\n",
    "plt.plot(d,linestyle='--', color='r', label='Test Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
